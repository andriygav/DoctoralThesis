\section{Основные понятия статистического обучения}

В теории машинного обучения базовой является стохастическая постановка, в рамках которой данные рассматриваются как выборка из неизвестного распределения. Пусть задано вероятностное пространство $(\Omega, \mathcal{F}, \mathbb{P})$ и случайная пара $(\mathbf{X}, \mathbf{Y})$, принимающая значения в декартовом произведении пространств объектов и ответов $\mathcal{X} \times \mathcal{Y}$, с неизвестным совместным распределением $\mathbb{P}_{\mathbf{X},\mathbf{Y}}$. Генеральная совокупность $\Gamma$ задает множество всех возможных объектов, а кольцо выборок
\[
    \mathfrak{D} = \{D_\Gamma^i : D_\Gamma^i \subset \Gamma\}
\]
состоит из всех конечных подмножеств, доступных для анализа. В дальнейшем под выборкой будем понимать произвольный элемент $D \in \mathfrak{D}$ вида
\[
    D = \{(\mathbf{x}_1, \mathbf{y}_1), \ldots, (\mathbf{x}_m, \mathbf{y}_m)\},
\]
который рассматривается как реализация независимых одинаково распределенных случайных величин $(\mathbf{X}_i, \mathbf{Y}_i) \sim \mathbb{P}_{\mathbf{X},\mathbf{Y}}$.

Моделью (или гипотезой) называется отображение $f \colon \mathcal{X} \to \mathcal{Y}$, выбранное из фиксированного класса параметрических функций $\mathfrak{F}$. Чтобы формализовать качество модели, вводится \textit{функция потерь} $\ell \colon \mathcal{Y} \times \mathcal{Y} \to \mathbb{R}_{+}$, измеряющая несоответствие предсказания $f(\mathbf{x})$ и истинного ответа $\mathbf{y}$. В классификации часто используют 0--1-потерю
\[
    \ell_{\mathrm{0\text{-}1}}(f(\mathbf{x}), \mathbf{y}) = \mathbb{I}\{f(\mathbf{x}) \neq \mathbf{y}\},
\]
а в задачах регрессии квадратичную или абсолютную потери.

\begin{definition}
    Риском модели $f \in \mathfrak{F}$ называют математическое ожидание потерь относительно истинного распределения данных:
    \[
        R(f) = \mathbb{E}_{(\mathbf{X},\mathbf{Y}) \sim \mathbb{P}_{\mathbf{X},\mathbf{Y}}}\left[\ell(f(\mathbf{X}), \mathbf{Y})\right].
    \]
\end{definition}

Так как распределение $\mathbb{P}_{\mathbf{X},\mathbf{Y}}$ неизвестно, прямой расчет $R(f)$ обычно невозможен. Вместо этого вводят \textit{эмпирический риск} по выборке $D$:
\[
    \hat{R}_m(f) = \frac{1}{m} \sum_{i=1}^{m} \ell(f(\mathbf{x}_i), \mathbf{y}_i),
\]
который рассматривается как статистическая оценка истинного риска. Связь между $R(f)$ и $\hat{R}_m(f)$ является центральным объектом исследования в теории обучаемости.

\begin{remark}
    В главах~\ref{chapter:complexity}, \ref{chapter:gesian} и далее для эмпирического риска параметризованных моделей используется обозначение $\mathcal{L}_m(\boldsymbol{\theta})$, которое совпадает с $\hat{R}_m(f)$ при параметризации $f_{\boldsymbol{\theta}}$. В настоящей главе оба обозначения рассматриваются как взаимозаменяемые.
\end{remark}

\begin{definition}
    Алгоритмом минимизации эмпирического риска называют отображение, которое по выборке $D \in \mathfrak{D}$ возвращает модель
    \[
        \hat{f}_{\mathrm{ERM}} \in \arg\min_{f \in \mathfrak{F}} \hat{R}_m(f).
    \]
\end{definition}

Даже если класс моделей достаточно богат, чтобы аппроксимировать зависимость между $\mathbf{X}$ и $\mathbf{Y}$, для конечной выборки $D$ возможно \textit{переобучение}: алгоритм подстраивается под случайные шумы в данных, достигая малого эмпирического риска при высоком истинном риске. Поэтому важной задачей является построение оценок отклонения $|R(f) - \hat{R}_m(f)|$ для различных классов $\mathfrak{F}$ и схем выбора моделей.

\begin{definition}
    Модель $f^{*}$, минимизирующая риск в фиксированном классе $\mathfrak{F}$,
    \[
        f^{*} \in \arg\min_{f \in \mathfrak{F}} R(f),
    \]
    называется \textit{наилучшей в классе}. Величина
    \[
        R(f) - R(f^{*})
    \]
    называется \textit{избыточным риском} модели $f$.
\end{definition}

В идеальном случае теоретические оценки должны гарантировать, что избыточный риск $\bigl(R(\hat{f}_{\mathrm{ERM}}) - R(f^{*})\bigr)$ мал с высокой вероятностью при разумном объеме выборки $m$. При этом ключевую роль играет мера сложности класса моделей $\mathfrak{F}$, определяющая скорость сходимости эмпирического риска к истинному.

\begin{definition}
    \textit{Класс моделей} $\mathfrak{F}$ называется \textit{обучаемым} в заданной постановке, если существует алгоритм, для которого при любом распределении $\mathbb{P}_{\mathbf{X},\mathbf{Y}}$ и любых $\varepsilon > 0$, $\delta > 0$ найдется такое число наблюдений $m(\varepsilon,\delta)$, что
    \[
        \mathbb{P}\left\{ R(\hat{f}) - R(f^{*}) \leq \varepsilon \right\} \geq 1 - \delta,
    \]
    где $\hat{f}$ есть результат работы алгоритма по выборке размера $m \geq m(\varepsilon,\delta)$.
\end{definition}

Дальнейший анализ в рамках классических подходов концентрируется на поиске верхних оценок $m(\varepsilon,\delta)$ через различные характеристики сложности класса $\mathfrak{F}$: VC-размерность, ростовую функцию, Rademacher-сложность и другие. Эти меры играют фундаментальную роль в теории обучаемости и подробно рассматриваются в следующей секции.

\section{Классические меры сложности и их ограничения}

Первые строгие представления о сложности моделей сформировались в рамках статистической теории распознавания~\cite{vapnik1974StatTheory}, где ключевую роль сыграли понятия VC-размерности и структурного риска. Пусть задано пространство объектов $\mathcal{X}$ и класс булевых моделей $\mathfrak{F} \subset \{0,1\}^{\mathcal{X}}$. Набор точек $D = \{\mathbf{x}_1, \ldots, \mathbf{x}_m\} \subset \mathcal{X}$ называется \textit{разделимым} классом $\mathfrak{F}$, если для любого разметочного вектора $(\mathbf{y}_1,\ldots,\mathbf{y}_m) \in \{0,1\}^m$ существует модель $f \in \mathfrak{F}$ такая, что $f(\mathbf{x}_i) = \mathbf{y}_i$ для всех $i = 1,\ldots,m$. Тогда VC-размерность класса $\mathfrak{F}$ определяется как
\[
    \mathrm{VC}(\mathfrak{F}) = \sup \left\{ m \in \mathbb{N} : \exists D \subset \mathcal{X},\ |D| = m,\ \text{$D$ разделим классом $\mathfrak{F}$} \right\}.
\]
Эти идеи позволили связать обобщающую способность алгоритмов с ростовой функцией $\Pi_{\mathfrak{F}}(m)$ и получить верхние оценки разности между эмпирическим риском $\hat{R}_m(f)$ и истинным риском $R(f)$ вида
\[
    R(f) \leq \hat{R}_m(f) + C \sqrt{\frac{\mathrm{VC}(\mathfrak{F}) \log m}{m}},
\]
где $C > 0$ некоторая универсальная константа. Однако такие оценки используют грубые верхние границы, мало чувствительные к структуре конкретной задачи и распределения данных.

Развитие PAC-подхода дополнило картину формальными критериями обучаемости~\cite{valiant1984LearnableTheory}. Класс моделей $\mathfrak{F}$ называется \textit{PAC-обучаемым}, если существует алгоритм, который для любых $\varepsilon > 0$ и $\delta > 0$ и для любого распределения на $\mathcal{X} \times \{0,1\}$, при числе объектов
\[
    m(\varepsilon,\delta) \geq C \frac{1}{\varepsilon^2}\left(\mathrm{VC}(\mathfrak{F}) \log \frac{1}{\varepsilon} + \log \frac{1}{\delta}\right),
\]
с вероятностью не менее $1 - \delta$ возвращает модель $f \in \mathfrak{F}$, удовлетворяющую неравенству $R(f) - R(f^*) \leq \varepsilon$, где $f^*$ минимизирует риск в классе $\mathfrak{F}$. Для реальных данных высокой размерности классические PAC-оценки остаются слабыми: они требуют огромных выборок даже для относительно простых архитектур и не учитывают внутреннюю структуру параметров, регуляризацию и специфику процесса оптимизации.

Rademacher-сложность предложила более тонкий инструмент анализа, связывающий способность класса функций к переобучению с эмпирическими оценками~\cite{koltchinskii2000RadamakherTheory}. Для заданного класса вещеценных функций $\mathcal{F}$ и выборки $D = \{\mathbf{x}_1,\ldots,\mathbf{x}_m\}$ \textit{эмпирическая Rademacher-сложность} определяется как
\[
    \hat{\mathfrak{R}}_D(\mathcal{F}) = \mathbb{E}_{\sigma}\left[\sup_{f \in \mathcal{F}} \frac{1}{m} \sum_{i=1}^{m} \sigma_i f(\mathbf{x}_i)\right],
\]
где $\sigma_1,\ldots,\sigma_m$ независимые случайные переменные Радемахера, принимающие значения $\pm 1$ с вероятностью $1/2$. Соответствующие неравенства связи с обобщающей способностью имеют вид
\[
    R(f) \leq \hat{R}_m(f) + 2 \hat{\mathfrak{R}}_D(\mathcal{F}) + 3 \sqrt{\frac{\log (2/\delta)}{2m}},
\]
что позволяет учитывать адаптивность класса к конкретной выборке. Тем не менее даже эти оценки остаются в основном асимптотическими и практически не отражают поведение современных нейронных сетей, имеющих миллионы параметров и сложные регуляризационные схемы~\cite{macKay2003}. Недостаток адаптивности классических мер к глубине, нелинейностям и особенностям оптимизации создает разрыв между теорией и практикой, который необходимо закрыть в дальнейших разделах обзора.

\subsection{VC-размерность и ростовая функция}

Одним из центральных понятий классической теории обучаемости является \textit{ростовая функция} (англ. growth function) класса моделей. Для конечной выборки $D = \{\mathbf{x}_1,\ldots,\mathbf{x}_m\}$ определим множество индуцированных разметок
\[
    \mathfrak{F}|_D = \{(f(\mathbf{x}_1),\ldots,f(\mathbf{x}_m)) : f \in \mathfrak{F}\} \subseteq \{0,1\}^m.
\]
Тогда ростовая функция класса $\mathfrak{F}$ определяется как
\[
    \Pi_{\mathfrak{F}}(m) = \max_{D \subset \mathcal{X},\, |D| = m} |\mathfrak{F}|_D|.
\]
Заметим, что тривиальная верхняя оценка имеет вид $\Pi_{\mathfrak{F}}(m) \leq 2^m$. Если VC-размерность класса конечна и равна $d = \mathrm{VC}(\mathfrak{F}) < \infty$, то лемма Сауэра обобщает эту грубую оценку и дает полиномиальный рост числа реализаций:
\[
    \Pi_{\mathfrak{F}}(m) \leq \sum_{k=0}^{d} \binom{m}{k} \leq \left(\frac{em}{d}\right)^{d}, \quad \text{для всех } m \geq d.
\]
В сочетании с неравенствами концентрации это приводит к классическим оценкам равномерной сходимости эмпирического риска к истинному риску, которые лежат в основе принципа минимизации структурного риска.

Важным следствием конечности VC-размерности является возможность построения иерархии вложенных классов $\mathfrak{F}_1 \subset \mathfrak{F}_2 \subset \cdots$ с возрастающей сложностью, что позволяет формализовать баланс между смещением и дисперсией модели. Однако на практике вычисление или даже оценка VC-размерности для сложных архитектур оказывается нетривиальной задачей: для линейных классификаторов в $\mathbb{R}^d$ верно $\mathrm{VC}(\mathfrak{F}) = d+1$, но для многослойных нейронных сетей VC-размерность оценивается как степенная функция от числа параметров и может быть астрономически велика, что делает полученные границы очень слабыми.

Кроме того, классические оценки через $\mathrm{VC}(\mathfrak{F})$ не отражают влияние таких практических аспектов, как ранняя остановка, стохастическая оптимизация, нормализация и другие регуляризаторы, которые существенно улучшают обобщающую способность, но никак не уменьшают формальную VC-размерность класса.

\subsection{PAC-обучаемость: реализуемый и агностический случаи}

В рамках PAC-подхода различают \textit{реализуемый} и \textit{агностический} случаи. В реализуемой постановке предполагается, что существует модель $f^{*} \in \mathfrak{F}$, для которой $R(f^{*}) = 0$, то есть данные порождаются без шума в рамках выбранного класса. В этой ситуации возможно получить более сильные гарантии сходимости алгоритмов минимизации эмпирического риска:
\[
    \Pr\left\{\sup_{f \in \mathfrak{F}} |R(f) - \hat{R}_m(f)| > \varepsilon \right\} \leq \delta,
\]
при числе наблюдений $m(\varepsilon,\delta)$, логарифмически зависящем от $1/\delta$ и линейно (или квазилинейно) зависящем от $\mathrm{VC}(\mathfrak{F})$.

В агностической постановке шум допускается, и оптимальная модель $f^{*}$ достигает ненулевого риска $R(f^{*}) > 0$. В этом случае стандартной целью является достижение неравенства вида
\[
    R(f) \leq R(f^{*}) + \varepsilon
\]
с вероятностью не менее $1 - \delta$. Соответствующие оценки на число наблюдений имеют тот же порядок, что и в реализуемом случае, но константы и зависимости от параметров модели оказываются менее благоприятными. Важно, что классические PAC-оценки делают акцент на наихудшем распределении данных и не используют информацию о структуре реальных задач.

Еще одним ограничением является то, что PAC-анализ, как правило, не учитывает вычислительную сторону задачи: существование алгоритма, удовлетворяющего PAC-критериям, не гарантирует его практическую реализуемость с полиномиальной сложностью. Для глубоких нейронных сетей это особенно важно, так как реальное обучение основано на приближенных численных процедурах, которые не обязательно находят глобальный минимум риска.

\subsection{Rademacher-сложность и локальные оценки}

Переход к Rademacher-сложности был мотивирован стремлением получить более точные, зависящие от данных оценки сложности класса функций. В отличие от VC-размерности, которая является глобальной характеристикой $\mathfrak{F}$, величина $\hat{\mathfrak{R}}_D(\mathcal{F})$ зависит от конкретной выборки $D$ и потому позволяет учитывать геометрию данных. Через технику симметризации и цепочечные неравенства могут быть получены оценки общего вида
\[
    \mathbb{E}\left[\sup_{f \in \mathcal{F}} |R(f) - \hat{R}_m(f)|\right] \leq C \, \mathfrak{R}_m(\mathcal{F}),
\]
где $\mathfrak{R}_m(\mathcal{F}) = \mathbb{E}_{D}[\hat{\mathfrak{R}}_D(\mathcal{F})]$ обозначает ожидаемую Rademacher-сложность.

Для типичных классов гладких функций удается получить явные верхние границы на $\mathfrak{R}_m(\mathcal{F})$ через нормы параметров и радиус области определения. Например, для линейных классификаторов
\[
    \mathcal{F} = \{x \mapsto \langle w, x \rangle : \|w\|_2 \leq B\},
\]
при ограничении $\|x_i\|_2 \leq R$ для всех $i$ верна оценка
\[
    \hat{\mathfrak{R}}_D(\mathcal{F}) \leq \frac{BR}{\sqrt{m}}.
\]
Для нейронных сетей аналогичные оценки строятся через произведения норм весов по слоям, что уже лучше согласуется с эмпирическими наблюдениями о роли регуляризации весов.

Тем не менее и здесь сохраняется ряд принципиальных ограничений. Во-первых, получение достаточно точных верхних границ для глубоких архитектур приводит к сильно завышенным оценкам, поскольку приходится применять грубые неравенства при переходе от нелинейных слоев к линейным аппроксимациям. Во-вторых, стандартные Rademacher-оценки учитывают только статический класс функций и не отражают динамику обучения, в частности, влияние траектории градиентного спуска и стохастичности минибатчей. Наконец, даже будучи зависящими от данных, эти оценки по-прежнему нацелены на наихудший случай и плохо согласуются с наблюдаемой в практике устойчивостью крупных моделей к шуму в данных.

\subsection{Общие ограничения классических мер сложности}

Суммируя рассмотренные подходы, можно выделить несколько ключевых ограничений классических мер сложности в контексте современных моделей глубокого обучения. Во-первых, большинство оценок строится в предположении фиксированного, конечномерного пространства признаков и не учитывает появление дополнительных структур, таких как сверточные фильтры, остаточные связи и механизмы внимания, которые существенно меняют эффективную сложность класса моделей.

Во-вторых, как VC-размерность, так и Rademacher-сложность ориентированы на worst-case анализ и не используют специфические свойства реальных распределений данных, такие как низкая размерность многообразия, коррелированность признаков или наличие сильных инвариантностей. В результате получаемые границы оказываются слишком консервативными и часто на несколько порядков хуже эмпирически наблюдаемых характеристик.

В-третьих, классические меры, как правило, рассматривают модель и данные раздельно: сложность гипотезы оценивается независимо от сложностей выборки, а влияние распределения на обучение учитывается лишь через общие вероятностные предположения. Для глубоких нейросетевых архитектур, где наблюдается сложное взаимодействие между параметрами, структурой данных и алгоритмом оптимизации, такое раздельное рассмотрение оказывается недостаточным для объяснения эмпирических фактов.

Наконец, классические результаты в основном фокусируются на асимптотических режимах $m \to \infty$ и не описывают поведение моделей при конечных, но больших размерах выборок, характерных для реальных задач. Это особенно заметно при анализе крупных языковых и мультимодальных моделей, для которых наблюдаются устойчивые законы масштабирования качества от размера данных и модели, выходящие за рамки традиционных теоретических предсказаний.

\section{Современные подходы к анализу сложности нейросетей}

Развитие теории сложности нейросетей началось с изучения их аппроксимирующих свойств. В фундаментальной теореме Дж.\,Цибенко (англ. Cybenko theorem) показано, что многослойный перцептрон с регулируемым числом нейронов в скрытом слое способен аппроксимировать любую непрерывную функцию на компактном подмножестве $\mathbb{R}^n$ с произвольной точностью~\cite{cybenko1989ApproximationBS}. Этот результат формально выражается следующим образом: для любой непрерывной функции $g \colon [0,1]^n \to \mathbb{R}$ и любого $\varepsilon > 0$ существует сеть вида
\[
    f(\mathbf{x}) = \sum_{j=1}^{N} \alpha_j \sigma(\mathbf{w}_j^\top \mathbf{x} + b_j),
\]
где $\sigma$ --- сигмоидальная нелинейность, такая что $\|f - g\|_{\infty} < \varepsilon$. Теорема Цибенко дала первое строгое обоснование репрезентативной способности нейронных сетей, но не предоставила конструктивных оценок на число нейронов $N$ и не объяснила, как глубина влияет на эффективность представления функций.

Вскоре после этого Й.\,Хёстад показал, что переход к многоуровневым архитектурам позволяет экспоненциально сократить число нейронов, необходимое для аппроксимации некоторых классов функций~\cite{hastad1987phd}. Формально, для любую фиксированную глубину $L$ существует семейство булевых функций $F_L$, для которого любая сеть глубины $L$ требует $\Omega\!\left(\exp(n^{1/(L-1)})\right)$ нейронов, тогда как сеть глубины $L+1$ реализует те же функции полиномиально малым числом параметров. Этот результат свидетельствует о принципиальной роли глубины: существуют функции, которые требуют экспоненциального числа нейронов в сети фиксированной глубины, но допускают компактное представление при добавлении дополнительных слоев. Позднее эти идеи были развиты в работах Й.\,Бенджио и Я.\,Лекуна~\cite{bengioLecun2007:scaling,begio2011exponetialdepth}, где обсуждалась экспоненциальная эффективность глубоких архитектур.

В более современных исследованиях Н.\,Коэна, А.\,Эльдана и др. показано, что глубина определяет не только число параметров, но и тип функций, которые можно эффективно представить~\cite{cohen2015OnTE,eldan2016exponentialcomplexity}. В частности, в работе~\cite{eldan2016exponentialcomplexity} доказано существование функций, которые могут быть представлены трехслойными сетями с полиномиальным числом нейронов, но требуют экспоненциального числа нейронов в двухслойных сетях. Эти результаты подчеркивают ограниченность чисто ширинных архитектур и стимулируют развитие теорий, учитывающих топологию сети.

Работа Н.\,Коэна и А.\,Эльдана также указывает на экспоненциальную зависимость сложности сети от числа слоев: для определенного класса полиномов степени $d$ минимальное число скрытых блоков $N_L$ в сети глубины $L$ удовлетворяет условию
\[
    N_L \geq c\cdot \exp\left(\gamma \frac{d}{L}\right),
\]
где $c, \gamma > 0$ зависят от нормировки весов и выбора нелинейностей. При увеличении глубины до $L+1$ тот же класс функций достигается при
\[
    N_{L+1} \leq C \cdot d^{\alpha},
\]
то есть сложность падает до полиномиальной. Это означает, что для фиксированного уровня точности гибрид ``ширина/глубина'' должен подчиняться экспоненциальной зависимости: слишком малое число слоев приводит к взрывному росту числа параметров, тогда как рост глубины позволяет удерживать сложность в полиномиальных границах.

Параллельно исследовались подходы к количественной оценке сложности обучаемых представлений. PAC-Bayes теоремы~\cite{mcallester2013book}, связывают обобщающую способность моделей с дивергенциями между апостериорным и априорным распределениями параметров. Для нейросетей эти подходы применялись в контексте анализа плотности спектров Гессиана и флатнеса локальных минимумов. Хотя PAC-Bayes оценки предоставляют гибкие вероятностные ограничения, на практике получение информативных границ требует сложного подбора априорного распределения и зачастую приводит к слабым числам.

Другой линией стало изучение динамики обучения через линейные аппроксимации, такие как нейронно-тангентное ядро (NTK). Работы Артура Жако и коллег показали, что в пределе бесконечной ширины динамика градиентного спуска описывается линейным ядровым методом, что позволяет получить строгие результаты по обучаемости и обобщению в этом режиме. Указанные подходы демонстрируют, что некоторые архитектуры обладают явным «линейным» режимом, но не объясняют поведение конечных сетей и не учитывают ограниченные вычислительные ресурсы.

Начиная с 2017 года активно развиваются эвристические метрики сложности, основанные на анализе ландшафта функции потерь показывают, что минимумы с малым спектральным радиусом Гессиана коррелируют с лучшей обобщающей способностью, а распределение собственных значений отражает «жесткость» модели к возмущениям данных. Однако эти связи во многом эмпирические и зависят от режима оптимизации, поэтому пока не приводят к строгим теоремам обучаемости.

Влияние регуляризации и структурных ограничений параметров также анализируется через теории дистилляции, привилегированного обучения и методов снижения размерности (квантизация, вырезание). Например, дистилляция в стиле Хинтона~\cite{hinton2015} интерпретируется как способ переноса сложности от сложной модели к компактной, но строгие границы на избыточный риск пока существуют лишь для простых семей моделей~\cite{lopez2016,grabovoi2021bayesian609999432}.

С обоснованием потребности в больших данных связан анализ эмпирических законов масштабирования. Работы Дж.\,Каплана и Дж.\,Хоффмана~\cite{kaplan2020ScalingLaws,hoffmann2022Chinchila} демонстрируют, что метрики качества языковых моделей следуют степенным законам относительно числа параметров, объема данных и вычислительного бюджета. Эти законы используются на практике для планирования обучения, но пока не имеют строгого теоретического обоснования и, как правило, подстраиваются под конкретную архитектуру.

Суммируя, современная теория сложности нейросетей развивается в нескольких направлениях: (1) аппроксимативные теоремы, описывающие роль глубины и ширины; (2) вероятностные оценки обобщения (PAC-Bayes, NTK), связывающие динамику оптимизации с геометрией параметрического пространства; (3) ландшафтные методы, изучающие спектральные свойства матриц Гессе и устойчивость к возмущениям; (4) эмпирические законы масштабирования, связывающие качество с ресурсами. Несмотря на существенный прогресс, эти подходы по-прежнему дают неполную картину и мотивируют разработку новых мер сложности, способных совместить свойства данных и модели в единой теории.
