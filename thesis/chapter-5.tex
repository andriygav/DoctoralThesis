\section{Сложность моделей в многозадачном обучении}

\subsection{Радамахеровская сложность моделей глубокого обучения}
Пусть $\mathcal{X}$ обозначает входное пространство, а 
$\mathcal{Y} = \{1, \dots, C\}$~--- общее пространство меток для всех доменов.
Домен определяется как пара 
$\mathcal{D} = (\mathcal{X}, P(X))$, где $P(X)$~--- распределение над $\mathcal{X}$.

Предполагается наличие $K$ размеченных исходных доменов
\begin{equation}
    \mathcal{D}_{S_k} = (\mathcal{X}, P_{S_k}(X)), 
    \quad k = 1, \dots, K,
\end{equation}
с размеченными выборками
\begin{equation}
    \mathcal{S}_k = \{(x_i^{S_k}, y_i^{S_k})\}_{i=1}^{n_{S_k}}, 
    \quad x_i^{S_k} \sim P_{S_k}(X), \; y_i^{S_k} \in \mathcal{Y}.
\end{equation}

Также рассматривается целевой домен
\begin{equation}
    \mathcal{D}_T = (\mathcal{X}, P_T(X)),
\end{equation}
с выборками
\begin{equation}
    \mathcal{T} = 
    \{(x_j^T, y_j^T)\}_{j=1}^{n_T^{\text{lab}}} 
    \cup \{x_j^T\}_{j=1}^{n_T^{\text{unlab}}}.
\end{equation}

Цель кросс-доменной классификации~--- обучить классификатор
\begin{equation}
    f_\theta : \mathcal{X} \to \mathcal{Y}, 
    \quad f_\theta(x) = \arg\max_{y \in \mathcal{Y}} 
    p_\theta(y \mid x),
\end{equation}
такой, чтобы ожидаемая целевая ошибка
\begin{equation}
    \epsilon_T(f_\theta) = 
    \mathbb{E}_{(x,y) \sim P_T(X,Y)} 
    [\mathbf{1}\{f_\theta(x) \neq y\}]
\end{equation}
минимизировалась за счет использования знаний из всех источников 
$\{\mathcal{S}_k\}_{k=1}^K$. Наша цель~--- обучить классификатор, который, будучи обученным на данных из нескольких исходных доменов, способен достигать высоких метрик качества на примерах из доменов, которые либо не встречались during training, либо были представлены лишь ограниченными данными.

Современные задачи классификации часто решаются путем адаптации больших предобученных моделей 
к конкретному домену или набору данных~\cite{devlin2019bert}. Распространенная стратегия~--- тонкая настройка (fine-tuning), когда параметры предобученной модели обновляются с использованием размеченных данных из целевой задачи. Хотя этот подход обычно дает высокую производительность, 
он может быть вычислительно дорогим, поскольку количество обучаемых параметров 
очень велико.

Основная идея LoRA заключается в том, что для адаптации к задаче 
не обязательно обновлять всю матрицу параметров. 
Вместо этого обновления могут быть эффективно представлены в низкоразмерном подпространстве, 
которое захватывает существенные вариации, необходимые для адаптации. 
Это значительно сокращает количество обучаемых параметров, 
в значительной степени сохраняя выразительную способность модели.

Формально, пусть $\Delta W \in \mathbb{R}^{d \times k}$ обозначает обновление параметров для данного слоя. 
При стандартной тонкой настройке $\Delta W$ изучается напрямую. 
LoRA ограничивает $\Delta W$ условием низкого ранга путем факторизации:
\begin{equation}
    \Delta W \approx A B,
\end{equation}
где $A \in \mathbb{R}^{d \times r}$ и $B \in \mathbb{R}^{r \times k}$ с $r \ll \min(d,k)$. 
Обновленная матрица параметров тогда имеет вид:
\begin{equation}
    W_{\text{upd}} = W + \Delta W = W + AB,
\end{equation}
где $W$ обозначает замороженные предобученные веса, а $AB$~--- изучаемое низкоранговое обновление. 
Ранг $r$ выступает в качестве гиперпараметра, контролирующего размер изучаемого подпространства.

\begin{table}[t]
    \caption{Сравнение обновлений параметров при полной тонкой настройке и LoRA} \label{table:lora}
    \begin{center}
    \begin{tabular}{cc}
    \toprule
    \textbf{Полная тонкая настройка} & \textbf{Тонкая настройка с LoRA} \\
    \midrule
    $W_{\text{upd}} = W + \Delta W$ & $W_{\text{upd}} = W + AB$ \\
    $\hat{y} = x(W + \Delta W)$ & $\hat{y} = x(W + AB)$ \\
    \bottomrule
    \end{tabular}
    \end{center}
\end{table}

В задачах классификации предсказание обычно имеет вид
\begin{equation}
    p(c \mid \mathbf{x}) = \operatorname{softmax}(W^{\top} \mathbf{x}),
\end{equation}
где $\mathbf{x}$~--- это вектор признаков входного объекта, 
а $W$~--- обучаемая матрица весов. 
LoRA может быть применена здесь путем замены $W$ на ее низкоранговую адаптированную форму $W + AB$.

Многозадачное обучение~--- это подход, в котором несколько связанных задач 
изучаются совместно с целью достижения лучшей обобщающей способности по сравнению с 
обучением каждой задачи независимо. Ключевое предположение заключается в том, что задачи разделяют некоторую 
базовую структуру, так что обмен информацией между ними уменьшает переобучение 
и улучшает predictive performance. 

Формально, пусть $\{(x_{t,i}, y_{t,i})\}_{i=1}^{n_t}$ обозначает обучающие данные для 
задачи $t \in \{1,\dots,T\}$, взятые из распределения $P_t$ над 
$\mathcal{X} \times \mathcal{Y}$. Цель~--- обучить дискриминативные функции 
$f_t : \mathcal{X} \to \mathcal{Y}$ для всех задач. Распространенный подход формулирует 
это как задачу регуляризованной минимизации эмпирического риска:
\begin{equation}
    \min_{f = (f_1,\ldots,f_T)} 
        \frac{1}{T} \sum_{t=1}^T \frac{1}{n_t} \sum_{i=1}^{n_t} 
            \ell(f_t(x_{t,i}), y_{t,i}) 
        + \lambda \, \Omega(f),
\end{equation}
где первое слагаемое~--- это средняя эмпирическая ошибка по задачам, а 
$\Omega(f)$~--- регуляризующее слагаемое, поощряющее обмен информацией. 

С теоретической точки зрения, преимущество MTL может быть интерпретировано как 
эффективное сокращение пространства гипотез за счет использования связанности задач, 
что приводит к более узким обобщающим границам.

Традиционные методы машинного обучения часто обучаются в однозадачной постановке. В отличие от этого, многозадачное обучение совместно обучается на нескольких задачах с целью улучшения общей производительности за счет использования общих представлений~\cite{anonymous2024}. Такая постановка особенно эффективна, когда задачи связаны, так как передача информации может уменьшить переобучение и улучшить обобщение. Кроме того, даже для одной целевой задачи вспомогательные задачи могут служить формой индуктивного смещения, помогая модели изучать более robust representations.

Центральный вопрос в многозадачном обучении, как и в стандартном обучении с учителем, 
заключается в том, насколько хорошо изученные функции обобщаются на новые данные. 
Границы обобщающей ошибки предоставляют теоретические гарантии, связывая 
истинный риск с его эмпирическим аналогом. В постановке MTL границы часто 
выводятся в рамках упомянутого выше подхода регуляризованной минимизации эмпирического риска. 

Пусть даны обучающие примеры $\{(X_1, Y_1), \ldots, (X_n, Y_n)\}$, взятые i.i.d. из 
неизвестного распределения $P$. Цель~--- обучить функцию $f \in \mathcal{F}$ 
с малой ожидаемой потерей $\mathbb{E}_{(X,Y) \sim P} [\ell(f(X), Y)]$. Поскольку $P$ 
неизвестно, обычно связывают этот риск со средним эмпирическим loss плюс 
слагаемое сложности, которое зависит от богатства гипотезного класса 
$\mathcal{F}$:
\begin{align}
    \mathbb{E}_{(X,Y) \sim P}[\ell(f(X), Y)] &\leq \frac{1}{n} \sum_{i=1}^{n} \ell(f(X_i), Y_i) \\
    &\quad + h\!\left(\text{complexity of }\mathcal{F}, n \right).
\end{align}

Среди различных мер сложности широко используется сложность Радемахера, так как она количественно определяет, насколько хорошо гипотезный класс может аппроксимируемым случайный шум.
Формально:

\begin{definition}[Сложность Радемахера]
    Пусть $\mathcal{G} := \{g : \mathcal{Z} \to \mathbb{R}\}$~--- гипотезный класс, 
    а $S := \{z_1, \ldots, z_n\}$~--- i.i.d. выборка из $P$. 
    Эмпирическая сложность Радемахера для $\mathcal{G}$ определяется как
    \[
    \widehat{R}(\mathcal{G}) := \mathbb{E}_{\sigma} \left[ 
        \sup_{g \in \mathcal{G}} \frac{1}{n} \sum_{i=1}^n \sigma_i g(z_i) \right],
    \]
    где $\sigma_i$~--- независимые случайные величины Радемахера, равномерно распределенные 
    в $\{\pm 1\}$. (Ожидаемая) сложность Радемахера определяется как
    \[
    R(\mathcal{G}) := \mathbb{E}_{S \sim P^n} \left[ \widehat{R}(\mathcal{G}) \right].
    \]
\end{definition}

Интуитивно, меньшая сложность Радемахера соответствует менее выразительному предсказаному классу, что, в свою очередь, приводит к более узким границам обобщения.
В данном исследовании, в противоположность сравнению различных типов границ, происходит сопоставление сложности модели в условиях многозадачного и однозадачного обучения.

Для эмпирической проверки нашего теоретического анализа сфокусируемся на задаче обнаружения 
машинно-генерированного текста. Эта задача требует высокой точности классификации с низкой частотой ложных 
срабатываний, чтобы избежать некорректного помечания контента, написанного человеком. Стремительное улучшение больших языковых моделей (LLMs) сделало 
тексты, сгенерированные ИИ, все более неотличимыми от написанных человеком ~\cite{zellers2019grover, solaiman2019gpt2}, 
создавая насущную потребность в robust методах обнаружения для сохранения академической честности и борьбы с дезинформацией. 

Большинство подходов рассматривают это как задачу бинарной классификации текста~\cite{jawahar2020automatic, uchendu2021authorship}. 
Тонкая настройка архитектур на основе Transformer стала доминирующим решением ~\cite{valiaiev2024detectionmachinegeneratedtextliterature}, 
демонстрируя высокую производительность, когда тестовые данные поступают из того же или близкородственного домена. 
Однако производительность часто резко падает при появлении новых доменов, делая модели менее надежными~\cite{anonymous2025}. 
Чтобы решить эту проблему, можно либо использовать более мощные модели, либо интегрировать дополнительную информацию 
о тексте, такую как его источник, домен или стилистические особенности. 
Эти сигналы могут выступать в качестве вспомогательных регуляризаторов, улучшая обобщение. 
Многозадачное обучение предоставляет естественную основу для объединения нескольких задач, 
включая интеграцию такой вспомогательной информации, 
при этом сохраняя основную цель классификации.

\subsection{Радамахеровская сложность многозадачного обучения в LoRa адаптарех}

Предполагается, что решается задачу классификации с использованием моделей с архитектурой Transformer~\cite{attention}.
Как упоминалось ранее, их тонкая настройка в режиме обучения с учителем является современным методом для задач классификации.

Анализ LoRA показывает, что минимизация эмпирического риска при параметризации LoRA 
остается согласованной с минимизацией истинного риска, гарантируя, что низкоранговая адаптация 
сохраняет асимптотические статистические гарантии полной тонкой настройки.

\begin{theorem}[Состоятельность]\label{theorem:consistency}
Пусть $\mathcal{D} = \{(X_i, c_i)\}_{i=1}^n$~--- независимые одинаково распределенные выборки из истинного распределения $P_{\mathrm{true}}$, 
где $c_i \in [N_c]$ обозначает метки классов. 
Предположим следующее:
\begin{enumerate}
    \item Существует параметр $\Theta^\star$ такой, что модель распределения 
    $P_{\mathrm{model}}(\cdot \mid \Theta)$ аппроксимирует истинное распределение 
    с минимальным расхождением Кульбака-Лейблера:
    \begin{equation}
    \label{eq:kl-opt}
    \Theta^\star \in \arg\min_{\Theta} D_{\mathrm{KL}}\big(P_{\mathrm{true}} \,\|\, P_{\mathrm{model}}(\cdot \mid \Theta)\big).
    \end{equation}

    \item При $n \to \infty$ эмпирическое распределение сходится по вероятности к $P_{\mathrm{true}}$.
    
    \item Функция потерь задается как отрицательное логарифмическое правдоподобие
    \begin{equation}
    \label{eq:loss}
        \mathscr{L}_n(\Theta) 
        = -\frac{1}{n} \sum_{i=1}^n \log \Big(P_{\Phi_0 + \Theta}\big(c_i \mid X_i\big)\Big),
    \end{equation}
    где $\Phi_0$~--- замороженные предобученные веса, а $\Theta$ соответствует 
    обучаемым низкоранговым параметрам в LoRA. 
    Предполагается, что $\mathcal{L}_n(\Theta)$ непрерывна и дифференцируема.
\end{enumerate}

Тогда минимизация эмпирического риска является состоятельной:
\begin{equation}
\label{eq:consistency}
\lim_{n \to \infty} \arg\min_{\Theta} \, \mathscr{L}_n(\Theta) = \Theta^\star.
\end{equation}
\end{theorem}
\begin{proof}
Пусть истинный риск и его эмпирический аналог определены как
\[
    L(\Theta) = \mathbb{E}_{(X,c)\sim P_{\mathrm{true}}}[\mathscr{L}(X,c;\Theta)], \quad \widehat{L}_n(\Theta) = \frac{1}{n}\sum_{i=1}^n \mathscr{L}(X_i,c_i;\Theta),
\]
где $\mathscr{L}(X_i,c_i;\Theta) = -\log P_{\Phi_0+\Theta}(c_i\mid X_i)$~--- отрицательное логарифмическое правдоподобие для отдельного примера.

В соответствии с равномерным законом больших чисел,
для непрерывной и ограниченной функции $\mathscr{L}$ имеем
\begin{equation}
    \sup_{\Theta}\big|\,L(\Theta)-\widehat{L}_n(\Theta)\,\big|\xrightarrow[n\to\infty]{p}0.
\label{eq:unif-conv}
\end{equation}
Следовательно, последовательность эмпирических рисков $\widehat{L}_n(\Theta)$ сходится равномерно 
к истинному риску $L(\Theta)$. Равномерная сходимость влечет состоятельность минимизации 
эмпирического риска, т.е.
\[
    \arg\min_{\Theta}\widehat{L}_n(\Theta)\xrightarrow[n\to\infty]{}\arg\min_{\Theta}L(\Theta).
\]

Из определения $L(\Theta)$ и с использованием тождества
\[
D_{\mathrm{KL}}\!\big(P_{\mathrm{true}}\|P_{\mathrm{model}}(\cdot\mid\Theta)\big)
= \mathbb{E}_{(X,c)\sim P_{\mathrm{true}}}
   \!\left[\log\frac{P_{\mathrm{true}}(c\mid X)}{P_{\mathrm{model}}(c\mid X;\Theta)}\right],
\]
минимизация ожидаемых потерь $L(\Theta)$ эквивалентна минимизации 
расхождения Кульбака-Лейблера между $P_{\mathrm{true}}$ и $P_{\mathrm{model}}(\cdot\mid\Theta)$.
Согласно Предположению (1), минимизатором этого расхождения является $\Theta^\star$. Следовательно,
\[
\lim_{n\to\infty}\arg\min_{\Theta}\widehat{L}_n(\Theta)
=\arg\min_{\Theta}L(\Theta)=\Theta^\star,
\]
что завершает доказательство.
\end{proof}

\begin{theorem}[Корректность при низкоранговых обновлениях]
\label{theorem:lowrank}
Предположим следующее:
\begin{enumerate}
    \item Выходной слой задается в виде
    \begin{equation}
    \label{eq:softmax}
        \hat{\mathbf{y}} = \operatorname{softmax}\!\left(W_{\mathrm{upd}}^{\top} \mathbf{x}\right),
    \end{equation}
    где $\mathbf{x} \in \mathbb{R}^d$~--- это вектор признаков BERT, 
    $W \in \mathbb{R}^{d \times k}$~--- замороженные предобученные веса, а 
    \begin{equation}
    \label{eq:update}
        W_{\mathrm{upd}} = W + \Delta W.
    \end{equation}

    \item Вместо непосредственного обучения $\Delta W \in \mathbb{R}^{d \times k}$, 
    обновление параметризуется в низкоранговой форме:
    \begin{equation}
    \label{eq:lora}
        \Delta W = A B, 
        \quad A \in \mathbb{R}^{d \times r},\; 
        B \in \mathbb{R}^{r \times k}, \;
        r \ll \min(d,k).
    \end{equation}

    \item Выполнены условия Теоремы~\ref{theorem:consistency}, т.е. модель остается статистически состоятельной при минимизации эмпирического риска.
\end{enumerate}

Тогда при параметризации~\eqref{eq:lora} 
выход модели $\hat{\mathbf{y}}$ сохраняется в том смысле, что 
низкоранговое обновление не искажает корректность классификационного слоя.
\end{theorem}
\begin{proof}
Пусть выходной слой определен как
\[
    \hat{\mathbf{y}} = \operatorname{softmax}\!\big(W_{\mathrm{upd}}^{\top}\mathbf{x}\big), \quad W_{\mathrm{upd}} = W + \Delta W,
\]
где $W \in \mathbb{R}^{d\times k}$~--- замороженные предобученные веса, а 
$\mathbf{x}\in\mathbb{R}^d$~--- вектор признаков энкодера. 
В силу дистрибутивности матричного сложения,
\[
    W_{\mathrm{upd}}^{\top}\mathbf{x} = W^{\top}\mathbf{x} + \Delta W^{\top}\mathbf{x}.
\]
Следовательно, предсказанные вероятности могут быть записаны как
\begin{equation}\label{eq:softmax-expanded}
    \hat{\mathbf{y}} = \frac{\exp\!\big(W^{\top}\mathbf{x} + \Delta W^{\top}\mathbf{x}\big)}      {\sum_{i=1}^{k}\exp\!\big((W^{\top}\mathbf{x} + \Delta W^{\top}\mathbf{x})_i\big)}.
\end{equation}

При параметризации LoRA $\Delta W = AB$ с 
$A\in\mathbb{R}^{d\times r}$ и $B\in\mathbb{R}^{r\times k}$, 
член обновления принимает вид
\[
    \Delta W^{\top}\mathbf{x} = (AB)^{\top}\mathbf{x} = B^{\top}(A^{\top}\mathbf{x}) \in \mathbb{R}^{k}.
\]
Это показывает, что низкоранговая форма лишь ограничивает $\Delta W$ 
рангом $r$ в подпространстве $\mathbb{R}^{d\times k}$, но не изменяет 
выходную размерность или отображение $\mathbf{x}\mapsto\hat{\mathbf{y}}$.
Логиты в~\eqref{eq:softmax-expanded} остаются хорошо определенными 
и дифференцируемыми для всех $\mathbf{x}$.

Более того, поскольку обновление $\Delta W$ изучается через минимизацию 
эмпирического риска, согласованную с Теоремой 1, 
результирующие параметры $(A,B)$ дают тот же минимизатор истинного 
ожидаемого риска, что и неограниченный $\Delta W$. Следовательно, 
низкоранговая параметризация сохраняет корректность выходного 
слоя в том смысле, что~$\hat{\mathbf{y}}_{\mathrm{LoRA}} = \operatorname{softmax}\!\big((W+AB)^{\top}\mathbf{x}\big)$ порождает то же решающее правило, что и~$\operatorname{softmax}\!\big((W+\Delta W)^{\top}\mathbf{x}\big)$.
Таким образом, введение модулей LoRA не искажает выходное распределение 
или классификационные границы модели.
\end{proof}

\begin{corollary}[LoRA с теоретическими гарантиями]
\label{corollary:lora}
Объединяя Теорему~\ref{theorem:consistency} и Теорему~\ref{theorem:lowrank}, 
мы получаем, что тонкая настройка на основе LoRA одновременно сохраняет:
\begin{enumerate}
    \item Статистическую состоятельность: минимизация эмпирического риска сходится к минимизатору истинного риска с ростом объема выборки;
    \item Корректность выходного слоя: низкоранговые обновления $AB$ не искажают выход классификации.
\end{enumerate}
Таким образом, адаптация с помощью LoRA наследует те же асимптотические гарантии, что и полная тонкая настройка, 
при этом требуя значительно меньшего количества обучаемых параметров.
\end{corollary}

Приведенные выше результаты показывают, что LoRA не ослабляет теоретические основы 
тонкой настройки. Со статистической точки зрения, метод сохраняет состоятельность: можно показать, что с увеличением количества обучающих примеров адаптированная модель сходится к тому же оптимальному решению, что и при полной тонкой настройке. 
С функциональной точки зрения, ограничение обновлений низкоранговым подпространством не искажает выход классификационного слоя. 
В совокупности эти свойства объясняют, почему LoRA достигает сопоставимой производительности с полной тонкой настройкой на практике, будучи при этом существенно более эффективной.

Проанализируем, как многозадачное обучение влияет на сложность обобщения для каждой задачи.
В частности, сравнимм однозадачное обучение модели на основе Transformer с MTL-подходом, использующим общий энкодер.
Предполагается, что архитектуры энкодера и головы идентичны и состоят из линейных слоев.
В случае STL присутствует единственная голова для целевой задачи, тогда как в настройке MTL вводятся дополнительные головы для связанных задач, обеспечивая неявную регуляризацию для целевой задачи.

Формально, в случаях STL и MTL гипотезные классы имеют вид:
\begin{align}
\mathcal{F}_{\mathrm{STL}}
&= \Big\{\, x \mapsto w_{\mathrm{head}}^\top \phi(x; w_{\mathrm{enc}}) \\
&\qquad \big|\, w_{\mathrm{enc}}\in\mathcal{W}_{\mathrm{enc}},\;
               w_{\mathrm{head}}\in\mathcal{W}_{\mathrm{head}} \Big\},
\\[4pt]
\mathcal{F}_{\mathrm{MTL}}
&= \Big\{\, (\,x \mapsto w_t^\top \phi(x; w_{\mathrm{shared}})\,)_{t=1}^T \\
&\qquad \big|\, w_{\mathrm{shared}}\in\mathcal{W}_{\mathrm{shared}},\;
               w_t\in\mathcal{W}_{\mathrm{head}} \Big\}.
\end{align}


\begin{theorem}[Сложность Радемахера на задачу при MTL]\label{thm:per-task-rc-fair-scaling}
Пусть $S_t=\{x_i\}_{i=1}^n$~--- выборка фиксированной целевой задачи $t$ с $\|x_i\|_2 \le R$.
Пусть $\phi(\cdot;w)$~--- энкодер, и рассмотрим линейные головы
$f_{w,h}(x)=h^\top \phi(x;w)$ с $\|h\|_2 \le B_{\mathrm{head}}$.
Предположим:
\begin{enumerate}
\item Ограничение на признаки: для всех $x,w$ 
$\|\phi(x;w)\|_2 \le L\,\|w\|\,\|x\|_2$.
\item Энкодер STL удовлетворяет $\|w_{\mathrm{enc}}\|\le B_{\mathrm{enc}}$,
общий энкодер MTL удовлетворяет $\|w_{\mathrm{shared}}\|\le B_{\mathrm{shared}}$.
\item Многозадачное масштабирование: $B_{\mathrm{shared}} \le B_{\mathrm{enc}}/\sqrt{T}$.
\end{enumerate}

Обозначим через $\widehat{\mathfrak R}_n(\cdot;S_t)$ эмпирическую сложность Радемахера на $S_t$.
Тогда
\begin{equation}\label{eq:mtl-vs-stl-rc}
    \widehat{\mathfrak R}_n\!\big(\mathcal{F}_{\mathrm{MTL}}^{(t)};S_t\big)
    \;\le\; \frac{1}{\sqrt{T}}\,
    \widehat{\mathfrak R}_n\!\big(\mathcal{F}_{\mathrm{STL}}^{(t)};S_t\big).
\end{equation}
\end{theorem}
\begin{proof}
Пусть $S_t = \{x_i\}_{i=1}^n$~--- выборка для целевой задачи $t$ с 
$\|x_i\|_2 \le R$. 
Для $B > 0$ определим гипотезный класс
\[
    \mathcal{F}(B)
    = \big\{\,x \mapsto h^\top \phi(x;w) 
    \;\big|\;
    \|h\|_2 \le B_{\mathrm{head}},\, \|w\|_2 \le B
    \big\}.
\]
Эмпирическая сложность Радемахера на $S_t$ равна
\[
    \widehat{\mathfrak R}_n(\mathcal{F}(B);S_t)
    = \frac{1}{n}\,\mathbb{E}_{\sigma}
      \sup_{\|h\|\le B_{\mathrm{head}},\,\|w\|\le B}
      \sum_{i=1}^n \sigma_i\, h^\top \phi(x_i;w),
\]
где $\sigma_i \in \{\pm1\}$~--- независимые одинаково распределенные величины Радемахера.

Для фиксированных $w$ и $\sigma$, по дуальности Коши-Буняковского,
\[
    \sup_{\|h\|\le B_{\mathrm{head}}}
    \sum_{i=1}^n \sigma_i\, h^\top \phi(x_i;w)
    = B_{\mathrm{head}}
      \Big\|\sum_{i=1}^n \sigma_i\, \phi(x_i;w)\Big\|_2.
\]
Следовательно,
\[
    \widehat{\mathfrak R}_n(\mathcal{F}(B);S_t)
    \le
    \frac{B_{\mathrm{head}}}{n}\,
    \mathbb{E}_{\sigma}
    \sup_{\|w\|\le B}
      \Big\|\sum_{i=1}^n \sigma_i\, \phi(x_i;w)\Big\|_2.
\]

По неравенствам Йенсена и Хинчина,
\[
    \mathbb{E}_{\sigma}
      \Big\|\sum_{i=1}^n \sigma_i\,a_i\Big\|_2
    \le
    \Big(\sum_{i=1}^n \|a_i\|_2^2\Big)^{1/2},
\]
что дает
\[
    \widehat{\mathfrak R}_n(\mathcal{F}(B);S_t)
    \le
    \frac{B_{\mathrm{head}}}{n}\,
    \sup_{\|w\|\le B}
      \Big(\sum_{i=1}^n \|\phi(x_i;w)\|_2^2\Big)^{1/2}.
\]

Используя ограничение на признаки $\|\phi(x;w)\|_2 \le L\,\|w\|_2\,\|x\|_2$ 
и $\|x_i\|_2 \le R$, получаем
\[
    \widehat{\mathfrak R}_n(\mathcal{F}(B);S_t)
    \le
    \frac{B_{\mathrm{head}}\,L\,R\,B}{\sqrt{n}}.
\]
Применяя это с $B=B_{\mathrm{enc}}$ для STL и $B=B_{\mathrm{shared}}$ для MTL, находим
\[
    \widehat{\mathfrak R}_n(\mathcal{F}(B_{\mathrm{shared}});S_t)
    \le
    \frac{B_{\mathrm{head}}\,L\,R\,B_{\mathrm{shared}}}{\sqrt{n}}
    \le
    \frac{1}{\sqrt{T}}\,
    \frac{B_{\mathrm{head}}\,L\,R\,B_{\mathrm{enc}}}{\sqrt{n}}
    =
    \frac{1}{\sqrt{T}}\,
    \widehat{\mathfrak R}_n(\mathcal{F}(B_{\mathrm{enc}});S_t),
\]
где последнее неравенство следует из предположения многозадачного масштабирования 
$B_{\mathrm{shared}}\le B_{\mathrm{enc}}/\sqrt{T}$.
\end{proof}

Полученный результат указывает на снижение эмпирической сложности Радемахера на задачу в $1/\sqrt{T}$ раз при справедливом масштабировании.
Это согласуется  с современными анализами многозадачного обучения, основанными на средних Радемахера, как показано в~\cite{maurer2006}. 

Однако отметим, что более ранняя работа~\cite{baxter2000} установила 
более сильное улучшение типа $1/T$ в другой постановке. 
В постановке Бакстера, количество задач $T$ само по себе способствует 
оценке общего индуктивного смещения: с ростом $T$ сложность данных 
на задачу уменьшается пропорционально $1/T$. 
В отличие от этого, наш анализ сохраняет размер выборки целевой задачи $n$ фиксированным и сравнивает STL и MTL на одном и том же $n$, поэтому улучшение проявляется как множитель $1/\sqrt{T}$ в сложности Радемахера на задачу.

Обе сложности на задачу оцениваются на одной и той же $S_t$ (размера $n$), поэтому общий множитель $1/\sqrt{n}$ сокращается; разница обусловлена бюджетом энкодера.
Более того, в анализе обеспечивается, чтобы обе модели STL и MTL обучались на одинаковом общем количестве примеров ($nT$). 
Для STL энкодер обучается на $nT$ примерах только из целевой задачи. 
Для MTL каждая из $T$ голов получает $n$ примеров из своей соответствующей задачи, так что общий энкодер видит те же самые $nT$ примеров, причем одна из голов соответствует целевой задаче. 
Это гарантирует, что наблюдаемое снижение сложности на задачу обусловлено совместным использованием параметров, а не неравными бюджетами данных.

Наш теоретический анализ установил, что LoRA сохраняет статистическую состоятельность полной тонкой настройки и поддерживает корректность выходного слоя, в то время как многозадачное обучение при соответствующем масштабировании снижает сложность Радемахера на задачу в $1/\sqrt{T}$ раз.
Вместе эти результаты показывают, что оба подхода сохраняют фундаментальные гарантии классической тонкой настройки, но достигают большей эффективности с точки зрения параметров (LoRA) или обобщения (MTL).


\section{Снижение сложности данных в задаче декодирования ФМРТ снимков}

Частота кадров $\nu \in \mathbb{R}$ и продолжительность $t \in \mathbb{R}$ видеопоследовательности задаются. Видеопоследовательность задается как
\begin{equation}
	\label{eq1}
	\mathbf{P} = [\mathbf{p}_1, \ldots, \mathbf{p}_{\nu t}], \quad\
	\mathbf{p}_{\ell} \in \mathbb{R}^{W \times H \times C},
\end{equation}
где $W$, $H$ и $C$~--- ширина, высота и количество каналов изображения соответственно.

Обозначим частоту фМРТ-изображений через $\mu \in \mathbb{R}$. Зададим последовательность изображений
\begin{equation}
	\label{eq2}
	\mathbf{S} = [\mathbf{s}_1, \ldots, \mathbf{s}_{\mu t}], \quad\
	\mathbf{s}_{\ell} \in \mathbb{R}^{X \times Y \times Z},
\end{equation}
где $X$, $Y$ и $Z$~--- размеры воксельного изображения.

Задача состоит в построении отображения, учитывающего задержку $\Delta t$ между фМРТ-изображением и видеопоследовательностью, а также предыдущие томографические данные. Формально необходимо найти такое отображение $\mathbf{g}$, что
\begin{equation}
	\label{eq3}
	\mathbf{g}(\mathbf{p}_1, \ldots, \mathbf{p}_{k_{\ell} - \nu \Delta t}; \mathbf{s}_1, \ldots, \mathbf{s}_{\ell-1}) = \mathbf{s}_{\ell}, \quad \ell = 1, \ldots, \mu t,
\end{equation}
где для $\ell$-го фМРТ-изображения номер соответствующего кадра $k_{\ell}$ определяется по формуле
\begin{equation}
	\label{eq4}
	k_{\ell} = \dfrac{\ell \cdot \nu}{\mu}.
\end{equation}

Схема предложенного метода реконструкции фМРТ-изображений показана на Рис.~\ref{fig:scheme}.

\begin{figure}[h!t]
	\centering
	\includegraphics[width=\textwidth]{thesis/figures/chapter-5/fmri/scheme}
	\caption{Схема метода декодирования ФМРТ}
	\label{fig:scheme}
\end{figure}

Обозначим фМРТ-изображение как $\mathbf{s}_{\ell} = [v^{\ell}_{ijk}] \in \mathbb{R}^{X \times Y \times Z}$, где $v^{\ell}_{ijk} \in \mathbb{R}_+$ — значение соответствующего вокселя.
Для сокращения времени работы метода предлагается использовать сжатие фМРТ-изображений путем снижения размерности.
Сжатие в 2 раза представляется в виде отображения
\[
    \boldsymbol{\chi}: \mathbb{R}^{X \times Y \times Z} \to \mathbb{R}^{X/2 \times Y/2 \times Z/2}.
\]
Сжатие в $2^k$ раз получается последовательным применением $\boldsymbol{\chi}$ $k$ раз.
В дальнейшем для простоты сохраняем обозначения размерностей изображения $X \times Y \times Z$.

Предположим, что для последовательности снимков выполняется свойство Маркова, т.е. каждый снимок зависит только от одного изображения и предыдущего снимка. Тогда соответствующее отображение записывается в виде
\begin{equation}
	\label{eq5}
	\mathbf{g}(\mathbf{p}_{k_{\ell} - \nu \Delta t}) = \mathbf{s}_{\ell} - \mathbf{s}_{\ell-1} = \boldsymbol{\delta}_{\ell}, \quad \ell = 2, \ldots, \mu t.
\end{equation}
где $\boldsymbol{\delta}_{\ell} = [v^{\ell}_{ijk} - v^{\ell-1}_{ijk}] = [\delta^{\ell}_{ijk}] \in \mathbb{R}^{X \times Y \times Z}$~--- разность двух последовательных снимков.

Отображение $\mathbf{g}: \mathbf{P} \to \mathbf{S}$ представляется как композиция двух других:
\[
    \mathbf{g} = \boldsymbol{\varphi} \circ \boldsymbol{\psi},
\]
где
\begin{align}
	 & \boldsymbol{\psi}: \mathbf{P} \to \mathbb{R}^d
	\text{~--- векторизация изображения,}        \\
	 & \boldsymbol{\varphi}: \mathbb{R}^d \to \mathbf{S}
	\text{~--- целевое отображение.}
\end{align}

Для каждого изображения из видеопоследовательности имеем вектор внедрения размерности $d$:
\[
    \mathbf{x}_{\ell} = [x^{\ell}_1, \ldots, x^{\ell}_{d}]^\top \in \mathbb{R}^{d}, \quad {\ell} = 1, \ldots, \nu t.
\]
Используется архитектура нейронной сети ResNet152 без последнего линейного слоя.

При заданном $k_{\ell} = \ell \cdot \nu / \mu$ общее количество пар (изображение, снимок) составляет $N = \mu (t - \Delta t)$. Таким образом, для каждого вокселя задана выборка
\[
    \mathfrak{D}_{ijk} = \{(\mathbf{x}_{\ell}, \delta^{\ell}_{ijk}) \ | \ {\ell} = 2, \ldots, N \}.
\]

Ставится задача регрессии
\begin{equation}\label{eq6}
	y_{ijk}: \mathbb{R}^{d} \to \mathbb{R}.
\end{equation}

Используется линейная модель с вектором параметров
\[
    \mathbf{w}_{ijk} = [w^{ijk}_1, \ldots, w^{ijk}_{d}]^\top \in \mathbb{R}^{d}:
\]
\begin{equation}
	\label{eq7}
	f_{ijk}(\mathbf{x}, \mathbf{w}_{ijk}) = \langle \mathbf{x}, \mathbf{w}_{ijk} \rangle.
\end{equation}

Для модели $f_{ijk}$ с соответствующим вектором параметров $\mathbf{w}_{ijk} \in \mathbb{R}^{d}$ определим квадратичную функцию потерь с $L_2$-регуляризацией:
\begin{equation}
	\label{eq8}
	\mathcal{L}_{ijk}(\mathbf{w}_{ijk}) = \sum\limits_{\ell = 2}^{N} \big(f_{ijk}(\mathbf{x}_{\ell}, \mathbf{w}_{ijk}) - \delta^{\ell}_{ijk}\big)^2 + \alpha \| \mathbf{w}_{ijk} \|_2^2,
\end{equation}
где $\alpha \in \mathbb{R}$~--- коэффициент регуляризации.

Требуется найти параметры, доставляющие минимум функционалу потерь $\mathcal{L}_{ijk}(\mathbf{w}_{ijk})$ при заданных гиперпараметрах $\Delta t$ и $\alpha$:
\begin{equation}
	\label{eq9}
	\hat{\mathbf{w}}_{ijk} = \arg\min_{\mathbf{w}_{ijk}} \mathcal{L}_{ijk}(\mathbf{w}_{ijk}).
\end{equation}

Минимум функции потерь находится методом наименьших квадратов. Определим матрицу объектов-признаков
\begin{equation}
	\label{eq10}
	\mathbf{X} = [\mathbf{x}_2, \ldots, \mathbf{x}_N]^\top = [x^i_j] \in \mathbb{R}^{(N-1) \times d}
\end{equation}
и вектор, компонентами которого являются разности значений одного и того же вокселя на разных изображениях,
\begin{equation}
	\label{eq11}
	\mathbf{\Delta}_{ijk} = [\delta^2_{ijk}, \ldots, \delta^N_{ijk}]^\top \in \mathbb{R}^{N-1}.
\end{equation}

Решение записывается в виде
\begin{equation}
	\label{eq12}
	\hat{\mathbf{w}}_{ijk} = (\mathbf{X}^\top \mathbf{X} + \alpha \mathbf{I})^{-1} \mathbf{X}^\top \mathbf{\Delta}_{ijk}.
\end{equation}

Получим формулу для восстановленных фМРТ-изображений. Введем матрицу весов
\begin{equation}
	\label{eq13}
	\hat{\mathbf{W}} = [\hat{\mathbf{w}}_1, \ldots, \hat{\mathbf{w}}_{XYZ}]^\top = [\hat{w}^i_j] \in \mathbb{R}^{XYZ \times d}.
\end{equation}

Введем для тензоров $\mathbf{s}_{\ell}, \boldsymbol{\delta}_{\ell} \in \mathbb{R}^{X \times Y \times Z}$ векторы
\[ \mathbf{s}_{\ell}^{R} = [ v^{\ell}_1, \ldots, v^{\ell}_{XYZ} ]^\top,\
	\boldsymbol{\delta}_{\ell}^{R} = [ \delta^{\ell}_1, \ldots, \delta^{\ell}_{XYZ} ]^\top \in \mathbb{R}^{XYZ}. \]

Тогда вектор прогнозируемого изображения находится по формуле
\begin{equation}
	\label{eq14}
	\hat{\mathbf{s}}_{\ell}^{R} = \mathbf{s}_{\ell-1}^{R} + \hat{\boldsymbol{\delta}}_{\ell}^{R} = \mathbf{s}_{\ell-1}^{R} + \hat{\mathbf{W}} \mathbf{x}_{\ell}.
\end{equation}

\section{Качество данных в задаче детекции машинной генерации}
Появилось огромное количество AI-детекторов и коллекций с AI-фрагментами, и несколько методов детекции даже показали качество распознавания до 99,9\% согласно целевым метрикам в таких коллекциях.
Однако качество таких детекторов часто резко падает в реальных условиях, что ставит вопрос: действительно ли детекторы высоконадежны или их высокие бенчмарк-показатели связаны с низким качеством оценочных наборов данных?
Подчеркнем необходимость создания надежных и качественных методов оценки сгенерированных данных, которые были бы устойчивы к смещениям и низкой способности к обобщению будущих моделей.посвященных детекции AI-генерированного контента, и предлагаем методы оценки качества наборов данных, содержащих AI-фрагменты.

Предлагается оценить различные наборы данных с едиными настройками, чтобы увидеть, насколько хорошо стандартные подходы работают на них.
Целью исследования является не достичь максимальных показателей, а сравнить производительность одного и того же метода на разных наборах данных.

\paragraph{Базовые методы.} Для методов, основанных на возмущениях, использовался фреймворк DetectGPT с GPT-2~\cite{radford2019language} в качестве базовой модели и T5-Large \cite{t5} в качестве генератора возмущений.
Однако из-за высоких вычислительных затрат DetectGPT использовался Fast-DetectGPT~\cite{fast-detectgpt}, который заменяет этап возмущения в DetectGPT более эффективным этапом сэмплирования.
Для методов zero-shot использовался Binoculars~\cite{hans2024spotting} с улучшенной оценкой перплексии.
Эти два базовых метода не требуют тонкой настройки, что является важным аспектом для задачи детекции, поскольку обучать детектор для каждого домена и генератора непрактично.
Наконец, в качестве метода на основе энкодера использовалась модель
mDeBERTa~\cite{he2021deberta}, которая является современной моделью для детекции машинно-генерированного текста в мультиязычном контексте~\cite{macko-etal-2023-multitude}.
Эти три детектора, охватывают все основные категории детекторов.

\paragraph{Топологическая статистика.} В работе \cite{Tulchinskii_phd} было показано, что если рассмотреть внутреннюю размерность многообразия на множестве эмбеддингов, то можно отделить тексты, написанные человеком, от машинно-сгенерированных.
Авторы использовали размерность персистентной гомологии (англ. PHD) и показали, что статистически тексты, сгенерированные человеком, имеют более высокую PHD, чем машинно-сгенерированные тексты, предложив таким образом новый детектор.
Дополнительно, в ~\cite{kushnareva2024boundary} было предложено вычислять PHD внутри скользящего окна.
Эти внутренние размерности текста в пределах скользящего окна могут быть использованы в качестве признака для детекторов.
Авторы демонстрируют, что метрика устойчива к изменению домена и генераторов.
Чтобы иметь возможность сравнивать наборы данных между собой, разработана симметричная оценка, используящая KL-дивергенцию.
Пусть $h_d$, $m_d$~--- распределения внутренних размерностей для двух типов текстов из одного набора данных, человеческого и машинного происхождения, тогда наша оценка $\text{KL}_{\text{TTS}}$ выглядит следующим образом:
\[
    \text{KL}_{\text{TTS}} (h_d, m_d) = | D_{\text{KL}}(h_d || m_d) - D_{\text{KL}}(m_d || h_d) |
\]
Чем ниже эта оценка, тем ближе друг к другу $h_d$ и $m_d$, что означает почти неразличимые тексты, и наоборот.

\paragraph{Возмущения и перемешивание.} Основываясь на результатах исследований модификации текста~\cite{sadasivan2024can, mitchell2023detectgpt}, которые показывают, как небольшие возмущения влияют на системы машинного понимания текста, рассмотривается этот способ как возможный метод оценки качества набора данных.
Ключевая идея заключается в том, что ИИ-модели чувствительны к таким адверсарным изменениям, в отличие от людей.
Рассматриваются две модификации: Адверсарное возмущение токенов и перемешивание предложений.

В этом подходе текст разбивается на токены и случайным образом заменяем токен на синоним из коллекции WordNet~\cite{wordnet} с вероятностью 70\%.
Далее применяя такую технику к каждому представленному классу, и используя модель-энкодер, получаются эмбеддинги для каждого из текстов в текущем наборе данных.
Наконец, измеряя средние сдвиги эмбеддингов для классов человеческих и сгенерированных тексто, получаем сдвиги эмбеддингов, используя косинусное расстояние между эмбеддингами исходных текстов и модифицированных. В итоге, после модификаций получаем $\Delta_{\text{shift}}$~--- логарифм разности средних сдвигов эмбеддингов.
\[
    \Delta_{\text{shift}} = \log \frac{{\frac{1}{n} \sum_{i=1}^{n} \text{cos}_d(h_{h_i}^o, h_{h_i}^p)}}{{\frac{1}{m}\sum_{j=1}^{m} \text{cos}_d(h_{m_j}^o, h_{m_j}^p)}},
\]
где~$n$ и~$m$~--- количество примеров в человеческой и сгенерированной частях набора данных соответственно, $h_{h_i}^o$~--- эмбеддинг $i$-го фрагмента человеческой части данных, $h_{h_i}^p$~--- тот же эмбеддинг после пертурбации. Аналогично, $h_{m_i}^o$ и $h_{m_i}^p$~--- эмбеддинги для машинно-сгенерированных текстов.
Функция $\text{cos}_d$ измеряет косинусное расстояние между двумя векторами.

В этом подходе случайным образом предложения меняются местами, влияя таким образом на связность текста.
Разделяя фрагмент на предложения и случайным образом изменяя порядок 70\% выбранных предложений, эта техника применяется  к каждому представленному классу. Затем, используя модель кодирования текста, получаются эмбеддинги для каждого из текстов текущего набора данных.
Наконец, происходит измерение сдвига эмбеддингов для класса человеческих и сгенерированных текстов, а затем преобразуем сдвиги в распределения, подобные вероятностным.
Это в итоге приводит к~$\text{KL}_{\text{shuffle}}(H,M)$~--- дивергенции Кульбака-Лейблера между сдвигами человеческих и сгенерированных текстов.
\[
    \text{KL}_{\text{shuffle}}(H,M)= \sum_{i} H(i) \log \frac{H(i)}{M(i)},
\]
\[
    H(i) = \frac{\text{cos}_d(h_{h_i}^o, h_{h_i}^p) + \epsilon}{\sum_j \left(\text{cos}_d(h_{h_j}^o, h_{h_j}^p) + \epsilon\right)},
\]
где $M(i)$ имеет ту же структуру, что и $H(i)$, за исключением того, что вместо текстов человеческого класса используются тексты сгенерированного класса, $\epsilon$~--- малая константа, добавляемая для избежания деления на ноль.

\section{Результаты вычислительных экспериментов}

\subsection{Сложность моделей в многозадачном обучении}

\begin{figure}[ht]
  \centering
    \includegraphics[width=0.75\linewidth]{thesis/figures/chapter-5/rademacher/lora_rank_vs_f1-1.pdf}
    \caption{Метрика $F_{1}$ модели DeBERTa-v3-base с адаптацией LoRA при различных рангах $r \in \{8, 16, 32\}$ в пробном запуске. Наилучшая производительность достигается при $r=8$, что указывает на снижение отдачи при увеличении ранга.}
    \label{fig:r_vs_f1}
\label{fig:lora_rank}
\end{figure}

Для эмпирической проверки теоретических свойств, установленных выше, рассматривается задача обнаружения машинно-генерированного текста. 
Данная задача формулируется как проблема бинарной классификации (текст, написанный человеком, против сгенерированного ИИ), 
что служит компактным, но информативным эталоном для оценки как прогнозной производительности, так и эффективности обучения.

Набор данных GenAI Detection Challenge (COLING~2025, Task~1), представленный в~\cite{wang2025genaicontentdetectiontask}. 
Из исходных 600 000 примеров выбирается 60 000 для обучения и 5 000 для тестирования, сохраняя распределение меток. 
Набор данных охватывает широкий спектр доменов: внутрираспределительные категории, такие как финансы, право, психология, новости и медицина, а также внераспределительные категории, такие как эссе IELTS, научные статьи, биомедицинские аннотации и юридические статьи. 
Результаты предыдущих соревнований указывают на то, что стандартные методы тонкой настройки struggle для достижения сильного обобщения на этом гетерогенном тестовом наборе, подчеркивая необходимость более эффективных стратегий адаптации.

В наших экспериментах фиксируется энкодер как DeBERTa-base~\cite{he2023debertav3improvingdebertausing}, который продемонстрировал высокую производительность в недавних задачах классификации текста. 
Для анализа качества рассматривается точность (accuracy), точность (precision), полнота (recall), F1-мера, потеря на валидации и общее время обучения (wall-clock training time).

Для эмпирической проверки гарантии корректности для моделей Transformer с добавлением LoRA (Теорема~\ref{theorem:lowrank}) сравнивается DeBERTa-v3-base в двух режимах тонкой настройки: полная тонкая настройка всех параметров и адаптация с помощью LoRA.
Цели эксперимента: (i) подтвердить, что LoRA сохраняет прогнозную корректность, существенно сокращая сложность параметров, и 
(ii) проверить, что теоретические выгоды в эффективности транслируются в сокращение времени обучения. 
Все условия обучения сохраняются идентичными, а полные детали гиперпараметров приведены в дополнительных материалах.

При полной тонкой настройке обновляются все параметры DeBERTa-v3-base.
Для LoRA исходные веса замораживаются, а низкоранговые адаптеры вставляются в каждый блок Transformer с рангом $r=8$, коэффициентом масштабирования $\alpha=32$ и долей отсева (dropout) для адаптеров $0.1$. 
Эта конфигурация была выбрана после дополнительного анализа чувствительности к рангу, представленного на Рисунке~\ref{fig:lora_rank}.

Результаты суммированы в Таблице~\ref{tab:combined}. 
По сравнению с полной тонкой настройкой, LoRA демонстрирует лишь незначительное снижение прогнозных метрик (1.4–3.2\%), при этом обеспечивая существенно более низкие потери на валидации (снижение на 0.657, или 36.3\%).
В сочетании с дополнительной диагностикой в дополнительных материалах, показывающей более гладкие нормы градиентов и траектории потерь при обучении, это свидетельствует о более стабильной сходимости и большей эмпирической устойчивости LoRA по сравнению с полной тонкой настройкой.
Эти находки согласуются с нашей теоретической гарантией о том, что низкоранговые обновления сохраняют корректность выходного слоя.
Для оценки вычислительной эффективности также рассматривается общее время обучения.
LoRA обеспечивает ускорение в 12.6\%, что указывает на то, что низкоранговая адаптация снижает эффективную сложность и ускоряет оптимизацию при незначительной потере в метриках, основанных на точности.

\begin{table}[h!t]
    \caption{Относительное сравнение DeBERTa-v3-base и LoRA адаптеров. Приведенные изменения отражают относительную разницу показателей LoRA по сравнению с базовой полной тонкой настройкой, нормированную на значение базового показателя.}
    \label{tab:combined}
    \centering
    \begin{tabular}{l c c c} 
    \toprule
    Metric & DeBERTa & DeBERTa \& LoRA & Change (\%) \\
    \midrule
    Accuracy $\uparrow$        & 0.7104 & 0.6876 & $-3.2$ \\
    Precision $\uparrow$      & 0.6573 & 0.6413 & $-2.4$ \\
    Recall $\uparrow$         & 0.9608 & 0.9470 & $-1.4$ \\
    $F_{1}$-score $\uparrow$  & 0.7806 & 0.7648 & $-2.0$ \\
    \midrule
    Validation Loss $\downarrow$ & 1.8094 & \textbf{1.1522} & $+36.3$ \\
    Training Time (s) $\downarrow$ & 5570 & \textbf{4867} & $+12.6$ \\
    \bottomrule
    \end{tabular}
\end{table}

Задача GenAI Detection предоставляет, помимо бинарной метки (человек vs. сгенерированный ИИ), вспомогательные метаданные, такие как поддомен и источник benchmark.
Эта информация используется для создания многозадачной постановки с тремя выходными головками: исходная задача бинарной классификации и две вспомогательные многоклассовые задачи.
Такая конфигурация побуждает модель изучать более богатые текстовые представления и отражает теоретическое преимущество MTL в снижении сложности на задачу.

Мотивированные нашим аналитическим результатом об эффективности Радемахера (Теорема~\ref{thm:per-task-rc-fair-scaling}), происходит адаптация~DeBERTa-base для выполнения необходимых предположений.
Обеспечивается: (i) ограничения нормы весов через проецирование параметров на $L_2$-шары после каждого обновления; (ii) липшицева непрерывность с помощью спектральной нормализации всех линейных слоев; и (iii) ограниченность входов через нормализацию токенных эмбеддингов.
Эти модификации гарантируют, что эмпирическая установка соответствует теоретическим условиям, позволяя проводить валидную оценку преимуществ MTL в рамках установленной схемы.
Подробный процесс подготовки модели описан в дополнительных материалах.

Для начала оценивается прогнозная производительность в условиях STL и MTL.
Происходит обучение двух вариантов: (i) базовый STL-модель с частичной тонкой настройкой энкодера и классификационной головой, и (ii) MTL-модель с общим энкодером, обновляемым совместно по всем трем задачам.
На этапе тестирования для MTL-модели используется только общий энкодер и бинарная голова, отбрасывая вспомогательные головы.
Результаты в Таблице~\ref{tab:stl-mtl-performance-erc} показывают, что включение вспомогательных задач в процесс обучения улучшает точность на исходной бинарной задаче, подтверждая, что многозадачные сигналы действуют как полезное индуктивное смещение.

\begin{table}[t]
    \caption{Производительность и эмпирическая сложность Радемахера (ERC) модели DeBERTa-v3-base в условиях STL и MTL для задачи бинарной классификации GenAI Detection.}
    \label{tab:stl-mtl-performance-erc}
    \begin{center}
    \begin{tabular}{@{}lccccc@{}}
    \toprule
    Model & Mode & F1 $\uparrow$ & ROC--AUC $\uparrow$ & Acc. $\uparrow$ & ERC $\downarrow$ \\
    \midrule
    DeBERTa & STL & 0.781 & 0.788 & 0.710 & $0.0159 \pm 0.0009$ \\
    DeBERTa & MTL & \textbf{0.826} & \textbf{0.834} & \textbf{0.781} & $\mathbf{0.0111} \pm \mathbf{0.0010}$ \\
    \bottomrule
    \end{tabular}
    \end{center}
\end{table}

Далее, для оценки не только прогнозные улучшения, но и сложность модели на целевой задаче, происходит сравнение эмпирической сложности Радемахера (ERC) напрямую. 
В соответствии с определением, ERC измеряется на тех же данных, что использовались для обучения, после замены истинных меток случайным шумом.
Это гарантирует, что оценка отражает только емкость гипотезного класса, а не информацию о реальных метках.
После обучения ERC оценивается исключительно для целевой задачи как для STL, так и для MTL.
Результаты представлены в колонке ERC в Таблице~\ref{tab:stl-mtl-performance-erc}.
Более подробное описание процесса проведения обоих экспериментов приведено в дополнительных материалах.

Можно видеть, что MTL не только улучшает прогнозную производительность, но и достигает более низкой эмпирической сложности Радемахера по сравнению с STL.
Это демонстрирует, что вспомогательные задачи обеспечивают полезное индуктивное смещение, которое как улучшает обобщающую способность на целевой задаче, так и эффективно снижает сложность на задачу, что согласуется с предсказанным снижением на $1/\sqrt{T}$ из нашего теоретического анализа.

\begin{table}[h!t]
  \centering
  \caption{Сравнение моделей DeBERTa base и DeBERTa \& LoRA (5 эпох).}
  \label{tab:models_comparison}
  \begin{tabular}{lccccc}
    \toprule
    Model & Loss & Grad. Norm & Runtime (s) & Params & Epochs \\
    \midrule
    Full Tuning & 0.3058 & 24.65 & 679{,}660 & 184M (100\%) & 5 \\
    LoRA ($r=8$) & 0.2972 & 17.41 & 700{,}284 & 296{,}450 ($\approx$0.16\%) & 5 \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[h!t]
  \centering
  \caption{Сравнение конфигураций LoRA с различными рангами ($r$) для модели DeBERTa-v3-base.}
  \label{tab:lora_rank}
  \begin{tabular}{lccc}
    \toprule
    \textbf{Rank ($r$)} & Loss & Grad. Norm & Runtime (s) \\
    \midrule
    8  & 0.3413 & 2.95 & 1681 \\
    16 & 0.3358 & 5.18 & 1684 \\
    32 & 0.3194 & 2.55 & 1688 \\
    \bottomrule
  \end{tabular}
\end{table}

Все исходные параметры DeBERTa были заморожены, а низкоранговые адаптерные модули были вставлены в каждый блок трансформера.
Ранг адаптера выбран~$r=8$, коэффициент масштабирования $\alpha=32$ и использовался dropout $0.1$ в слоях адаптера.
Данная конфигурация выбрана как наиболее эффективная после проведения поиска по сетке для $r=\{8, 16, 32\}$.
Это оставляет обучаемыми только 296 450 параметров из 184 млн общих ($\approx0.16\%$), что согласуется с теоретической мотивацией снижения размерности.
Все конфигурации экспериментов указаны в Таблице~\ref{tab:models_comparison}.

Кроме того, на Рисунке~\ref{fig:combined} наблюдается производительность модели: модели DeBERTa и DeBERTa~\&~LoRA обучались в течение 5 эпох с размороженными 6 слоями из 12.
Заметим, что норма градиента является значительно более гладкой для модели, использующей LoRA, по сравнению с моделью без нее.
Тот же эффект наблюдается на графике функции потерь обучения: потери при обучении модели с LoRA являются более гладкими и сходятся быстрее, чем у модели без нее.

Для определения оптимального ранга адаптера сравнивается~$r=8, 16, 32$ с точки зрения потерь при обучении, представленных на Рисунке~\ref{fig:r_vs_loss}.
Хотя более высокие ранги, в частности $r=32$, демонстрировали более быструю сходимость и более низкие финальные потери при обучении, $r=8$ обеспечивает лучшее обобщение, несмотря на более медленную сходимость.
В целом, $r=8$ был выбран в качестве наиболее эффективной конфигурации в текущей настройке. Конфигурации экспериментов показаны в Таблице~\ref{tab:lora_rank}.

Из аналитических результатов об эффективности Радемахера, происходит адаптация~\texttt{DeBERTa-base} для выполнения необходимых предположений.
Введенные модификации гарантируют, что эмпирическая установка соответствует теоретическим условиям, позволяя провести валидную оценку преимуществ MTL в рамках установленной схемы.
Подробный процесс подготовки описан в Алгоритме~\ref{alg:theorem-constraints}.

\begin{algorithm}[h!t]
    \caption{Обеспечение условий теоремы для оценки ERC с использованием DeBERTa}\label{alg:theorem-constraints}
    \KwIn{Модель $f_t(x) = w_t^\top \phi(x; w_{\text{shared}})$, с ограничениями~$B_{\text{shared}}, B_{\text{head}}, R$}
    \KwOut{Модель удовлетворяющая условиям теоремы~\ref{thm:per-task-rc-fair-scaling}.}
    \ForEach{linear layer $W$ in encoder $\phi(\cdot; w_{\text{shared}})$}{
        $W \leftarrow \text{SpectralNorm}(W)$ \tcp*{$\|\phi(x;w)\|_2 \leq L\|w\|\|x\|_2$}
    }
    \ForEach{input sequence $x = [x_1 \dots x_m]$}{
        $\widetilde{x}_i \leftarrow x_i / \max(1, \|x_i\|_2) \quad \forall i$
        $x \leftarrow \left[\widetilde{x}_1 \dots \widetilde{x}_m\right] \cdot \min\left(1, \frac{R}{\|\widetilde{x}\|_F}\right)$ \tcp*{$\|x\| \leq R$}
    }
    \ForEach{training step}{
        \ForEach{parameter group $(w, B)$ in $\{(w_{\text{shared}}, B_{\text{shared}})\} \cup \{(w_t, B_{\text{head}}) \mid t \in [T]\}$}{
            $w \leftarrow w \cdot \min\left(1, \dfrac{B}{\|w\|_2}\right)$ \tcp*{$\|w\|_2 \leq B$}
        }
    }
\end{algorithm}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{thesis/figures/chapter-5/rademacher/r_vs_loss.png}
    \caption{Сравнение потерь при обучении для различных рангов LoRA ($r=8$–$16$–$32$).}
    \label{fig:r_vs_loss}
\end{figure}

\begin{figure}[htbp]
    \centering
    \subfloat[Норма градиента]{\includegraphics[width=0.75\textwidth]{thesis/figures/chapter-5/rademacher/Gradient_norm.png}}\\
    \subfloat[Ошибка на обучающей выборке]{\includegraphics[width=0.75\textwidth]{thesis/figures/chapter-5/rademacher/Loss.png}}\\
    \caption{Сравнение производительности моделей с использованием DeBERTa и LoRA. Динамика нормы градиента и потерь при обучении в течение 5 эпох для моделей DeBERTa и DeBERTa~\&~LoRA с шестью размороженными слоями трансформера.}
    \label{fig:combined}
\end{figure}

Для оценки ERC обучается как STL, так и MTL модели в контролируемых и сопоставимых условиях.
В обоих случаях использовалось одинаковое общее количество обучающих примеров (\(nT\)), что гарантирует, что любые наблюдаемые различия в ERC вызваны совместным использованием параметров, а не дисбалансом данных.

В эксперименте STL использовался энкодер \texttt{DeBERTa-v3-base} с одной бинарной классификационной головой, соответствующей целевой задаче (бинарная классификация).
Модель обучалась на \(nT = 90{,}000\) примерах (\(n = 30{,}000\), \(T = 3\)), выбранных исключительно из набора данных целевой бинарной классификации (текст, написанный человеком, против сгенерированного ИИ).
Чтобы гарантировать, что ERC отражает репрезентационную способность модели, а не ее соответствие истинному распределению меток, все целевые метки были заменены случайным шумом из \(\{-1, 1\}\).
Энкодер и классификационная головка подвергались тонкой настройке на этих зашумленных метках в течение $num\_epochs = 3$ эпох.
После обучения ERC вычислялась на том же наборе данных со случайными метками.

В настройке MTL использовался тот же энкодер DeBERTa-v3-base, разделяемый между \(T=3\) классификационными головками.
Одна головка соответствовала целевой бинарной задаче (с метками, замененными случайным шумом, как указано выше), в то время как две другие обучались на вспомогательных многоклассовых задачах: (a) предсказание поддомена с 5 классами (набор HC3) и (b) предсказание поддомена с 6 классами (набор M4GT).
Каждая задача предоставляла \(n = 30{,}000\) примеров, так что общий энкодер обрабатывал в сумме \(nT = 90{,}000\) обучающих примеров.
Только вспомогательные задачи использовали свои исходные метки; целевая задача использовала зашумленные метки для обеспечения независимости от емкости модели.
После обучения ERC оценивалась только на подмножестве целевой задачи (со случайными метками).

Данная процедура гарантирует, что как STL, так и MTL модели обучались в идентичных условиях по объему данных и вычислительным ресурсам.
Следовательно, наблюдаемое снижение ERC типа \(1/\sqrt{T}\) непосредственно количественно оценивает эффект совместного использования параметров энкодера на эффективную емкость модели.

\subsection{Снижение сложности данных в задаче декодирования ФМРТ снимков}
Для анализа производительности предложенного метода и проверки гипотез был проведен вычислительный эксперимент.
В качестве данных использовалась выборка, представленная в~\cite{Berezutskaya2022}.
Набор данных содержит результаты обследования 63 испытуемых.
Для тридцати из них известны данные фМРТ.
В выборке 16 мужчин и 14 женщин в возрасте от 7 до 47 лет.
Средний возраст испытуемых составляет 22 года.
Характеристики выборки: продолжительность обследования,
частоты кадров видеопоследовательностей фМРТ и изображений, а также их размеры суммированы в Таблице~\ref{table:sample}.

\begin{table}[h!t]\center
    \caption{Описание выборки для тестирования снижения размерности ФМРТ снимков в задаче декодирования}\label{table:sample}
    \begin{tabular}{@{}ccc@{}}
    \toprule
    Name & Notation & Value \\ 
    \midrule
    Duration of examination & $t$ & 390 s \\
    Video frame rate & $\nu$ & 25 Hz \\
    fMRI frame rate & $\mu$ & 1.64 Hz \\
    Video dimensions & $W, H, C$ & 640, 480, 3 \\
    fMRI dimensions & $X, Y, Z$ & 40, 64, 64 \\
    \bottomrule
    \end{tabular}
\end{table}

Выборка разделена на обучающую и тестовую части в соотношении 70\% и 30\% соответственно.
Критерием качества реконструкции фМРТ-изображений является MSE~--- сумма квадратов отклонений между истинными и реконструированными изображениями, усредненная по всем вокселям каждого изображения из тестовой выборки.

Для сокращения времени работы алгоритма фМРТ-изображение предварительно сжимается с использованием слоя MaxPool3D. Рассматриваются коэффициенты сжатия 1, 2, 4 и 8.
Значения вокселей нормализованы к диапазону $[0; 1]$ с помощью процедуры MinMaxScale.

Была проанализирована зависимость MSE от параметра регуляризации $\alpha$.
Рассматривались коэффициенты сжатия 1, 2, 4 и 8.
Соответствующие графики показаны на Рис.~\ref{fig:mse-alpha}.
Для построения графика было выполнено усреднение по испытуемым.
Показаны границы стандартного отклонения.
Графики демонстрируют, что оптимальное значение коэффициента $\alpha \approx 1000$.
Форма кривой сохраняется независимо от коэффициента сжатия фМРТ-изображений.
\begin{figure}[h!t]\centering
	\includegraphics[width=0.65\textwidth]{thesis/figures/chapter-5/fmri/subs_MSE_alpha}
	\caption{Зависимость метрики MSE от параметра регуляризации $\alpha$ на изображениях из тестовой выборки.}
	\label{fig:mse-alpha}
\end{figure}

Сравнивается время обучения модели при использовании различных коэффициентов сжатия фМРТ-изображений. Рассматриваются коэффициенты 1, 2, 4 и 8.
Для каждого значения коэффициента сжатия вычисляется среднее значение времени обучения модели для всех испытуемых.
Результаты экспериментов представлены в Таблице~\ref{table:coeffs}.
Время работы метода существенно сокращается при использовании предварительного сжатия фМРТ-изображений.
Эксперимент с подбором оптимального коэффициента регуляризации подтверждает, что сжатие изображений не изменяет характер зависимостей.

\begin{table}[h!t]\center
    \caption{Зависимость времени обучения модели от коэффициента сжатия выборки ФМРТ снимков}\label{table:coeffs}
    \begin{tabular}{@{}ccc@{}}
    \toprule
    Compression coefficient & Mean time, s & Std, s \\
    \midrule
    1 & 36.3 & 6.1 \\
    2 & 6.7 & 0.5 \\
    4 & 1.6 & 0.1 \\
    8 & 1.4 & 0.3 \\
    \bottomrule
    \end{tabular}
\end{table}

\subsection{Качество данных в задаче детекции машинной генерации}
\begin{table}[h!t]\centering
    \begin{tabular}{c|c|c|c}
    \toprule    
        Dataset & DeBERTa & Binoculars & DetectGPT \\
    \midrule
        GPT-2 &  0.972 & 0.495 & 0.412\\ 
        HC3 & 0.998 &  0.931 & 0.972 \\
        GhostBuster & 0.910 &   0.683  &  0.711 \\
        MGTBench & 0.961 & 0.364 & 0.447 \\
        MAGE &  0.835 &  0.632 &  0.654 \\
        M4 & 0.987 &  0.871 &  0.881   \\
        OutFox & 0.901 & 0.692 & 0.707 \\
        TweepFake & 0.941 & 0.845 & 0.864 \\ 
    \midrule
        SemEval24 Mono & 0.991 & 0.913 & 0.924 \\
        SemEval24 Multi & 0.994 & -- & --\\
        RuATD & 0.765 & -- & -- \\
        DAGPap22 &  0.968 & 0.333 & 0.562 \\
        PAN24  & 0.826 &  0.411 & 0.890 \\
        AuTex23en & 0.941 & 0.783 & 0.911\\
        AuTex23es & 0.933 & -- & --\\
        IberAuTex & 0.964 & -- & --\\
        MGT-1 Mono & 0.904 & 0.665 & 0.683 \\
        MGT-1 Multi & 0.934 & -- & --\\
    \bottomrule    
    \end{tabular}
    \caption{Результаты классификации с различными детекторами, оцененные с помощью метрики $F_1$-score.}
    \label{tab:classifier}
\end{table}

\begin{table}[h!t]
    \centering
    \begin{tabular}{l|c|c|c|c|c}
    \toprule
        Dataset & $\text{KL}_{\text{TTS}}$ $\downarrow$ & $\text{PHD}_{\text{human}}$ & $\text{PHD}_{\text{machine}}$ &  $\Delta_{\text{shift}}$ $\downarrow$ &  $\text{KL}_\text{shuffle}$ $\downarrow$  \\
    \midrule
        GPT-2 & \textbf{0.014} & 9.23 $\pm$ 1.98 & 10.27 $\pm$ 1.84 &  0.084 & 1.255  \\
        HC3 & 0.053  & 8.76 $\pm$ 1.83 & 7.38 $\pm$ 1.05 & 0.264 &   1.167  \\
        GhostBuster & 0.053 & 9.84 $\pm$ 1.18 & 9.76 $\pm$ 1.15 & \textbf{0.024} &  \textbf{0.359}  \\
        MGTBench & 0.043  & 8.77 $\pm$ 1.31 & 9.97 $\pm$ 1.02 &  \textbf{0.031} &   \textbf{0.421} \\
        MAGE & \textbf{0.011}  & 9.8 $\pm$ 2.14 & 9.38 $\pm$ 3.04 & 0.094  & \textbf{0.310}  \\
        M4 & 0.036 & 7.26 $\pm$ 1.99 & 8.59 $\pm$ 1.4 & 0.107 &  \textbf{0.483}  \\
        OutFox & 0.025  & 8.96 $\pm$ 1.21 & 11.48 $\pm$ 1.13  & 0.095 & \textbf{0.237} \\
        TweepFake & \textbf{-} & 9.02 $\pm$ 3.19 & 8.12 $\pm$ 4.02 & 0.116 & 1.001 \\
    \midrule
        SemEval24 Mono & \textbf{0.012} & 9.11 $\pm$ 1.19 & 9.41 $\pm$ 1.2 &    0.191 &  2.576  \\
        SemEval24 Multi & \textbf{0.001}  & 9.65 $\pm$ 1.81 & 9.42 $\pm$ 1.44 &  0.059 &  2.046  \\
        RuATD & \underline{0.007} & 7.33 $\pm$ 1.4 & 7.46 $\pm$ 1.41 &  0.315 &  14.028  \\
        DAGPap22 & 0.083 & 8.35 $\pm$ 1.33 & 7.48 $\pm$ 2.01 &  \textbf{0.039} &   \textbf{0.472}  \\
        PAN24 & 0.053 & 9.4 $\pm$ 1.05 & 8.52 $\pm$ 1.59 &  \textbf{0.050} &  \textbf{0.331}  \\
        AuTex23 Eng & \underline{0.021} & 8.07 $\pm$ 2.26 & 8.1 $\pm$ 2.68 &  0.110 &  4.331 \\
        AuTex23 Esp &  \underline{0.001}& 9.16 $\pm$ 3.49 & 9.25 $\pm$ 3.26  &   0.105  &   1.306 \\
        IberAuTex & \textbf{0.012} & 9.33 $\pm$ 2.45 & 8.47 $\pm$ 2.73 &  0.223 & 5.516 \\
        MGT-1 Mono & \textbf{0.019} & 9.19 $\pm$ 1.75 & 8.96 $\pm$ 2.24 & \textbf{0.031} & 0.587\\
        MGT-1 Multi & \textbf{0.006} & 
8.76 $\pm$ 1.85 & 8.6 $\pm$ 2.29 &  \textbf{0.027} & 0.522\\
    \bottomrule    
    \end{tabular}
    \caption{Рассчитанная статистика по текстам выбранных наборов данных. Некоторые значения для $\text{KL}_{\text{TTS}}$ подчеркнуты, поскольку тексты слишком короткие, и TTS для почти всех текстов в TweepFake равна 0.}
    \label{tab:results}
\end{table}

\begin{figure}[h!t]\centering
    \includegraphics[width=\textwidth]{thesis/figures/chapter-5/ai-datasets/violins_PHD}
    \caption{Значения PHD для всех наборов данных, за исключением TweepFake и AuTex23 Spanish, тексты в которых оказались слишком короткими для корректного расчета PHD.}
    \label{fig:phd_values}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=1.00\textwidth]{thesis/figures/chapter-5/ai-datasets/4_datasets_TTS}
\caption{Топологические временные ряды для различных наборов данных.} 
\label{tts}
\end{figure}

Из каждого набора данных выбрано 1000 документов из тестовой выборки, сбалансированных между двумя классами.
Что касается базовых методов, выполняется тонкая настройка mdeberta-v3-base для каждого набора данных и оценили модель.
Для оценки качества Binoculars и Fast-DetectGPT использовался falcon-rw-1b~\cite{almazrouei2023falconseriesopenlanguage} и gpt-neo-2.7B~\cite{gpt-neo} соответственно.
Стоит отметить, что с последними двумя методами качество измерялось только на англоязычных выборках.
В эксперименте с топологическими признаками использовалась модель roberta-base, как и авторы оригинальной работы.
В эксперименте с пертурбациями и перемешиванием энкодер multilingual-e5-large использовался для построения эмбеддингов текстов, который показывает высокие метрики для кодирования высокоресурсных языков~\cite{e5}.
Результаты сравнения разработанных признаков в выбранных наборах данных представлены в Таблице~\ref{tab:results}. 
Что касается PHD и оценки TTS, в предыдущих работах было показано, что тексты языковых моделей имеют меньшие значения PHD, чем написанные человеком; однако этот результат был получен для моделей GPT-2, GPT-3.5 и OPT, и эта тенденция могла измениться для более современных языковых моделей, которые генерируют более похожие на человеческие тексты.
Если тексты разного происхождения имеют высокое значение $\text{KL}_{\text{TTS}}$, это означает, что детектору легче разделить такие тексты. $\text{KL}_{\text{TTS}}$ также ограничена для более коротких текстов.
Что касается PHD, предполагается, что сгенерированные тексты хорошего качества должны иметь PHD, аналогичный написанным человеком.
Дополнительно сравнивается распределения PHD для всех наборов данных на Рисунке~\ref{fig:phd_values}.
Снова, распределения для текстов обоих типов происхождения должны быть схожими, что в основном соблюдается для текстов из SemEval, PAN24 и MGT-1.
В следующих столбцах приводится статистика, наблюдаемая на модифицированных текстах, и для обеих из них чем ниже значение, тем лучше, так как это отражает схожую степень устойчивости сгенерированных и человеческих текстов к адверсарным атакам.
Качественно сгенерированные данные без смещений должны принимать значения, близкие к человеческим.

Наконец, в Таблице~\ref{tab:classifier} показаны результаты применения современных детекторов к выбранным тестовым наборам данных.
Например, на наборах данных с низкими значениями в Таблице~\ref{tab:results} может быть достигнуто качество, близкое к 1, что указывает на явное наличие смещения детектора в их сторону или структурной особенности, которая слишком очевидна для модели детекции.
Невозможно судить о качестве данных только по достижению значений $F_1$, близких к 1, но, комбинируя значения двух таблиц, можно оценить, какой набор имеет данные лучшего качества, а какой~--- худшего.

Что касается $\text{KL}_{\text{TTS}}$, на Рис.~\ref{tts} показано 4 набора данных с высоким значением этого показателя.
В то время как GhostBuster и PAN24 получили такой высокий балл из-за расхождения в текстах с более высокими размерностями, MGTBench и DAGPap22 — из-за разницы в самих распределениях.
Также стоит обратить внимание, что $\text{KL}_{\text{TTS}}$ может плохо работать с очень короткими текстами, поскольку внутренний метод вычисления PHD требует достаточно длинных текстов для стабильного вычисления.
Поэтому $\text{KL}_{\text{TTS}}$ для RuATD, AuTex23-es и Tweepfake отбрасываются, так как они не соответствуют критериям.
Кроме того, показано, что тексты должны быть достаточной длины~\cite{gritsay2022automatic526652068} для построения надежных детекторов.

Анализируя значения в Таблице~\ref{tab:results} показано наличие данных достаточно высокого качества в выбранных наборах данных.
Разработанные атрибуты в совокупности способны отражать качество сгенерированного набора данных с разных точек зрения и ракурсов.
Предлагается использовать эти атрибуты в сочетании с другими статистическими инструментами для оценки качества данных, например, с законом Ципфа~\cite{zipf}.

Представленная статистика может быть использована для оценки качества коллекций и их улучшения.
Кроме того, наборы данных, собирающие машинно-генерированный контент, также могут быть полезны для двух более общих целей.
Во-первых, высококачественные сгенерированные данные могут быть использованы для оценки качества каузальной модели во время обучения, как одна из целей обучения для улучшения ответов модели и сделать их более похожими на человеческие.
Во-вторых, хорошие детекторы могут помочь очистить обучающие наборы, поскольку большая доля низкокачественных сгенерированных текстов в этих наборах может привести к возникновению смещений в сторону некорректной структуры и мусорных фрагментов в выходных данных модели в будущем.

Вопрос о том, означает ли низкая производительность детекторов низкое качество набора данных, не имеет однозначного ответа.
Например, в \cite{hans2024spotting} метод Binoculars достигает оценки F$_1$, близкой к 1.0, в то время как в наших экспериментах был получен широкий диапазон оценок: от 0.33 на DAGPap22 до 0.93 на HC3.
Для HC3 все три детектора показали схожие результаты, что позволяет предположить, что тексты HC3 относительно легко обнаружить.
Однако эта согласованность не распространяется на DAGPap22.
Например, детектор на основе DeBERTa достиг оценки F$_1$ 0.96, в то время как DetectGPT показал только 0.562.
Эта закономерность, когда детектор на основе DeBERTa демонстрирует заметно более высокие результаты, чем два других метода, наблюдалась на значительной части проанализированных наборов данных.

И наоборот, низкие оценки для Binoculars заслуживают дополнительного изучения.
Даже при фокусировке на доменах, специально протестированных его авторами, таких как PAN24 (Новости) и Outfox (Студенческие эссе), оценки оказываются значительно ниже почти идеальных результатов, представленных в~\cite{hans2024spotting}.
Это расхождение позволяет предположить, что детектор Binoculars может быть нерепрезентативным.
Аналогично, в наших экспериментах оценки DetectGPT сопоставимы с оценками Binoculars, что потенциально указывает на схожие базовые проблемы с устойчивостью этих детекторов.

\section{Заключение по главе}

В данной главе представлены результаты практического применения теоретического аппарата оценки сложности моделей и данных в решении прикладных задач.
В отличие от предыдущих глав, где основной акцент делался на разработке строгих математических оценок, здесь продемонстрирована адаптация теоретических подходов к реальным проблемам машинного обучения.

В частности получены результаты для многозадачного обучения с LoRA-адаптерами, для которых получены как теоретические, так и эмперические оценки.
На примере адаптеров LoRa показано, что теоретические оценки Радемахеровской сложности позволяют эффективно управлять балансом между специализацией и обобщением в многозадачных сценариях, что открывает возможности для создания более эффективных и компактных моделей.
С другой стороны, разработаны методы снижения сложности данных в задачах нейровизуализации.
Практические эксперименты подтвердили эффективность предложенных подходов.
Также исследована оценка качества данных в задаче детекции машинной генерациию Исследована связь между качеством данных и эффективностью детекции машинной генерации.
Полученные результаты указывают на важность учета сложности данных.

Перспективным направлением дальнейших исследований является разработка упрощенных практических метрик сложности, которые могли бы служить мостом между строгим теоретическим аппаратом предыдущих глав и потребностями прикладных задач.