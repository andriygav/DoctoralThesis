В предыдущих главах был разработан единый теоретический аппарат для формализации соотношения между сложностью модели и сложностью данных.
В главе~\ref{chapter:complexity} введены формальные определения меры сложности выборки $\mu_D(D)$ и меры сложности модели $\mu_f(f)$, а также установлен критерий обучаемости $\mu_f(f) \leq \mu_D(D)$.
Кроме того, разработана ландшафтная мера сложности модели $\mu_f(f|D)$, определяемая через спектральные свойства матриц Гессе функции потерь.
В главе~\ref{chapter:gesian} получены конкретные оценки спектральных норм матриц Гессе для различных архитектур нейронных сетей, что обеспечивает вычислимо осуществимые методы оценки ландшафтной меры сложности.
В главе~\ref{chapter:samplesize} разработаны практические методы определения достаточного размера выборки на основе анализа стабильности процесса обучения.
В главе~\ref{chapter:pruning} предложены методы снижения сложности моделей через удаление параметров, дистилляцию и анти-дистилляцию.

Однако для полной валидации разработанного теоретического аппарата и демонстрации его практической значимости необходимо применить полученные результаты к реальным прикладным задачам машинного обучения.
В отличие от предыдущих глав, где основной акцент делался на разработке строгих математических оценок и алгоритмических процедур, в настоящей главе демонстрируется адаптация теоретических подходов к конкретным практическим проблемам.
Это позволяет оценить эффективность предложенного формализма в условиях реальных данных и ограниченных вычислительных ресурсов.

Настоящая глава охватывает три ключевых направления практического применения теоретического аппарата сложности моделей и данных.
Во-первых, рассматривается применение меры сложности Радемахера для анализа многозадачного обучения с адаптерами LoRA, что позволяет количественно оценить преимущества совместного использования параметров энкодера и эффективность низкоранговой параметризации.
Во-вторых, демонстрируется снижение сложности данных в задаче декодирования фМРТ-изображений из видеопоследовательностей, где предварительное сжатие данных обеспечивает существенное сокращение времени обучения без потери качества реконструкции.
В-третьих, разрабатываются методы оценки качества данных в задаче детекции машинно-генерированного текста, основанные на топологической статистике и анализе устойчивости к адверсарным возмущениям, что позволяет выявить смещения в обучающих наборах данных и улучшить надежность детекторов.

Полученные результаты создают основу для практического применения теоретического аппарата сложности моделей и данных в реальных задачах машинного обучения, демонстрируя эффективность предложенных подходов и открывая перспективы для дальнейшего развития методов управления сложностью в прикладных задачах.

\section{Сложность моделей в многозадачном обучении}

\subsection{Радемахеровская сложность моделей глубокого обучения}
Пусть $\mathcal{X}$ обозначает входное пространство, а $\mathcal{Y} = \{1, \dots, C\}$~--- общее пространство меток для всех доменов.
Домен определяется как пара $\mathcal{D} = (\mathcal{X}, P(X))$, где $P(X)$~--- распределение над $\mathcal{X}$.

Предполагается наличие $K$ размеченных исходных доменов
\begin{equation}
    \mathcal{D}_{S_k} = (\mathcal{X}, P_{S_k}(X)), 
    \quad k = 1, \dots, K,
\end{equation}
с размеченными выборками
\begin{equation}
    \mathcal{S}_k = \{(x_i^{S_k}, y_i^{S_k})\}_{i=1}^{n_{S_k}}, 
    \quad x_i^{S_k} \sim P_{S_k}(X),  y_i^{S_k} \in \mathcal{Y}.
\end{equation}

Также рассматривается целевой домен
\begin{equation}
    \mathcal{D}_T = (\mathcal{X}, P_T(X)),
\end{equation}
с выборками
\begin{equation}
    \mathcal{T} = \{(x_j^T, y_j^T)\}_{j=1}^{n_T^{\text{lab}}} \cup \{x_j^T\}_{j=1}^{n_T^{\text{unlab}}}.
\end{equation}

Цель кросс-доменной классификации~--- обучить классификатор
\begin{equation}
    f_\theta : \mathcal{X} \to \mathcal{Y}, \quad f_\theta(x) = \arg\max_{y \in \mathcal{Y}} p_\theta(y \mid x),
\end{equation}
такой, чтобы ожидаемая целевая ошибка
\begin{equation}
    \epsilon_T(f_\theta) = \mathbb{E}_{(x,y) \sim P_T(X,Y)} [\mathbf{1}\{f_\theta(x) \neq y\}]
\end{equation}
минимизировалась за счет использования знаний из всех источников $\{\mathcal{S}_k\}_{k=1}^K$.
Цель состоит в обучении классификатора, который способен достигать высоких метрик качества на примерах из доменов, не встречавшихся во время обучения или представленных лишь ограниченными данными.

Современные задачи классификации часто решаются путем адаптации больших предобученных моделей к конкретному домену или набору данных~\cite{devlin2019bert}.
Распространенная стратегия~--- тонкая настройка (fine-tuning), когда параметры предобученной модели обновляются с использованием размеченных данных из целевой задачи.
Хотя этот подход обычно дает высокую производительность, он может быть вычислительно дорогим, поскольку количество обучаемых параметров очень велико.

Основная идея LoRA заключается в том, что для адаптации к задаче не обязательно обновлять всю матрицу параметров.
Вместо этого обновления могут быть эффективно представлены в низкоразмерном подпространстве, которое захватывает существенные вариации, необходимые для адаптации.
Это значительно сокращает количество обучаемых параметров, в значительной степени сохраняя выразительную способность модели.

Формально, пусть $\Delta W \in \mathbb{R}^{d \times k}$ обозначает обновление параметров для данного слоя.
При стандартной тонкой настройке $\Delta W$ изучается напрямую.
LoRA ограничивает $\Delta W$ условием низкого ранга путем факторизации:
\begin{equation}
    \Delta W \approx A B,
\end{equation}
где $A \in \mathbb{R}^{d \times r}$ и $B \in \mathbb{R}^{r \times k}$ с $r \ll \min(d,k)$. 
Обновленная матрица параметров тогда имеет вид:
\begin{equation}
    W_{\text{upd}} = W + \Delta W = W + AB,
\end{equation}
где $W$ обозначает замороженные предобученные веса, а $AB$~--- изучаемое низкоранговое обновление. 
Ранг $r$ выступает в качестве гиперпараметра, контролирующего размер изучаемого подпространства.

\begin{table}[t]
    \caption{Сравнение формул обновления параметров для полной тонкой настройки и метода LoRA. В полной тонкой настройке обновление $\Delta W$ изучается напрямую, тогда как в LoRA обновление параметризуется в виде низкоранговой факторизации $AB$, где $r \ll \min(d,k)$, что значительно сокращает количество обучаемых параметров.} \label{table:lora}
    \begin{center}
    \begin{tabular}{cc}
    \toprule
    \textbf{Полная тонкая настройка} & \textbf{Тонкая настройка с LoRA} \\
    \midrule
    $W_{\text{upd}} = W + \Delta W$ & $W_{\text{upd}} = W + AB$ \\
    $\hat{y} = x(W + \Delta W)$ & $\hat{y} = x(W + AB)$ \\
    \bottomrule
    \end{tabular}
    \end{center}
\end{table}

В задачах классификации предсказание обычно имеет вид
\begin{equation}
    p(c \mid \mathbf{x}) = \operatorname{softmax}(W^{\top} \mathbf{x}),
\end{equation}
где $\mathbf{x}$~--- это вектор признаков входного объекта, а $W$~--- обучаемая матрица весов.
LoRA может быть применена здесь путем замены $W$ на ее низкоранговую адаптированную форму $W + AB$.

Многозадачное обучение~--- это подход, в котором несколько связанных задач изучаются совместно с целью достижения лучшей обобщающей способности по сравнению с обучением каждой задачи независимо.
Ключевое предположение заключается в том, что задачи разделяют некоторую базовую структуру, так что обмен информацией между ними уменьшает переобучение и улучшает прогнозную производительность. 

Формально, пусть $\{(x_{t,i}, y_{t,i})\}_{i=1}^{n_t}$ обозначает обучающие данные для задачи $t \in \{1,\dots,T\}$, взятые из распределения $P_t$ над $\mathcal{X} \times \mathcal{Y}$.
Цель~--- обучить дискриминативные функции $f_t : \mathcal{X} \to \mathcal{Y}$ для всех задач.
Распространенный подход формулирует это как задачу регуляризованной минимизации эмпирического риска:
\begin{equation}
    \min_{f = (f_1,\ldots,f_T)} 
        \frac{1}{T} \sum_{t=1}^T \frac{1}{n_t} \sum_{i=1}^{n_t} 
            \ell(f_t(x_{t,i}), y_{t,i}) 
        + \lambda \, \Omega(f),
\end{equation}
где первое слагаемое~--- это средняя эмпирическая ошибка по задачам, а $\Omega(f)$~--- регуляризующее слагаемое, поощряющее обмен информацией. 

С теоретической точки зрения, преимущество MTL может быть интерпретировано как эффективное сокращение пространства гипотез за счет использования связанности задач, что приводит к более узким обобщающим границам.

Традиционные методы машинного обучения часто обучаются в однозадачной постановке.
В отличие от этого, многозадачное обучение (MTL) совместно обучается на нескольких задачах с целью улучшения общей производительности за счет использования общих представлений~\cite{anonymous2024}. 

Такая постановка особенно эффективна, когда задачи связаны, так как передача информации может уменьшить переобучение и улучшить обобщение.
Кроме того, даже для одной целевой задачи вспомогательные задачи могут служить формой индуктивного смещения, помогая модели изучать более устойчивые представления.

Центральный вопрос в многозадачном обучении, как и в стандартном обучении с учителем, заключается в том, насколько хорошо изученные функции обобщаются на новые данные.
Границы обобщающей ошибки предоставляют теоретические гарантии, связывая истинный риск с его эмпирическим аналогом.
В постановке MTL границы часто выводятся в рамках упомянутого выше подхода регуляризованной минимизации эмпирического риска. 

Пусть даны обучающие примеры $\{(X_1, Y_1), \ldots, (X_n, Y_n)\}$, взятые i.i.d. из неизвестного распределения $P$.
Цель~--- обучить функцию $f \in \mathcal{F}$ с малой ожидаемой потерей $\mathbb{E}_{(X,Y) \sim P} [\ell(f(X), Y)]$.
Поскольку $P$ неизвестно, обычно связывают этот риск со средним эмпирическим значением функции потерь плюс слагаемое сложности, которое зависит от богатства гипотезного класса $\mathcal{F}$:
\begin{align}
    \mathbb{E}_{(X,Y) \sim P}[\ell(f(X), Y)] &\leq \frac{1}{n} \sum_{i=1}^{n} \ell(f(X_i), Y_i) \\
    &\quad + h\!\left(\text{complexity of }\mathcal{F}, n \right).
\end{align}

Среди различных мер сложности широко используется сложность Радемахера.
Эта мера количественно определяет, насколько хорошо гипотезный класс может аппроксимировать случайный шум, что напрямую связано с обобщающей способностью модели.
Формально:

\begin{definition}[Сложность Радемахера]
    Пусть $\mathcal{G} := \{g : \mathcal{Z} \to \mathbb{R}\}$~--- гипотезный класс, а $S := \{z_1, \ldots, z_n\}$~--- i.i.d. выборка из $P$.
    Эмпирическая сложность Радемахера для $\mathcal{G}$ определяется как
    \[
    \widehat{R}(\mathcal{G}) := \mathbb{E}_{\sigma} \left[ 
        \sup_{g \in \mathcal{G}} \frac{1}{n} \sum_{i=1}^n \sigma_i g(z_i) \right],
    \]
    где $\sigma_i$~--- независимые случайные величины Радемахера, равномерно распределенные в $\{\pm 1\}$.
    (Ожидаемая) сложность Радемахера определяется как
    \[
    R(\mathcal{G}) := \mathbb{E}_{S \sim P^n} \left[ \widehat{R}(\mathcal{G}) \right].
    \]
\end{definition}

Интуитивно, меньшая сложность Радемахера соответствует менее выразительному предсказательному классу, что, в свою очередь, приводит к более узким границам обобщения.
В настоящем исследовании выполняется сопоставление сложности модели в условиях многозадачного и однозадачного обучения.
В отличие от других работ, мы не сравниваем различные типы границ обобщения, а фокусируемся на сравнении сложности моделей.

Для эмпирической проверки нашего теоретического анализа сфокусируемся на задаче обнаружения машинно-генерированного текста.
Эта задача требует высокой точности классификации с низкой частотой ложных срабатываний, чтобы избежать некорректного помечания контента, написанного человеком.
Стремительное улучшение больших языковых моделей (LLMs) сделало тексты, сгенерированные ИИ, все более неотличимыми от написанных человеком ~\cite{zellers2019grover, solaiman2019gpt2}, создавая насущную потребность в устойчивых методах обнаружения для сохранения академической честности и борьбы с дезинформацией. 

Большинство подходов рассматривают это как задачу бинарной классификации текста~\cite{jawahar2020automatic, uchendu2021authorship}.
Тонкая настройка архитектур на основе Transformer стала доминирующим решением ~\cite{valiaiev2024detectionmachinegeneratedtextliterature}, демонстрируя высокую производительность, когда тестовые данные поступают из того же или близкородственного домена.
Однако производительность часто резко падает при появлении новых доменов, делая модели менее надежными~\cite{anonymous2025}.
Чтобы решить эту проблему, можно либо использовать более мощные модели, либо интегрировать дополнительную информацию о тексте, такую как его источник, домен или стилистические особенности.
Эти сигналы могут выступать в качестве вспомогательных регуляризаторов, улучшая обобщение.
Многозадачное обучение предоставляет естественную основу для объединения нескольких задач, включая интеграцию такой вспомогательной информации, при этом сохраняя основную цель классификации.

\subsection{Радемахеровская сложность многозадачного обучения в LoRA-адаптерах}

Предполагается, что решается задача классификации с использованием моделей с архитектурой Transformer~\cite{attention}.
Тонкая настройка таких моделей в режиме обучения с учителем является современным методом для задач классификации.

Анализ LoRA показывает, что минимизация эмпирического риска при параметризации LoRA остается согласованной с минимизацией истинного риска, гарантируя, что низкоранговая адаптация сохраняет асимптотические статистические гарантии полной тонкой настройки.

\begin{theorem}[Состоятельность]\label{theorem:consistency}
Пусть $\mathcal{D} = \{(X_i, c_i)\}_{i=1}^n$~--- независимые одинаково распределенные выборки из истинного распределения $P_{\mathrm{true}}$, где $c_i \in [N_c]$ обозначает метки классов. 
Предположим следующее:
\begin{enumerate}
    \item Существует параметр $\Theta^\star$ такой, что модель распределения $P_{\mathrm{model}}(\cdot \mid \Theta)$ аппроксимирует истинное распределение с минимальным расхождением Кульбака-Лейблера:
    \begin{equation}
    \label{eq:kl-opt}
    \Theta^\star \in \arg\min_{\Theta} D_{\mathrm{KL}}\big(P_{\mathrm{true}} \,\|\, P_{\mathrm{model}}(\cdot \mid \Theta)\big).
    \end{equation}

    \item При $n \to \infty$ эмпирическое распределение сходится по вероятности к $P_{\mathrm{true}}$.
    
    \item Функция потерь задается как отрицательное логарифмическое правдоподобие
    \begin{equation}
    \label{eq:loss}
        \mathscr{L}_n(\Theta) = -\frac{1}{n} \sum_{i=1}^n \log \Big(P_{\Phi_0 + \Theta}\big(c_i \mid X_i\big)\Big),
    \end{equation}
    где $\Phi_0$~--- замороженные предобученные веса, а $\Theta$ соответствует обучаемым низкоранговым параметрам в LoRA.
    Предполагается, что $\mathcal{L}_n(\Theta)$ непрерывна и дифференцируема.
\end{enumerate}

Тогда минимизация эмпирического риска является состоятельной:
\begin{equation}
\label{eq:consistency}
\lim_{n \to \infty} \arg\min_{\Theta} \, \mathscr{L}_n(\Theta) = \Theta^\star.
\end{equation}
\end{theorem}
\begin{proof}
Пусть истинный риск и его эмпирический аналог определены как
\[
    L(\Theta) = \mathbb{E}_{(X,c)\sim P_{\mathrm{true}}}[\mathscr{L}(X,c;\Theta)], \quad \widehat{L}_n(\Theta) = \frac{1}{n}\sum_{i=1}^n \mathscr{L}(X_i,c_i;\Theta),
\]
где $\mathscr{L}(X_i,c_i;\Theta) = -\log P_{\Phi_0+\Theta}(c_i\mid X_i)$~--- отрицательное логарифмическое правдоподобие для отдельного примера.

В соответствии с равномерным законом больших чисел,
для непрерывной и ограниченной функции $\mathscr{L}$ имеем
\begin{equation}
    \sup_{\Theta}\big|\,L(\Theta)-\widehat{L}_n(\Theta)\,\big|\xrightarrow[n\to\infty]{p}0.
\label{eq:unif-conv}
\end{equation}
Следовательно, последовательность эмпирических рисков $\widehat{L}_n(\Theta)$ сходится равномерно к истинному риску $L(\Theta)$.
Равномерная сходимость влечет состоятельность минимизации эмпирического риска, т.е.
\[
    \arg\min_{\Theta}\widehat{L}_n(\Theta)\xrightarrow[n\to\infty]{}\arg\min_{\Theta}L(\Theta).
\]

Из определения $L(\Theta)$ и с использованием тождества
\[
D_{\mathrm{KL}}\!\big(P_{\mathrm{true}}\|P_{\mathrm{model}}(\cdot\mid\Theta)\big)
= \mathbb{E}_{(X,c)\sim P_{\mathrm{true}}}
   \!\left[\log\frac{P_{\mathrm{true}}(c\mid X)}{P_{\mathrm{model}}(c\mid X;\Theta)}\right],
\]
минимизация ожидаемых потерь $L(\Theta)$ эквивалентна минимизации расхождения Кульбака-Лейблера между $P_{\mathrm{true}}$ и $P_{\mathrm{model}}(\cdot\mid\Theta)$.
Согласно Предположению (1), минимизатором этого расхождения является $\Theta^\star$.
Следовательно,
\[
\lim_{n\to\infty}\arg\min_{\Theta}\widehat{L}_n(\Theta)
=\arg\min_{\Theta}L(\Theta)=\Theta^\star,
\]
что завершает доказательство.
\end{proof}

\begin{theorem}[Корректность при низкоранговых обновлениях]
\label{theorem:lowrank}
Предположим следующее:
\begin{enumerate}
    \item Выходной слой задается в виде
    \begin{equation}
    \label{eq:softmax}
        \hat{\mathbf{y}} = \operatorname{softmax}\!\left(W_{\mathrm{upd}}^{\top} \mathbf{x}\right),
    \end{equation}
    где $\mathbf{x} \in \mathbb{R}^d$~--- это вектор признаков BERT, $W \in \mathbb{R}^{d \times k}$~--- замороженные предобученные веса, а 
    \begin{equation}
    \label{eq:update}
        W_{\mathrm{upd}} = W + \Delta W.
    \end{equation}

    \item Вместо непосредственного обучения $\Delta W \in \mathbb{R}^{d \times k}$, обновление параметризуется в низкоранговой форме:
    \begin{equation}
    \label{eq:lora}
        \Delta W = A B, 
        \quad A \in \mathbb{R}^{d \times r}, 
        B \in \mathbb{R}^{r \times k}, 
        r \ll \min(d,k).
    \end{equation}

    \item Выполнены условия Теоремы~\ref{theorem:consistency}, т.е. модель остается статистически состоятельной при минимизации эмпирического риска.
\end{enumerate}

Тогда при параметризации~\eqref{eq:lora} выход модели $\hat{\mathbf{y}}$ сохраняется в том смысле, что низкоранговое обновление не искажает корректность классификационного слоя.
\end{theorem}
\begin{proof}
Пусть выходной слой определен как
\[
    \hat{\mathbf{y}} = \operatorname{softmax}\!\big(W_{\mathrm{upd}}^{\top}\mathbf{x}\big), \quad W_{\mathrm{upd}} = W + \Delta W,
\]
где $W \in \mathbb{R}^{d\times k}$~--- замороженные предобученные веса, а $\mathbf{x}\in\mathbb{R}^d$~--- вектор признаков энкодера. 
В силу дистрибутивности матричного сложения,
\[
    W_{\mathrm{upd}}^{\top}\mathbf{x} = W^{\top}\mathbf{x} + \Delta W^{\top}\mathbf{x}.
\]
Следовательно, предсказанные вероятности могут быть записаны как
\begin{equation}\label{eq:softmax-expanded}
    \hat{\mathbf{y}} = \frac{\exp\!\big(W^{\top}\mathbf{x} + \Delta W^{\top}\mathbf{x}\big)}      {\sum_{i=1}^{k}\exp\!\big((W^{\top}\mathbf{x} + \Delta W^{\top}\mathbf{x})_i\big)}.
\end{equation}

При параметризации LoRA $\Delta W = AB$ с $A\in\mathbb{R}^{d\times r}$ и $B\in\mathbb{R}^{r\times k}$, член обновления принимает вид
\[
    \Delta W^{\top}\mathbf{x} = (AB)^{\top}\mathbf{x} = B^{\top}(A^{\top}\mathbf{x}) \in \mathbb{R}^{k}.
\]
Это показывает, что низкоранговая форма лишь ограничивает $\Delta W$ рангом $r$ в подпространстве $\mathbb{R}^{d\times k}$, но не изменяет выходную размерность или отображение $\mathbf{x}\mapsto\hat{\mathbf{y}}$.
Логиты в~\eqref{eq:softmax-expanded} остаются хорошо определенными и дифференцируемыми для всех $\mathbf{x}$.

Более того, поскольку обновление $\Delta W$ изучается через минимизацию эмпирического риска, согласованную с Теоремой 1, результирующие параметры $(A,B)$ дают тот же минимизатор истинного ожидаемого риска, что и неограниченный $\Delta W$.
Следовательно, низкоранговая параметризация сохраняет корректность выходного слоя в том смысле, что~$\hat{\mathbf{y}}_{\mathrm{LoRA}} = \operatorname{softmax}\!\big((W+AB)^{\top}\mathbf{x}\big)$ порождает то же решающее правило, что и~$\operatorname{softmax}\!\big((W+\Delta W)^{\top}\mathbf{x}\big)$.
Таким образом, введение модулей LoRA не искажает выходное распределение или классификационные границы модели.
\end{proof}

\begin{corollary}[LoRA с теоретическими гарантиями]
\label{corollary:lora}
Объединяя Теорему~\ref{theorem:consistency} и Теорему~\ref{theorem:lowrank}, мы получаем, что тонкая настройка на основе LoRA одновременно сохраняет:
\begin{enumerate}
    \item Статистическую состоятельность: минимизация эмпирического риска сходится к минимизатору истинного риска с ростом объема выборки;
    \item Корректность выходного слоя: низкоранговые обновления $AB$ не искажают выход классификации.
\end{enumerate}
Таким образом, адаптация с помощью LoRA наследует те же асимптотические гарантии, что и полная тонкая настройка, при этом требуя значительно меньшего количества обучаемых параметров.
\end{corollary}

Приведенные выше результаты показывают, что LoRA не ослабляет теоретические основы тонкой настройки.
Со статистической точки зрения, метод сохраняет состоятельность: с увеличением количества обучающих примеров адаптированная модель сходится к тому же оптимальному решению, что и при полной тонкой настройке.
С функциональной точки зрения, ограничение обновлений низкоранговым подпространством не искажает выход классификационного слоя.
В совокупности эти свойства объясняют, почему LoRA достигает сопоставимой производительности с полной тонкой настройкой на практике, будучи при этом существенно более эффективной.

В настоящем разделе анализируется влияние многозадачного обучения на сложность обобщения для каждой задачи.
Для этого выполняется сравнение однозадачного обучения модели на основе Transformer с MTL-подходом, использующим общий энкодер.
Для обеспечения справедливого сравнения предполагается, что архитектуры энкодера и головы идентичны и состоят из линейных слоев.
Это позволяет изолировать эффект многозадачного обучения от влияния различий в архитектуре.
В случае STL присутствует единственная голова для целевой задачи, тогда как в настройке MTL вводятся дополнительные головы для связанных задач, обеспечивая неявную регуляризацию для целевой задачи.

Формально, в случаях STL и MTL гипотезные классы имеют вид:
\begin{align}
\mathcal{F}_{\mathrm{STL}}
&= \Big\{\, x \mapsto w_{\mathrm{head}}^\top \phi(x; w_{\mathrm{enc}}) \\
&\qquad \big|\, w_{\mathrm{enc}}\in\mathcal{W}_{\mathrm{enc}},
               w_{\mathrm{head}}\in\mathcal{W}_{\mathrm{head}} \Big\},
\\[4pt]
\mathcal{F}_{\mathrm{MTL}}
&= \Big\{\, (\,x \mapsto w_t^\top \phi(x; w_{\mathrm{shared}})\,)_{t=1}^T \\
&\qquad \big|\, w_{\mathrm{shared}}\in\mathcal{W}_{\mathrm{shared}},
               w_t\in\mathcal{W}_{\mathrm{head}} \Big\}.
\end{align}


\begin{theorem}[Сложность Радемахера на задачу при MTL]\label{thm:per-task-rc-fair-scaling}
Пусть $S_t=\{x_i\}_{i=1}^n$~--- выборка фиксированной целевой задачи $t$ с $\|x_i\|_2 \le R$.
Пусть $\phi(\cdot;w)$~--- энкодер, и рассмотрим линейные головы
$f_{w,h}(x)=h^\top \phi(x;w)$ с $\|h\|_2 \le B_{\mathrm{head}}$.
Предположим:
\begin{enumerate}
\item Ограничение на признаки: для всех $x,w$ 
$\|\phi(x;w)\|_2 \le L\,\|w\|\,\|x\|_2$.
\item Энкодер STL удовлетворяет $\|w_{\mathrm{enc}}\|\le B_{\mathrm{enc}}$,
общий энкодер MTL удовлетворяет $\|w_{\mathrm{shared}}\|\le B_{\mathrm{shared}}$.
\item Многозадачное масштабирование: $B_{\mathrm{shared}} \le B_{\mathrm{enc}}/\sqrt{T}$.
\end{enumerate}

Обозначим через $\widehat{\mathfrak R}_n(\cdot;S_t)$ эмпирическую сложность Радемахера на $S_t$.
Тогда
\begin{equation}\label{eq:mtl-vs-stl-rc}
    \widehat{\mathfrak R}_n\!\big(\mathcal{F}_{\mathrm{MTL}}^{(t)};S_t\big)
    \le \frac{1}{\sqrt{T}}\,
    \widehat{\mathfrak R}_n\!\big(\mathcal{F}_{\mathrm{STL}}^{(t)};S_t\big).
\end{equation}
\end{theorem}
\begin{proof}
Пусть $S_t = \{x_i\}_{i=1}^n$~--- выборка для целевой задачи $t$ с 
$\|x_i\|_2 \le R$. 
Для $B > 0$ определим гипотезный класс
\[
    \mathcal{F}(B)
    = \big\{\,x \mapsto h^\top \phi(x;w) 
    \big|
    \|h\|_2 \le B_{\mathrm{head}},\, \|w\|_2 \le B
    \big\}.
\]
Эмпирическая сложность Радемахера на $S_t$ равна
\[
    \widehat{\mathfrak R}_n(\mathcal{F}(B);S_t)
    = \frac{1}{n}\,\mathbb{E}_{\sigma}
      \sup_{\|h\|\le B_{\mathrm{head}},\,\|w\|\le B}
      \sum_{i=1}^n \sigma_i\, h^\top \phi(x_i;w),
\]
где $\sigma_i \in \{\pm1\}$~--- независимые одинаково распределенные величины Радемахера.

Для фиксированных $w$ и $\sigma$, по дуальности Коши-Буняковского,
\[
    \sup_{\|h\|\le B_{\mathrm{head}}}
    \sum_{i=1}^n \sigma_i\, h^\top \phi(x_i;w)
    = B_{\mathrm{head}}
      \Big\|\sum_{i=1}^n \sigma_i\, \phi(x_i;w)\Big\|_2.
\]
Следовательно,
\[
    \widehat{\mathfrak R}_n(\mathcal{F}(B);S_t)
    \le
    \frac{B_{\mathrm{head}}}{n}\,
    \mathbb{E}_{\sigma}
    \sup_{\|w\|\le B}
      \Big\|\sum_{i=1}^n \sigma_i\, \phi(x_i;w)\Big\|_2.
\]

По неравенствам Йенсена и Хинчина,
\[
    \mathbb{E}_{\sigma}
      \Big\|\sum_{i=1}^n \sigma_i\,a_i\Big\|_2
    \le
    \Big(\sum_{i=1}^n \|a_i\|_2^2\Big)^{1/2},
\]
что дает
\[
    \widehat{\mathfrak R}_n(\mathcal{F}(B);S_t)
    \le
    \frac{B_{\mathrm{head}}}{n}\,
    \sup_{\|w\|\le B}
      \Big(\sum_{i=1}^n \|\phi(x_i;w)\|_2^2\Big)^{1/2}.
\]

Используя ограничение на признаки $\|\phi(x;w)\|_2 \le L\,\|w\|_2\,\|x\|_2$ и $\|x_i\|_2 \le R$, получаем
\[
    \widehat{\mathfrak R}_n(\mathcal{F}(B);S_t)
    \le
    \frac{B_{\mathrm{head}}\,L\,R\,B}{\sqrt{n}}.
\]
Применяя это с $B=B_{\mathrm{enc}}$ для STL и $B=B_{\mathrm{shared}}$ для MTL, находим
\[
    \widehat{\mathfrak R}_n(\mathcal{F}(B_{\mathrm{shared}});S_t)
    \le
    \frac{B_{\mathrm{head}}\,L\,R\,B_{\mathrm{shared}}}{\sqrt{n}}
    \le
    \frac{1}{\sqrt{T}}\,
    \frac{B_{\mathrm{head}}\,L\,R\,B_{\mathrm{enc}}}{\sqrt{n}}
    =
    \frac{1}{\sqrt{T}}\,
    \widehat{\mathfrak R}_n(\mathcal{F}(B_{\mathrm{enc}});S_t),
\]
где последнее неравенство следует из предположения многозадачного масштабирования $B_{\mathrm{shared}}\le B_{\mathrm{enc}}/\sqrt{T}$.
\end{proof}

Полученный результат указывает на снижение эмпирической сложности Радемахера на задачу в $1/\sqrt{T}$ раз при справедливом масштабировании.
Это согласуется с современными анализами многозадачного обучения, основанными на средних Радемахера, как показано в~\cite{maurer2006}.

Данный результат имеет важное практическое значение: при совместном использовании параметров энкодера между $T$ задачами эффективная сложность модели на каждую задачу снижается пропорционально $1/\sqrt{T}$, что количественно объясняет преимущества многозадачного обучения в терминах меры сложности Радемахера.
Однако более ранняя работа~\cite{baxter2000} установила более сильное улучшение типа $1/T$ в другой постановке.
В постановке Бакстера, количество задач $T$ само по себе способствует оценке общего индуктивного смещения: с ростом $T$ сложность данных на задачу уменьшается пропорционально $1/T$.
В отличие от этого, наш анализ сохраняет размер выборки целевой задачи $n$ фиксированным и сравнивает STL и MTL на одном и том же $n$, поэтому улучшение проявляется как множитель $1/\sqrt{T}$ в сложности Радемахера на задачу.

Обе сложности на задачу оцениваются на одной и той же выборке $S_t$ размера $n$, поэтому общий множитель $1/\sqrt{n}$ сокращается; разница обусловлена только бюджетом энкодера. 

Более того, в анализе обеспечивается, чтобы обе модели STL и MTL обучались на одинаковом общем количестве примеров ($nT$).
Для STL энкодер обучается на $nT$ примерах только из целевой задачи.
Для MTL каждая из $T$ голов получает $n$ примеров из своей соответствующей задачи, так что общий энкодер видит те же самые $nT$ примеров, причем одна из голов соответствует целевой задаче.
Это гарантирует, что наблюдаемое снижение сложности на задачу обусловлено совместным использованием параметров, а не неравными бюджетами данных.

Наш теоретический анализ установил, что LoRA сохраняет статистическую состоятельность полной тонкой настройки и поддерживает корректность выходного слоя, в то время как многозадачное обучение при соответствующем масштабировании снижает сложность Радемахера на задачу в $1/\sqrt{T}$ раз.
Вместе эти результаты показывают, что оба подхода сохраняют фундаментальные гарантии классической тонкой настройки, но достигают большей эффективности с точки зрения параметров (LoRA) или обобщения (MTL).

Полученные теоретические результаты создают основу для практического применения LoRA и многозадачного обучения в реальных задачах, обеспечивая теоретическое обоснование их эффективности и количественную оценку преимуществ по сравнению с полной тонкой настройкой.


\section{Снижение сложности данных в задаче декодирования фМРТ-снимков}

В предыдущем разделе рассматривалось снижение сложности моделей через низкоранговую параметризацию и многозадачное обучение.
В настоящем разделе демонстрируется альтернативный подход~--- снижение сложности данных без изменения архитектуры модели.
Такой подход особенно актуален в задачах, где данные имеют высокую размерность, но могут быть эффективно сжаты без существенной потери информации.
В задаче декодирования фМРТ-изображений из видеопоследовательностей предварительное сжатие томографических данных позволяет существенно сократить время обучения при сохранении качества реконструкции, что иллюстрирует практическую значимость управления сложностью данных в прикладных задачах нейровизуализации.

Частота кадров $\nu \in \mathbb{R}$ и продолжительность $t \in \mathbb{R}$ видеопоследовательности задаются.
Видеопоследовательность задается как
\begin{equation}
	\label{eq1}
	\mathbf{P} = [\mathbf{p}_1, \ldots, \mathbf{p}_{\nu t}], \quad \mathbf{p}_{\ell} \in \mathbb{R}^{W \times H \times C},
\end{equation}
где $W$, $H$ и $C$~--- ширина, высота и количество каналов изображения соответственно.

Обозначим частоту фМРТ-изображений через $\mu \in \mathbb{R}$.
Зададим последовательность изображений
\begin{equation}
	\label{eq2}
	\mathbf{S} = [\mathbf{s}_1, \ldots, \mathbf{s}_{\mu t}], \quad \mathbf{s}_{\ell} \in \mathbb{R}^{X \times Y \times Z},
\end{equation}
где $X$, $Y$ и $Z$~--- размеры воксельного изображения.

Задача состоит в построении отображения, учитывающего задержку $\Delta t$ между фМРТ-изображением и видеопоследовательностью, а также предыдущие томографические данные.
Формально необходимо найти такое отображение $\mathbf{g}$, что
\begin{equation}
	\label{eq3}
	\mathbf{g}(\mathbf{p}_1, \ldots, \mathbf{p}_{k_{\ell} - \nu \Delta t}; \mathbf{s}_1, \ldots, \mathbf{s}_{\ell-1}) = \mathbf{s}_{\ell}, \quad \ell = 1, \ldots, \mu t,
\end{equation}
где для $\ell$-го фМРТ-изображения номер соответствующего кадра $k_{\ell}$ определяется по формуле
\begin{equation}
	\label{eq4}
	k_{\ell} = \dfrac{\ell \cdot \nu}{\mu}.
\end{equation}

Схема предложенного метода реконструкции фМРТ-изображений показана на рис.~\ref{fig:scheme}.

\begin{figure}[h!t]
	\centering
	\includegraphics[width=\textwidth]{thesis/figures/chapter-5/fmri/scheme}
	\caption{Схема метода декодирования фМРТ-изображений из видеопоследовательностей. Метод использует архитектуру ResNet152 для векторизации видеокадров и линейную регрессию с $L_2$-регуляризацией для предсказания разностей между последовательными фМРТ-снимками с учетом временной задержки $\Delta t$.}
	\label{fig:scheme}
\end{figure}

Обозначим фМРТ-изображение как $\mathbf{s}_{\ell} = [v^{\ell}_{ijk}] \in \mathbb{R}^{X \times Y \times Z}$, где $v^{\ell}_{ijk} \in \mathbb{R}_+$ — значение соответствующего вокселя.
Для сокращения времени работы метода предлагается использовать сжатие фМРТ-изображений путем снижения размерности.
Сжатие в 2 раза представляется в виде отображения
\[
    \boldsymbol{\chi}: \mathbb{R}^{X \times Y \times Z} \to \mathbb{R}^{X/2 \times Y/2 \times Z/2}.
\]
Сжатие в $2^k$ раз получается последовательным применением $\boldsymbol{\chi}$ $k$ раз.
В дальнейшем для простоты сохраняем обозначения размерностей изображения $X \times Y \times Z$.

Предположим, что для последовательности снимков выполняется свойство Маркова, т.е. каждый снимок зависит только от одного изображения и предыдущего снимка.
Тогда соответствующее отображение записывается в виде
\begin{equation}
	\label{eq5}
	\mathbf{g}(\mathbf{p}_{k_{\ell} - \nu \Delta t}) = \mathbf{s}_{\ell} - \mathbf{s}_{\ell-1} = \boldsymbol{\delta}_{\ell}, \quad \ell = 2, \ldots, \mu t.
\end{equation}
где $\boldsymbol{\delta}_{\ell} = [v^{\ell}_{ijk} - v^{\ell-1}_{ijk}] = [\delta^{\ell}_{ijk}] \in \mathbb{R}^{X \times Y \times Z}$~--- разность двух последовательных снимков.

Отображение $\mathbf{g}: \mathbf{P} \to \mathbf{S}$ представляется как композиция двух других:
\[
    \mathbf{g} = \boldsymbol{\varphi} \circ \boldsymbol{\psi},
\]
где
\begin{align}
	 & \boldsymbol{\psi}: \mathbf{P} \to \mathbb{R}^d \text{~--- векторизация изображения,}        \\
	 & \boldsymbol{\varphi}: \mathbb{R}^d \to \mathbf{S} \text{~--- целевое отображение.}
\end{align}

Для каждого изображения из видеопоследовательности имеем вектор внедрения размерности $d$:
\[
    \mathbf{x}_{\ell} = [x^{\ell}_1, \ldots, x^{\ell}_{d}]^\top \in \mathbb{R}^{d}, \quad \ell = 1, \ldots, \nu t.
\]
В качестве архитектуры используется нейронная сеть ResNet152 без последнего линейного слоя.

При заданном $k_{\ell} = \ell \cdot \nu / \mu$ общее количество пар составляет $N = \mu (t - \Delta t)$.
Таким образом, для каждого вокселя задана выборка
\[
    \mathfrak{D}_{ijk} = \{(\mathbf{x}_{\ell}, \delta^{\ell}_{ijk}) \ | \ \ell = 2, \ldots, N \}.
\]

Задача формулируется как регрессия
\begin{equation}\label{eq6}
	y_{ijk}: \mathbb{R}^{d} \to \mathbb{R}.
\end{equation}

В качестве модели используется линейная регрессия с вектором параметров
\[
    \mathbf{w}_{ijk} = [w^{ijk}_1, \ldots, w^{ijk}_{d}]^\top \in \mathbb{R}^{d}:
\]
\begin{equation}
	\label{eq7}
	f_{ijk}(\mathbf{x}, \mathbf{w}_{ijk}) = \langle \mathbf{x}, \mathbf{w}_{ijk} \rangle.
\end{equation}

Для модели $f_{ijk}$ с соответствующим вектором параметров $\mathbf{w}_{ijk} \in \mathbb{R}^{d}$ определим квадратичную функцию потерь с $L_2$-регуляризацией:
\begin{equation}
	\label{eq8}
	\mathcal{L}_{ijk}(\mathbf{w}_{ijk}) = \sum\limits_{\ell = 2}^{N} \big(f_{ijk}(\mathbf{x}_{\ell}, \mathbf{w}_{ijk}) - \delta^{\ell}_{ijk}\big)^2 + \alpha \| \mathbf{w}_{ijk} \|_2^2,
\end{equation}
где $\alpha \in \mathbb{R}$~--- коэффициент регуляризации.

Требуется найти параметры, доставляющие минимум функционалу потерь $\mathcal{L}_{ijk}(\mathbf{w}_{ijk})$ при заданных гиперпараметрах $\Delta t$ и $\alpha$.
Задача оптимизации формулируется следующим образом:
\begin{equation}
	\label{eq9}
	\hat{\mathbf{w}}_{ijk} = \arg\min_{\mathbf{w}_{ijk}} \mathcal{L}_{ijk}(\mathbf{w}_{ijk}).
\end{equation}

Минимум функции потерь находится методом наименьших квадратов.
Введем матрицу объектов-признаков
\begin{equation}
	\label{eq10}
	\mathbf{X} = [\mathbf{x}_2, \ldots, \mathbf{x}_N]^\top = [x^i_j] \in \mathbb{R}^{(N-1) \times d}
\end{equation}
и вектор, компонентами которого являются разности значений одного и того же вокселя на разных изображениях:
\begin{equation}
	\label{eq11}
	\mathbf{\Delta}_{ijk} = [\delta^2_{ijk}, \ldots, \delta^N_{ijk}]^\top \in \mathbb{R}^{N-1}.
\end{equation}

Решение задачи оптимизации записывается в виде
\begin{equation}
	\label{eq12}
	\hat{\mathbf{w}}_{ijk} = (\mathbf{X}^\top \mathbf{X} + \alpha \mathbf{I})^{-1} \mathbf{X}^\top \mathbf{\Delta}_{ijk}.
\end{equation}

Выведем формулу для восстановленных фМРТ-изображений.
Введем матрицу весов
\begin{equation}
	\label{eq13}
	\hat{\mathbf{W}} = [\hat{\mathbf{w}}_1, \ldots, \hat{\mathbf{w}}_{XYZ}]^\top = [\hat{w}^i_j] \in \mathbb{R}^{XYZ \times d}.
\end{equation}

Введем для тензоров $\mathbf{s}_{\ell}, \boldsymbol{\delta}_{\ell} \in \mathbb{R}^{X \times Y \times Z}$ векторы
\[ \mathbf{s}_{\ell}^{R} = [ v^{\ell}_1, \ldots, v^{\ell}_{XYZ} ]^\top, \boldsymbol{\delta}_{\ell}^{R} = [ \delta^{\ell}_1, \ldots, \delta^{\ell}_{XYZ} ]^\top \in \mathbb{R}^{XYZ}. \]

Тогда вектор прогнозируемого изображения находится по формуле
\begin{equation}
	\label{eq14}
	\hat{\mathbf{s}}_{\ell}^{R} = \mathbf{s}_{\ell-1}^{R} + \hat{\boldsymbol{\delta}}_{\ell}^{R} = \mathbf{s}_{\ell-1}^{R} + \hat{\mathbf{W}} \mathbf{x}_{\ell}.
\end{equation}

\section{Качество данных в задаче детекции машинно-генерированного контента}

В предыдущих разделах рассматривались методы управления сложностью моделей и данных в контексте обучения.
В настоящем разделе акцент смещается на оценку качества самих данных, что является критически важным аспектом для обеспечения надежности моделей машинного обучения.
Низкое качество обучающих данных может приводить к завышенным оценкам производительности моделей и их неспособности к обобщению на реальные данные.
Это особенно актуально для задачи детекции машинно-генерированного контента, где качество обучающих наборов напрямую влияет на надежность детекторов.

В последние годы появилось значительное количество AI-детекторов и коллекций с AI-фрагментами.
Несколько методов детекции продемонстрировали качество распознавания до 99,9\% согласно целевым метрикам в таких коллекциях.
Однако качество таких детекторов часто резко падает в реальных условиях, что ставит вопрос о надежности детекторов: действительно ли они высоконадежны, или их высокие бенчмарк-показатели связаны с низким качеством оценочных наборов данных?
Подчеркнем необходимость создания надежных и качественных методов оценки сгенерированных данных, которые были бы устойчивы к смещениям и низкой способности к обобщению будущих моделей.
В настоящем разделе рассматриваются работы, посвященные детекции AI-генерированного контента, и предлагаются методы оценки качества наборов данных, содержащих AI-фрагменты.

Предлагается оценить различные наборы данных с едиными настройками, чтобы увидеть, насколько хорошо стандартные подходы работают на них.
Целью исследования является не достичь максимальных показателей, а сравнить производительность одного и того же метода на разных наборах данных.

\paragraph{Базовые методы.} Для методов, основанных на возмущениях, использовался фреймворк DetectGPT с GPT-2~\cite{radford2019language} в качестве базовой модели и T5-Large \cite{t5} в качестве генератора возмущений.
Однако из-за высоких вычислительных затрат DetectGPT использовался Fast-DetectGPT~\cite{fast-detectgpt}, который заменяет этап возмущения в DetectGPT более эффективным этапом сэмплирования.
Для методов zero-shot использовался Binoculars~\cite{hans2024spotting} с улучшенной оценкой перплексии.
Эти два базовых метода не требуют тонкой настройки, что является важным аспектом для задачи детекции, поскольку обучать детектор для каждого домена и генератора непрактично.
Наконец, в качестве метода на основе энкодера использовалась модель
mDeBERTa~\cite{he2021deberta}, которая является современной моделью для детекции машинно-генерированного текста в мультиязычном контексте~\cite{macko-etal-2023-multitude}.
Эти три детектора, охватывают все основные категории детекторов.

\paragraph{Топологическая статистика.} В работе \cite{Tulchinskii_phd} было показано, что если рассмотреть внутреннюю размерность многообразия на множестве эмбеддингов, то можно отделить тексты, написанные человеком, от машинно-сгенерированных.
Авторы использовали размерность персистентной гомологии (англ. PHD) и показали, что статистически тексты, сгенерированные человеком, имеют более высокую PHD, чем машинно-сгенерированные тексты, предложив таким образом новый детектор.
Дополнительно, в ~\cite{kushnareva2024boundary} было предложено вычислять PHD внутри скользящего окна.
Эти внутренние размерности текста в пределах скользящего окна могут быть использованы в качестве признака для детекторов.
Авторы демонстрируют, что метрика устойчива к изменению домена и генераторов.
Для возможности сравнения наборов данных между собой разработана симметричная оценка, использующая KL-дивергенцию.
Пусть $h_d$, $m_d$~--- распределения внутренних размерностей для двух типов текстов из одного набора данных, человеческого и машинного происхождения, тогда наша оценка $\text{KL}_{\text{TTS}}$ выглядит следующим образом:
\[
    \text{KL}_{\text{TTS}} (h_d, m_d) = | D_{\text{KL}}(h_d || m_d) - D_{\text{KL}}(m_d || h_d) |
\]
Чем ниже эта оценка, тем ближе друг к другу $h_d$ и $m_d$, что означает почти неразличимые тексты, и наоборот.

\paragraph{Возмущения и перемешивание.} Основываясь на результатах исследований модификации текста~\cite{sadasivan2024can, mitchell2023detectgpt}, которые показывают, как небольшие возмущения влияют на системы машинного понимания текста, рассмотривается этот способ как возможный метод оценки качества набора данных.
Ключевая идея заключается в том, что ИИ-модели чувствительны к таким адверсарным изменениям, в отличие от людей.
Рассматриваются две модификации: Адверсарное возмущение токенов и перемешивание предложений.

В данном подходе текст разбивается на токены, и каждый токен случайным образом заменяется на синоним из коллекции WordNet~\cite{wordnet} с вероятностью 70\%.
Далее данная техника применяется к каждому представленному классу, и с использованием модели-энкодера получаются эмбеддинги для каждого из текстов в текущем наборе данных.
Наконец, измеряются средние сдвиги эмбеддингов для классов человеческих и сгенерированных текстов, используя косинусное расстояние между эмбеддингами исходных текстов и модифицированных.
В итоге, после модификаций получаем $\Delta_{\text{shift}}$~--- логарифм разности средних сдвигов эмбеддингов.
\[
    \Delta_{\text{shift}} = \log \frac{{\frac{1}{n} \sum_{i=1}^{n} \text{cos}_d(h_{h_i}^o, h_{h_i}^p)}}{{\frac{1}{m}\sum_{j=1}^{m} \text{cos}_d(h_{m_j}^o, h_{m_j}^p)}},
\]
где~$n$ и~$m$~--- количество примеров в человеческой и сгенерированной частях набора данных соответственно, $h_{h_i}^o$~--- эмбеддинг $i$-го фрагмента человеческой части данных, $h_{h_i}^p$~--- тот же эмбеддинг после пертурбации.
Аналогично, $h_{m_i}^o$ и $h_{m_i}^p$~--- эмбеддинги для машинно-сгенерированных текстов.
Функция $\text{cos}_d$ измеряет косинусное расстояние между двумя векторами.

В данном подходе предложения случайным образом меняются местами, что влияет на связность текста.
Фрагмент разделяется на предложения, и случайным образом изменяется порядок 70\% выбранных предложений.
Данная техника применяется к каждому представленному классу.
Затем, используя модель кодирования текста, получаются эмбеддинги для каждого из текстов текущего набора данных.
Наконец, выполняется измерение сдвига эмбеддингов для класса человеческих и сгенерированных текстов, после чего сдвиги преобразуются в распределения, подобные вероятностным.
Это в итоге приводит к~$\text{KL}_{\text{shuffle}}(H,M)$~--- дивергенции Кульбака-Лейблера между сдвигами человеческих и сгенерированных текстов.
\[
    \text{KL}_{\text{shuffle}}(H,M)= \sum_{i} H(i) \log \frac{H(i)}{M(i)},
\]
\[
    H(i) = \frac{\text{cos}_d(h_{h_i}^o, h_{h_i}^p) + \epsilon}{\sum_j \left(\text{cos}_d(h_{h_j}^o, h_{h_j}^p) + \epsilon\right)},
\]
где $M(i)$ имеет ту же структуру, что и $H(i)$, за исключением того, что вместо текстов человеческого класса используются тексты сгенерированного класса, $\epsilon$~--- малая константа, добавляемая для избежания деления на ноль.

\section{Результаты вычислительных экспериментов}

\subsection{Сложность моделей в многозадачном обучении}

\begin{figure}[ht]
  \centering
    \includegraphics[width=0.75\linewidth]{thesis/figures/chapter-5/rademacher/lora_rank_vs_f1-1.pdf}
    \caption{Зависимость метрики $F_1$ от ранга $r$ адаптеров LoRA для модели DeBERTa-v3-base на задаче детекции машинно-генерированного текста. Наилучшая производительность достигается при $r=8$, что указывает на снижение отдачи при увеличении ранга и подтверждает эффективность низкоранговой параметризации.}
    \label{fig:r_vs_f1}
\label{fig:lora_rank}
\end{figure}

Для эмпирической проверки теоретических свойств, установленных выше, рассматривается задача обнаружения машинно-генерированного текста.
Данная задача формулируется как проблема бинарной классификации, что служит компактным, но информативным эталоном для оценки как прогнозной производительности, так и эффективности обучения. 

Выбор данной задачи мотивирован ее практической значимостью, разнообразием доменов в наборе данных и необходимостью эффективных стратегий адаптации для достижения сильного обобщения.

В качестве набора данных используется GenAI Detection Challenge (COLING~2025, Task~1), представленный в~\cite{wang2025genaicontentdetectiontask}.
Из исходных 600 000 примеров выбирается 60 000 для обучения и 5 000 для тестирования, сохраняя распределение меток. 

Набор данных охватывает широкий спектр доменов.
Внутрираспределительные категории включают финансы, право, психологию, новости и медицину.
Внераспределительные категории включают эссе IELTS, научные статьи, биомедицинские аннотации и юридические статьи. 

Результаты предыдущих соревнований указывают на то, что стандартные методы тонкой настройки испытывают трудности при достижении сильного обобщения на этом гетерогенном тестовом наборе, что подчеркивает необходимость более эффективных стратегий адаптации.

В экспериментах фиксируется энкодер как DeBERTa-base~\cite{he2023debertav3improvingdebertausing}, который продемонстрировал высокую производительность в недавних задачах классификации текста. 
Для анализа качества рассматриваются следующие метрики: точность (accuracy), точность (precision), полнота (recall), F1-мера, потеря на валидации и общее время обучения.

Для эмпирической проверки гарантии корректности для моделей Transformer с добавлением LoRA (теорема~\ref{theorem:lowrank}) выполняется сравнение DeBERTa-v3-base в двух режимах тонкой настройки: полная тонкая настройка всех параметров и адаптация с помощью LoRA.
Цели эксперимента состоят в следующем: (i) подтвердить, что LoRA сохраняет прогнозную корректность, существенно сокращая сложность параметров, и 
(ii) проверить, что теоретические выгоды в эффективности транслируются в сокращение времени обучения. 
Все условия обучения сохраняются идентичными, а полные детали гиперпараметров приведены в дополнительных материалах.

При полной тонкой настройке обновляются все параметры DeBERTa-v3-base.
Для LoRA исходные веса замораживаются, а низкоранговые адаптеры вставляются в каждый блок Transformer с рангом $r=8$, коэффициентом масштабирования $\alpha=32$ и долей отсева (dropout) для адаптеров $0.1$. 
Эта конфигурация была выбрана после дополнительного анализа чувствительности к рангу, представленного на рис.~\ref{fig:lora_rank}.

Результаты суммированы в таблице~\ref{tab:combined}.
По сравнению с полной тонкой настройкой, LoRA демонстрирует лишь незначительное снижение прогнозных метрик (1.4–3.2\%), при этом обеспечивая существенно более низкие потери на валидации (снижение на 0.657, или 36.3\%). 

Дополнительная диагностика, представленная в дополнительных материалах, показывает более гладкие нормы градиентов и траектории потерь при обучении для LoRA.
Это свидетельствует о более стабильной сходимости и большей эмпирической устойчивости LoRA по сравнению с полной тонкой настройкой.
Полученные результаты согласуются с теоретической гарантией о том, что низкоранговые обновления сохраняют корректность выходного слоя (теорема~\ref{theorem:lowrank}).
Для оценки вычислительной эффективности также рассматривается общее время обучения.
LoRA обеспечивает ускорение в 12.6\%, что указывает на то, что низкоранговая адаптация снижает эффективную сложность и ускоряет оптимизацию при незначительной потере в метриках, основанных на точности.

\begin{table}[h!t]
    \caption{Сравнение производительности модели DeBERTa-v3-base при полной тонкой настройке и адаптации с LoRA на задаче детекции машинно-генерированного текста. LoRA демонстрирует незначительное снижение метрик точности (1.4--3.2\%), но обеспечивает существенное снижение потерь на валидации (36.3\%) и ускорение обучения (12.6\%), что подтверждает теоретические гарантии корректности выходного слоя при низкоранговых обновлениях.}
    \label{tab:combined}
    \centering
    \begin{tabular}{l c c c} 
    \toprule
    Metric & DeBERTa & DeBERTa \& LoRA & Change (\%) \\
    \midrule
    Accuracy $\uparrow$        & 0.7104 & 0.6876 & $-3.2$ \\
    Precision $\uparrow$      & 0.6573 & 0.6413 & $-2.4$ \\
    Recall $\uparrow$         & 0.9608 & 0.9470 & $-1.4$ \\
    $F_{1}$-score $\uparrow$  & 0.7806 & 0.7648 & $-2.0$ \\
    \midrule
    Validation Loss $\downarrow$ & 1.8094 & \textbf{1.1522} & $+36.3$ \\
    Training Time (s) $\downarrow$ & 5570 & \textbf{4867} & $+12.6$ \\
    \bottomrule
    \end{tabular}
\end{table}

Задача GenAI Detection предоставляет, помимо бинарной метки, вспомогательные метаданные, такие как поддомен и источник benchmark.
Эта информация используется для создания многозадачной постановки с тремя выходными головками: исходная задача бинарной классификации и две вспомогательные многоклассовые задачи.
Такая конфигурация побуждает модель изучать более богатые текстовые представления и отражает теоретическое преимущество MTL в снижении сложности на задачу.

На основе аналитического результата об эффективности Радемахера (теорема~\ref{thm:per-task-rc-fair-scaling}) выполняется адаптация~DeBERTa-base для выполнения необходимых предположений.
Обеспечивается: (i) ограничения нормы весов через проецирование параметров на $L_2$-шары после каждого обновления; (ii) липшицева непрерывность с помощью спектральной нормализации всех линейных слоев; и (iii) ограниченность входов через нормализацию токенных эмбеддингов. 

Эти модификации гарантируют, что эмпирическая установка соответствует теоретическим условиям, позволяя проводить валидную оценку преимуществ MTL в рамках установленной схемы.
Подробный процесс подготовки модели описан в дополнительных материалах.

Сначала оценивается прогнозная производительность в условиях STL и MTL.
Выполняется обучение двух вариантов: (i) базовой STL-модели с частичной тонкой настройкой энкодера и классификационной головой, и (ii) MTL-модели с общим энкодером, обновляемым совместно по всем трем задачам. 

На этапе тестирования для MTL-модели используется только общий энкодер и бинарная голова, отбрасывая вспомогательные головы.
Результаты в таблице~\ref{tab:stl-mtl-performance-erc} показывают, что включение вспомогательных задач в процесс обучения улучшает точность на исходной бинарной задаче, подтверждая, что многозадачные сигналы действуют как полезное индуктивное смещение.

\begin{table}[t]
    \caption{Сравнение производительности и эмпирической сложности Радемахера (ERC) модели DeBERTa-v3-base в условиях однозадачного (STL) и многозадачного (MTL) обучения на задаче бинарной классификации GenAI Detection. MTL демонстрирует улучшение всех метрик качества (F1: 0.781→0.826, ROC-AUC: 0.788→0.834) и снижение ERC с $0.0159 \pm 0.0009$ до $0.0111 \pm 0.0010$, что согласуется с теоретическим предсказанием снижения сложности на задачу в $1/\sqrt{T}$ раз.}
    \label{tab:stl-mtl-performance-erc}
    \begin{center}
    \begin{tabular}{@{}lccccc@{}}
    \toprule
    Model & Mode & F1 $\uparrow$ & ROC--AUC $\uparrow$ & Acc. $\uparrow$ & ERC $\downarrow$ \\
    \midrule
    DeBERTa & STL & 0.781 & 0.788 & 0.710 & $0.0159 \pm 0.0009$ \\
    DeBERTa & MTL & \textbf{0.826} & \textbf{0.834} & \textbf{0.781} & $\mathbf{0.0111} \pm \mathbf{0.0010}$ \\
    \bottomrule
    \end{tabular}
    \end{center}
\end{table}

Далее, для оценки не только прогнозных улучшений, но и сложности модели на целевой задаче, выполняется прямое сравнение эмпирической сложности Радемахера (ERC).
В соответствии с определением, ERC измеряется на тех же данных, что использовались для обучения, после замены истинных меток случайным шумом. 

Это гарантирует, что оценка отражает только емкость гипотезного класса, а не информацию о реальных метках.
После обучения ERC оценивается исключительно для целевой задачи как для STL, так и для MTL.
Результаты представлены в колонке ERC в таблице~\ref{tab:stl-mtl-performance-erc}. 

Более подробное описание процесса проведения обоих экспериментов приведено в дополнительных материалах.

Анализ показывает, что MTL не только улучшает прогнозную производительность, но и достигает более низкой эмпирической сложности Радемахера по сравнению с STL.
Это демонстрирует, что вспомогательные задачи обеспечивают полезное индуктивное смещение, которое как улучшает обобщающую способность на целевой задаче, так и эффективно снижает сложность на задачу, что согласуется с предсказанным снижением на $1/\sqrt{T}$ из нашего теоретического анализа.

\begin{table}[h!t]
  \centering
  \caption{Сравнение моделей DeBERTa-v3-base при полной тонкой настройке и адаптации с LoRA ($r=8$) после 5 эпох обучения. LoRA обеспечивает более низкие потери (0.2972 vs 0.3058), более гладкие нормы градиентов (17.41 vs 24.65) и требует только 0.16\% параметров от полной модели (296{,}450 vs 184M), демонстрируя эффективность низкоранговой адаптации.}
  \label{tab:models_comparison}
  \begin{tabular}{lccccc}
    \toprule
    Model & Loss & Grad. Norm & Runtime (s) & Params & Epochs \\
    \midrule
    Full Tuning & 0.3058 & 24.65 & 679{,}660 & 184M (100\%) & 5 \\
    LoRA ($r=8$) & 0.2972 & 17.41 & 700{,}284 & 296{,}450 ($\approx$0.16\%) & 5 \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[h!t]
  \centering
  \caption{Сравнение конфигураций LoRA с различными рангами $r \in \{8, 16, 32\}$ для модели DeBERTa-v3-base. Анализ показывает, что более высокие ранги ($r=32$) обеспечивают более низкие потери при обучении, но $r=8$ обеспечивает лучшее обобщение, что подтверждает оптимальность низкоранговой параметризации для данной задачи.}
  \label{tab:lora_rank}
  \begin{tabular}{lccc}
    \toprule
    \textbf{Rank ($r$)} & Loss & Grad. Norm & Runtime (s) \\
    \midrule
    8  & 0.3413 & 2.95 & 1681 \\
    16 & 0.3358 & 5.18 & 1684 \\
    32 & 0.3194 & 2.55 & 1688 \\
    \bottomrule
  \end{tabular}
\end{table}

Все исходные параметры DeBERTa были заморожены, а низкоранговые адаптерные модули были вставлены в каждый блок трансформера.
Ранг адаптера выбран~$r=8$, коэффициент масштабирования $\alpha=32$ и использовался dropout $0.1$ в слоях адаптера.
Данная конфигурация выбрана как наиболее эффективная после проведения поиска по сетке для $r=\{8, 16, 32\}$.
Это оставляет обучаемыми только 296 450 параметров из 184 млн общих ($\approx0.16\%$), что согласуется с теоретической мотивацией снижения размерности.
Все конфигурации экспериментов указаны в таблице~\ref{tab:models_comparison}.

Кроме того, на рис.~\ref{fig:combined} представлена производительность модели: модели DeBERTa и DeBERTa~\&~LoRA обучались в течение 5 эпох с размороженными 6 слоями из 12.
Анализ показывает, что норма градиента является значительно более гладкой для модели, использующей LoRA, по сравнению с моделью без нее.
Тот же эффект наблюдается на графике функции потерь обучения: потери при обучении модели с LoRA являются более гладкими и сходятся быстрее, чем у модели без нее.

Для определения оптимального ранга адаптера сравнивается~$r=8, 16, 32$ с точки зрения потерь при обучении, представленных на рис.~\ref{fig:r_vs_loss}.
Хотя более высокие ранги, в частности $r=32$, демонстрировали более быструю сходимость и более низкие финальные потери при обучении, $r=8$ обеспечивает лучшее обобщение, несмотря на более медленную сходимость.
В целом, $r=8$ был выбран в качестве наиболее эффективной конфигурации в текущей настройке.
Конфигурации экспериментов показаны в таблице~\ref{tab:lora_rank}.

На основе аналитических результатов об эффективности Радемахера выполняется адаптация~\texttt{DeBERTa-base} для выполнения необходимых предположений.
Введенные модификации гарантируют, что эмпирическая установка соответствует теоретическим условиям, позволяя провести валидную оценку преимуществ MTL в рамках установленной схемы.
Подробный процесс подготовки описан в Алгоритме~\ref{alg:theorem-constraints}.

\begin{algorithm}[h!t]
    \caption{Алгоритм обеспечения условий теоремы~\ref{thm:per-task-rc-fair-scaling} для оценки эмпирической сложности Радемахера (ERC) с использованием модели DeBERTa. Алгоритм применяет спектральную нормализацию к линейным слоям энкодера, нормализует входные последовательности и проецирует параметры на $L_2$-шары для выполнения ограничений на нормы весов, необходимых для теоретического анализа.}\label{alg:theorem-constraints}
    \KwIn{Модель $f_t(x) = w_t^\top \phi(x; w_{\text{shared}})$, с ограничениями~$B_{\text{shared}}, B_{\text{head}}, R$}
    \KwOut{Модель удовлетворяющая условиям теоремы~\ref{thm:per-task-rc-fair-scaling}.}
    \ForEach{linear layer $W$ in encoder $\phi(\cdot; w_{\text{shared}})$}{
        $W \leftarrow \text{SpectralNorm}(W)$ \tcp*{$\|\phi(x;w)\|_2 \leq L\|w\|\|x\|_2$}
    }
    \ForEach{input sequence $x = [x_1 \dots x_m]$}{
        $\widetilde{x}_i \leftarrow x_i / \max(1, \|x_i\|_2) \quad \forall i$
        $x \leftarrow \left[\widetilde{x}_1 \dots \widetilde{x}_m\right] \cdot \min\left(1, \frac{R}{\|\widetilde{x}\|_F}\right)$ \tcp*{$\|x\| \leq R$}
    }
    \ForEach{training step}{
        \ForEach{parameter group $(w, B)$ in $\{(w_{\text{shared}}, B_{\text{shared}})\} \cup \{(w_t, B_{\text{head}}) \mid t \in [T]\}$}{
            $w \leftarrow w \cdot \min\left(1, \dfrac{B}{\|w\|_2}\right)$ \tcp*{$\|w\|_2 \leq B$}
        }
    }
\end{algorithm}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{thesis/figures/chapter-5/rademacher/r_vs_loss.png}
    \caption{Динамика потерь при обучении модели DeBERTa-v3-base с адаптерами LoRA различных рангов ($r \in \{8, 16, 32\}$) на задаче детекции машинно-генерированного текста. Анализ показывает, что более высокие ранги обеспечивают более быструю сходимость и более низкие финальные потери, но $r=8$ обеспечивает лучшее обобщение, что подтверждает оптимальность низкоранговой параметризации.}
    \label{fig:r_vs_loss}
\end{figure}

\begin{figure}[htbp]
    \centering
    \subfloat[Норма градиента]{\includegraphics[width=0.75\textwidth]{thesis/figures/chapter-5/rademacher/Gradient_norm.png}}\\
    \subfloat[Ошибка на обучающей выборке]{\includegraphics[width=0.75\textwidth]{thesis/figures/chapter-5/rademacher/Loss.png}}\\
    \caption{Динамика нормы градиента и потерь при обучении моделей DeBERTa-v3-base с полной тонкой настройкой и адаптацией LoRA ($r=8$) в течение 5 эпох на задаче детекции машинно-генерированного текста. LoRA демонстрирует более гладкие траектории нормы градиента и потерь, что указывает на более стабильную сходимость и большую эмпирическую устойчивость по сравнению с полной тонкой настройкой.}
    \label{fig:combined}
\end{figure}

Для оценки ERC обучается как STL, так и MTL модели в контролируемых и сопоставимых условиях.
В обоих случаях использовалось одинаковое общее количество обучающих примеров (\(nT\)), что гарантирует, что любые наблюдаемые различия в ERC вызваны совместным использованием параметров, а не дисбалансом данных.

В эксперименте STL использовался энкодер \texttt{DeBERTa-v3-base} с одной бинарной классификационной головой, соответствующей целевой задаче.
Модель обучалась на \(nT = 90{,}000\) примерах (\(n = 30{,}000\), \(T = 3\)), выбранных исключительно из набора данных целевой бинарной классификации.
Чтобы гарантировать, что ERC отражает репрезентационную способность модели, а не ее соответствие истинному распределению меток, все целевые метки были заменены случайным шумом из \(\{-1, 1\}\).
Энкодер и классификационная головка подвергались тонкой настройке на этих зашумленных метках в течение 3 эпох.
После обучения ERC вычислялась на том же наборе данных со случайными метками.

В настройке MTL использовался тот же энкодер DeBERTa-v3-base, разделяемый между \(T=3\) классификационными головками.
Одна головка соответствовала целевой бинарной задаче, в то время как две другие обучались на вспомогательных многоклассовых задачах: предсказание поддомена с 5 классами и предсказание поддомена с 6 классами.
Каждая задача предоставляла \(n = 30{,}000\) примеров, так что общий энкодер обрабатывал в сумме \(nT = 90{,}000\) обучающих примеров.
Только вспомогательные задачи использовали свои исходные метки; целевая задача использовала зашумленные метки для обеспечения независимости от емкости модели.
После обучения ERC оценивалась только на подмножестве целевой задачи.

Данная процедура гарантирует, что как STL, так и MTL модели обучались в идентичных условиях по объему данных и вычислительным ресурсам.
Следовательно, наблюдаемое снижение ERC типа \(1/\sqrt{T}\) непосредственно количественно оценивает эффект совместного использования параметров энкодера на эффективную емкость модели.

\subsection{Снижение сложности данных в задаче декодирования фМРТ-снимков}

Для анализа производительности предложенного метода и проверки гипотез был проведен вычислительный эксперимент.
В качестве данных использовалась выборка, представленная в~\cite{Berezutskaya2022}. 

Набор данных содержит результаты обследования 63 испытуемых.
Для тридцати из них известны данные фМРТ.
В выборке 16 мужчин и 14 женщин в возрасте от 7 до 47 лет.
Средний возраст испытуемых составляет 22 года.
Характеристики выборки: продолжительность обследования, частоты кадров видеопоследовательностей фМРТ и изображений, а также их размеры суммированы в таблице~\ref{table:sample}.

\begin{table}[h!t]\center
    \caption{Характеристики выборки для эксперимента по декодированию фМРТ-изображений из видеопоследовательностей. Выборка содержит данные 30 испытуемых с продолжительностью обследования 390 с, частотой кадров видео 25 Гц и частотой фМРТ-изображений 1.64 Гц, что обеспечивает временное соответствие между видеокадрами и томографическими данными.}\label{table:sample}
    \begin{tabular}{@{}ccc@{}}
    \toprule
    Name & Notation & Value \\ 
    \midrule
    Duration of examination & $t$ & 390 s \\
    Video frame rate & $\nu$ & 25 Hz \\
    fMRI frame rate & $\mu$ & 1.64 Hz \\
    Video dimensions & $W, H, C$ & 640, 480, 3 \\
    fMRI dimensions & $X, Y, Z$ & 40, 64, 64 \\
    \bottomrule
    \end{tabular}
\end{table}

Выборка разделена на обучающую и тестовую части в соотношении 70\% и 30\% соответственно.
Критерием качества реконструкции фМРТ-изображений является MSE~--- сумма квадратов отклонений между истинными и реконструированными изображениями, усредненная по всем вокселям каждого изображения из тестовой выборки.

Для сокращения времени работы алгоритма фМРТ-изображение предварительно сжимается с использованием слоя MaxPool3D.
Рассматриваются коэффициенты сжатия 1, 2, 4 и 8.
Значения вокселей нормализованы к диапазону $[0; 1]$ с помощью процедуры MinMaxScale.

Была проанализирована зависимость MSE от параметра регуляризации $\alpha$.
Рассматривались коэффициенты сжатия 1, 2, 4 и 8.
Соответствующие графики показаны на рис.~\ref{fig:mse-alpha}.
Для построения графика было выполнено усреднение по испытуемым.
Показаны границы стандартного отклонения.
Графики демонстрируют, что оптимальное значение коэффициента $\alpha \approx 1000$.
Форма кривой сохраняется независимо от коэффициента сжатия фМРТ-изображений.
\begin{figure}[h!t]\centering
	\includegraphics[width=0.65\textwidth]{thesis/figures/chapter-5/fmri/subs_MSE_alpha}
	\caption{Зависимость метрики MSE от параметра регуляризации $\alpha$ для метода декодирования фМРТ-изображений на тестовой выборке при различных коэффициентах сжатия (1, 2, 4, 8). Оптимальное значение коэффициента $\alpha \approx 1000$ сохраняется независимо от коэффициента сжатия, что подтверждает стабильность метода при снижении размерности данных.}
	\label{fig:mse-alpha}
\end{figure}

Выполняется сравнение времени обучения модели при использовании различных коэффициентов сжатия фМРТ-изображений.
Рассматриваются коэффициенты 1, 2, 4 и 8.
Для каждого значения коэффициента сжатия вычисляется среднее значение времени обучения модели для всех испытуемых. 

Результаты экспериментов представлены в таблице~\ref{table:coeffs}.
Время работы метода существенно сокращается при использовании предварительного сжатия фМРТ-изображений.
Эксперимент с подбором оптимального коэффициента регуляризации подтверждает, что сжатие изображений не изменяет характер зависимостей между параметрами и качеством реконструкции.

\begin{table}[h!t]\center
    \caption{Зависимость среднего времени обучения модели декодирования фМРТ-изображений от коэффициента сжатия данных. Использование предварительного сжатия фМРТ-изображений с коэффициентами 2, 4 и 8 обеспечивает существенное сокращение времени обучения (с 36.3 с до 6.7 с, 1.6 с и 1.4 с соответственно), что демонстрирует эффективность снижения сложности данных без потери качества реконструкции.}\label{table:coeffs}
    \begin{tabular}{@{}ccc@{}}
    \toprule
    Compression coefficient & Mean time, s & Std, s \\
    \midrule
    1 & 36.3 & 6.1 \\
    2 & 6.7 & 0.5 \\
    4 & 1.6 & 0.1 \\
    8 & 1.4 & 0.3 \\
    \bottomrule
    \end{tabular}
\end{table}

\subsection{Качество данных в задаче детекции машинно-генерированного контента}

\begin{table}[h!t]\centering
    \begin{tabular}{c|c|c|c}
    \toprule    
        Dataset & DeBERTa & Binoculars & DetectGPT \\
    \midrule
        GPT-2 &  0.972 & 0.495 & 0.412\\ 
        HC3 & 0.998 &  0.931 & 0.972 \\
        GhostBuster & 0.910 &   0.683  &  0.711 \\
        MGTBench & 0.961 & 0.364 & 0.447 \\
        MAGE &  0.835 &  0.632 &  0.654 \\
        M4 & 0.987 &  0.871 &  0.881   \\
        OutFox & 0.901 & 0.692 & 0.707 \\
        TweepFake & 0.941 & 0.845 & 0.864 \\ 
    \midrule
        SemEval24 Mono & 0.991 & 0.913 & 0.924 \\
        SemEval24 Multi & 0.994 & -- & --\\
        RuATD & 0.765 & -- & -- \\
        DAGPap22 &  0.968 & 0.333 & 0.562 \\
        PAN24  & 0.826 &  0.411 & 0.890 \\
        AuTex23en & 0.941 & 0.783 & 0.911\\
        AuTex23es & 0.933 & -- & --\\
        IberAuTex & 0.964 & -- & --\\
        MGT-1 Mono & 0.904 & 0.665 & 0.683 \\
        MGT-1 Multi & 0.934 & -- & --\\
    \bottomrule    
    \end{tabular}
    \caption{Результаты классификации различных детекторов машинно-генерированного текста (DeBERTa, Binoculars, DetectGPT) на множественных наборах данных, оцененные с помощью метрики $F_1$-score. Детектор на основе DeBERTa демонстрирует наиболее стабильную производительность на различных наборах данных, тогда как Binoculars и DetectGPT показывают значительные вариации, что указывает на проблемы с устойчивостью этих методов к различным доменам.}
    \label{tab:classifier}
\end{table}

\begin{table}[h!t]
    \centering
    \begin{tabular}{l|c|c|c|c|c}
    \toprule
        Dataset & $\text{KL}_{\text{TTS}}$ $\downarrow$ & $\text{PHD}_{\text{human}}$ & $\text{PHD}_{\text{machine}}$ &  $\Delta_{\text{shift}}$ $\downarrow$ &  $\text{KL}_\text{shuffle}$ $\downarrow$  \\
    \midrule
        GPT-2 & \textbf{0.014} & 9.23 $\pm$ 1.98 & 10.27 $\pm$ 1.84 &  0.084 & 1.255  \\
        HC3 & 0.053  & 8.76 $\pm$ 1.83 & 7.38 $\pm$ 1.05 & 0.264 &   1.167  \\
        GhostBuster & 0.053 & 9.84 $\pm$ 1.18 & 9.76 $\pm$ 1.15 & \textbf{0.024} &  \textbf{0.359}  \\
        MGTBench & 0.043  & 8.77 $\pm$ 1.31 & 9.97 $\pm$ 1.02 &  \textbf{0.031} &   \textbf{0.421} \\
        MAGE & \textbf{0.011}  & 9.8 $\pm$ 2.14 & 9.38 $\pm$ 3.04 & 0.094  & \textbf{0.310}  \\
        M4 & 0.036 & 7.26 $\pm$ 1.99 & 8.59 $\pm$ 1.4 & 0.107 &  \textbf{0.483}  \\
        OutFox & 0.025  & 8.96 $\pm$ 1.21 & 11.48 $\pm$ 1.13  & 0.095 & \textbf{0.237} \\
        TweepFake & \textbf{-} & 9.02 $\pm$ 3.19 & 8.12 $\pm$ 4.02 & 0.116 & 1.001 \\
    \midrule
        SemEval24 Mono & \textbf{0.012} & 9.11 $\pm$ 1.19 & 9.41 $\pm$ 1.2 &    0.191 &  2.576  \\
        SemEval24 Multi & \textbf{0.001}  & 9.65 $\pm$ 1.81 & 9.42 $\pm$ 1.44 &  0.059 &  2.046  \\
        RuATD & \underline{0.007} & 7.33 $\pm$ 1.4 & 7.46 $\pm$ 1.41 &  0.315 &  14.028  \\
        DAGPap22 & 0.083 & 8.35 $\pm$ 1.33 & 7.48 $\pm$ 2.01 &  \textbf{0.039} &   \textbf{0.472}  \\
        PAN24 & 0.053 & 9.4 $\pm$ 1.05 & 8.52 $\pm$ 1.59 &  \textbf{0.050} &  \textbf{0.331}  \\
        AuTex23 Eng & \underline{0.021} & 8.07 $\pm$ 2.26 & 8.1 $\pm$ 2.68 &  0.110 &  4.331 \\
        AuTex23 Esp &  \underline{0.001}& 9.16 $\pm$ 3.49 & 9.25 $\pm$ 3.26  &   0.105  &   1.306 \\
        IberAuTex & \textbf{0.012} & 9.33 $\pm$ 2.45 & 8.47 $\pm$ 2.73 &  0.223 & 5.516 \\
        MGT-1 Mono & \textbf{0.019} & 9.19 $\pm$ 1.75 & 8.96 $\pm$ 2.24 & \textbf{0.031} & 0.587\\
        MGT-1 Multi & \textbf{0.006} & 
8.76 $\pm$ 1.85 & 8.6 $\pm$ 2.29 &  \textbf{0.027} & 0.522\\
    \bottomrule    
    \end{tabular}
    \caption{Статистика качества данных для выбранных наборов данных детекции машинно-генерированного текста, включающая метрики $\text{KL}_{\text{TTS}}$, PHD, $\Delta_{\text{shift}}$ и $\text{KL}_\text{shuffle}$. Высокие значения метрик указывают на различимость текстов разного происхождения, тогда как низкие значения отражают схожую устойчивость к модификациям, что является признаком качественных данных.}
    \label{tab:results}
\end{table}

\begin{figure}[h!t]\centering
    \includegraphics[width=\textwidth]{thesis/figures/chapter-5/ai-datasets/violins_PHD}
    \caption{Распределения размерности персистентной гомологии (PHD) для человеческих и машинно-сгенерированных текстов в различных наборах данных детекции. Качественные наборы данных (SemEval, PAN24, MGT-1) демонстрируют схожие распределения PHD для обоих типов текстов, что указывает на высокое качество сгенерированных данных и их близость к человеческим текстам по топологическим характеристикам.}
    \label{fig:phd_values}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=1.00\textwidth]{thesis/figures/chapter-5/ai-datasets/4_datasets_TTS}
\caption{Топологические временные ряды (TTS) для четырех наборов данных с высокими значениями метрики $\text{KL}_{\text{TTS}}$: GhostBuster, PAN24, MGTBench и DAGPap22. Высокие значения $\text{KL}_{\text{TTS}}$ для GhostBuster и PAN24 обусловлены расхождением в текстах с более высокими размерностями, тогда как для MGTBench и DAGPap22~--- разницей в самих распределениях PHD, что указывает на различные типы различий между человеческими и машинно-сгенерированными текстами.} 
\label{tts}
\end{figure}

Из каждого набора данных выбрано 1000 документов из тестовой выборки, сбалансированных между двумя классами.
Для базовых методов выполняется тонкая настройка mdeberta-v3-base для каждого набора данных, после чего модель оценивается.
Для оценки качества Binoculars и Fast-DetectGPT использовался falcon-rw-1b~\cite{almazrouei2023falconseriesopenlanguage} и gpt-neo-2.7B~\cite{gpt-neo} соответственно.
Следует отметить, что для последних двух методов качество измерялось только на англоязычных выборках.
В эксперименте с топологическими признаками использовалась модель roberta-base, как и авторы оригинальной работы.
В эксперименте с пертурбациями и перемешиванием энкодер multilingual-e5-large использовался для построения эмбеддингов текстов, который показывает высокие метрики для кодирования высокоресурсных языков~\cite{e5}.
Результаты сравнения разработанных признаков в выбранных наборах данных представлены в таблице~\ref{tab:results}. 

Относительно PHD и оценки TTS, в предыдущих работах было показано, что тексты языковых моделей имеют меньшие значения PHD, чем написанные человеком.
Однако данный результат был получен для моделей GPT-2, GPT-3.5 и OPT.
Для более современных языковых моделей, которые генерируют более похожие на человеческие тексты, данная тенденция могла измениться. 

Высокое значение $\text{KL}_{\text{TTS}}$ для текстов разного происхождения означает, что детектору легче разделить такие тексты.
Следует отметить, что $\text{KL}_{\text{TTS}}$ также ограничена для более коротких текстов.
Относительно PHD предполагается, что сгенерированные тексты хорошего качества должны иметь PHD, аналогичный написанным человеком. 

Дополнительно сравниваются распределения PHD для всех наборов данных на рис.~\ref{fig:phd_values}.
Распределения для текстов обоих типов происхождения должны быть схожими, что в основном соблюдается для текстов из SemEval, PAN24 и MGT-1. 

В следующих столбцах приводится статистика, наблюдаемая на модифицированных текстах.
Для обеих метрик ($\Delta_{\text{shift}}$ и $\text{KL}_\text{shuffle}$) чем ниже значение, тем лучше, так как это отражает схожую степень устойчивости сгенерированных и человеческих текстов к адверсарным атакам.
Качественно сгенерированные данные без смещений должны принимать значения, близкие к человеческим.

В таблице~\ref{tab:classifier} показаны результаты применения современных детекторов к выбранным тестовым наборам данных.
На наборах данных с низкими значениями метрик качества в таблице~\ref{tab:results} может быть достигнуто качество, близкое к 1, что указывает на явное наличие смещения детектора в их сторону или структурной особенности, которая слишком очевидна для модели детекции. 

Невозможно судить о качестве данных только по достижению значений $F_1$, близких к 1.
Однако комбинирование значений двух таблиц позволяет оценить, какой набор имеет данные лучшего качества, а какой~--- худшего.

Относительно $\text{KL}_{\text{TTS}}$, на рис.~\ref{tts} показаны 4 набора данных с высоким значением этого показателя.
GhostBuster и PAN24 получили такой высокий балл из-за расхождения в текстах с более высокими размерностями, тогда как MGTBench и DAGPap22~--- из-за разницы в самих распределениях. 

Следует отметить, что $\text{KL}_{\text{TTS}}$ может плохо работать с очень короткими текстами, поскольку внутренний метод вычисления PHD требует достаточно длинных текстов для стабильного вычисления.
По этой причине $\text{KL}_{\text{TTS}}$ для RuATD, AuTex23-es и Tweepfake отбрасываются, так как они не соответствуют критериям.
Кроме того, показано, что тексты должны быть достаточной длины~\cite{gritsay2022automatic526652068} для построения надежных детекторов.

Анализ значений в таблице~\ref{tab:results} показывает наличие данных достаточно высокого качества в выбранных наборах данных.
Разработанные атрибуты в совокупности способны отражать качество сгенерированного набора данных с различных точек зрения. 

Предлагается использовать эти атрибуты в сочетании с другими статистическими инструментами для оценки качества данных, например, с законом Ципфа~\cite{zipf}.

Представленная статистика может быть использована для оценки качества коллекций и их улучшения.
Кроме того, наборы данных, собирающие машинно-генерированный контент, могут быть полезны для двух более общих целей.
Во-первых, высококачественные сгенерированные данные могут быть использованы для оценки качества каузальной модели во время обучения, что служит одной из целей обучения для улучшения ответов модели и приближения их к человеческим.
Во-вторых, хорошие детекторы могут помочь очистить обучающие наборы, поскольку большая доля низкокачественных сгенерированных текстов в этих наборах может привести к возникновению смещений в сторону некорректной структуры и артефактов в выходных данных модели в будущем.

Вопрос о том, означает ли низкая производительность детекторов низкое качество набора данных, не имеет однозначного ответа.
Например, в~\cite{hans2024spotting} метод Binoculars достигает оценки $F_1$, близкой к 1.0, в то время как в наших экспериментах был получен широкий диапазон оценок: от 0.33 на DAGPap22 до 0.93 на HC3.
Для HC3 все три детектора показали схожие результаты, что позволяет предположить, что тексты HC3 относительно легко обнаружить.
Однако данная согласованность не распространяется на DAGPap22.
Детектор на основе DeBERTa достиг оценки $F_1$ 0.96, в то время как DetectGPT показал только 0.562.
Данная закономерность, когда детектор на основе DeBERTa демонстрирует заметно более высокие результаты, чем два других метода, наблюдалась на значительной части проанализированных наборов данных.

Низкие оценки для Binoculars заслуживают дополнительного изучения.
Даже при фокусировке на доменах, специально протестированных его авторами, таких как PAN24 и Outfox, оценки оказываются значительно ниже почти идеальных результатов, представленных в~\cite{hans2024spotting}.
Данное расхождение позволяет предположить, что детектор Binoculars может быть нерепрезентативным.
Аналогично, в наших экспериментах оценки DetectGPT сопоставимы с оценками Binoculars, что указывает на схожие базовые проблемы с устойчивостью этих детекторов.

\section{Заключение по главе}

В настоящей главе продемонстрировано практическое применение теоретического аппарата оценки сложности моделей и данных, разработанного в главах~\ref{chapter:complexity} и~\ref{chapter:gesian}, к решению прикладных задач машинного обучения. 

В отличие от предыдущих глав, где основной акцент делался на разработке строгих математических оценок и методов анализа, здесь представлена адаптация теоретических подходов к реальным проблемам.
Глава охватывает три ключевых направления: (1) управление сложностью моделей в многозадачном обучении, (2) снижение сложности данных в задачах нейровизуализации и (3) оценка качества данных в задачах детекции машинно-генерированного контента.

В разделе о сложности моделей в многозадачном обучении получены фундаментальные теоретические результаты для адаптеров LoRA и многозадачного обучения.
Теорема~\ref{theorem:consistency} строго доказывает статистическую состоятельность минимизации эмпирического риска при параметризации LoRA, устанавливая, что низкоранговая адаптация сохраняет асимптотические статистические гарантии полной тонкой настройки.
Теорема~\ref{theorem:lowrank} доказывает корректность выходного слоя при низкоранговых обновлениях, показывая, что параметризация $\Delta W = AB$ с $r \ll \min(d,k)$ не искажает выходное распределение или классификационные границы модели.
Теорема~\ref{thm:per-task-rc-fair-scaling} устанавливает снижение эмпирической сложности Радемахера на задачу в $1/\sqrt{T}$ раз при многозадачном обучении с соответствующим масштабированием, что количественно характеризует преимущества совместного использования параметров энкодера.

Эмпирические эксперименты на задаче детекции машинно-генерированного текста (GenAI Detection Challenge) подтвердили теоретические предсказания.
LoRA-адаптеры с рангом $r=8$ демонстрируют незначительное снижение метрик точности (1.4--3.2\%) по сравнению с полной тонкой настройкой, но обеспечивают существенное снижение потерь на валидации (36.3\%) и ускорение обучения (12.6\%), требуя при этом только 0.16\% параметров от полной модели.
Многозадачное обучение с тремя выходными головками улучшает метрики качества (F1: 0.781→0.826, ROC-AUC: 0.788→0.834) и снижает эмпирическую сложность Радемахера с $0.0159 \pm 0.0009$ до $0.0111 \pm 0.0010$, что количественно подтверждает теоретическое предсказание снижения сложности на задачу в $1/\sqrt{T}$ раз.

В разделе о снижении сложности данных в задаче декодирования фМРТ-изображений разработан метод реконструкции томографических данных из видеопоследовательностей, использующий архитектуру ResNet152 для векторизации видеокадров и линейную регрессию с $L_2$-регуляризацией для предсказания разностей между последовательными фМРТ-снимками.
Предложенный метод предварительного сжатия фМРТ-изображений с коэффициентами 2, 4 и 8 обеспечивает существенное сокращение времени обучения (с 36.3 с до 6.7 с, 1.6 с и 1.4 с соответственно) без потери качества реконструкции.
Экспериментальные результаты на выборке из 30 испытуемых показали, что оптимальное значение коэффициента регуляризации $\alpha \approx 1000$ сохраняется независимо от коэффициента сжатия, что подтверждает стабильность метода при снижении размерности данных и демонстрирует практическую эффективность управления сложностью данных в задачах нейровизуализации.

В разделе о качестве данных в задаче детекции машинной генерации разработаны методы оценки качества наборов данных, содержащих AI-фрагменты, основанные на топологической статистике, анализе устойчивости к адверсарным возмущениям и перемешиванию предложений.
Предложены четыре метрики качества: $\text{KL}_{\text{TTS}}$, PHD, $\Delta_{\text{shift}}$ и $\text{KL}_\text{shuffle}$.
Экспериментальный анализ множественных наборов данных с использованием трех детекторов выявил значительные вариации в качестве данных: детектор на основе DeBERTa демонстрирует наиболее стабильную производительность на различных наборах данных, тогда как другие детекторы показывают значительные вариации, что указывает на проблемы с устойчивостью этих методов к различным доменам.
Качественные наборы данных (SemEval, PAN24, MGT-1) демонстрируют схожие распределения PHD для человеческих и машинно-сгенерированных текстов, что указывает на высокое качество сгенерированных данных и их близость к человеческим текстам по топологическим характеристикам.

Полученные результаты создают основу для практического применения теоретического аппарата сложности моделей и данных в реальных задачах машинного обучения.
Теоретические гарантии для LoRA и многозадачного обучения обеспечивают обоснованный выбор архитектурных решений при разработке эффективных и компактных моделей.
Методы снижения сложности данных в задачах нейровизуализации демонстрируют практическую значимость управления размерностью данных без потери качества.
Метрики оценки качества данных открывают возможности для создания надежных бенчмарков и улучшения качества обучающих наборов данных.

Основные ограничения представленных подходов связаны с вычислительной сложностью анализа топологических характеристик для очень коротких текстов, а также с необходимостью адаптации методов оценки качества данных к различным доменам и языкам.
Теоретическое обоснование методов снижения сложности данных в настоящее время ограничено задачами регрессии с линейными моделями.

Перспективными направлениями дальнейших исследований являются разработка упрощенных практических метрик сложности, которые могли бы служить мостом между строгим теоретическим аппаратом предыдущих глав и потребностями прикладных задач, расширение методов оценки качества данных на другие модальности, интеграция предложенных метрик в процесс создания и валидации обучающих наборов данных, а также разработка адаптивных методов выбора ранга LoRA-адаптеров на основе теоретических оценок сложности Радемахера.