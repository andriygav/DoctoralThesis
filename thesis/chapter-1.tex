Современные модели глубокого обучения демонстрируют исключительную эффективность в решении сложных задач, однако их успешное применение требует понимания фундаментального взаимодействия между сложностью модели и характеристиками данных.
В главе~\ref{chapter:gesian} проводится анализ матриц Гессе для различных архитектур нейронных сетей, что позволяет получить количественные оценки кривизны функции потерь и сложности оптимизационного ландшафта.
Эти результаты создают теоретическую основу для формального определения и измерения сложности как моделей, так и данных.

Ключевой идеей настоящей главы является установление формального соотношения между мерой сложности модели $\mu_f(f)$ и мерой сложности данных $\mu_D(D)$, определяемого через условие обучаемости:
\begin{equation}
    \mu_f(f) \leq \mu_D(D),
\end{equation}
а также получения частных случаев, которые имеют более подробный практический и теоретический анализ.

В рамках данного подхода основным является анализ изменения функции потерь при непрерывном изменении выборки. В разделе~\ref{chapter:complexity:loss} описывается то как абсолютное изменение функции потерь оценивается через спектральную норму матрицы Гессе:
\begin{equation}
    \left| \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) \right| \leqslant M_l + \frac{1}{k+1} \left\|\boldsymbol{\theta} - \boldsymbol{\theta}^*\right\|_2^2 \left\| \mathbf{H}_{k+1}(\boldsymbol{\theta}^*) - \frac{1}{k} \sum\limits_{i=1}^{k} \mathbf{H}_{i}(\boldsymbol{\theta}^*) \right\|_2
\end{equation}

Этот результат, основанный на теоретических выкладках из главы~\ref{chapter:gesian}, позволяет формализовать понятие~\textit{условной сложности выборки}~$\mu_D(D_i|f)$ и установить критерии достаточности объема данных для обучения конкретной модели.

Предлагаемый формализм не только углубляет теоретическое понимание процессов обучения глубоких нейронных сетей, но и имеет практическую значимость для разработки эффективных стратегий обучения, выбора архитектур моделей и планирования экспериментов.
Результаты данной главы создают мост между теоретическим анализом оптимизационных свойств моделей и практическими аспектами их применения к реальным данным, открывая новые возможности для систематического подхода к проектированию и обучению сложных нейросетевых архитектур.

\section{Оценка сложности моделей и данных}

В современной теории глубокого обучения фундаментальной проблемой является установление соответствия между сложностью модели и характеристиками данных.
В рамках данного раздела произведем формализацию данного определения.

\begin{definition}\label{chapter:complex:def-gamma}
    Генеральной совокупностью данных~$\Gamma$ назовем произвольное множество объектов, которые исследуются в рамках той либо иной задаче. В общем случае нет никаких ограничение на счетность множества генеральной совокупности.
\end{definition}

Определение~\ref{chapter:complex:def-gamma} позволяет работать как с однородными, так и с многородной генеральными совокупностями.

\begin{definition}\label{chapter:complex:def-gamma-modality}
    Генеральную совокупность~$\Gamma$ назовем однородной, если все объекты генеральной совокупности порождаются из одного распределения. В противном случае выборку назовем~$k$-родной, где~$k$ является числом распределений на основе которой была сгенерирована генеральная совокупность;
\end{definition}

В определении~\ref{chapter:complex:def-gamma-modality} примером двуродной генеральной совокупности выступает выборка состоящая из текстов и из изображений в качестве объекта исследования. Например, современные большие языковые модели одновременно работают как с текстами, так и с изображениями и называются многомодальными моделями.

Пусть задана генеральная совокупность данных~$\Gamma,$ где задано множество всех подмножеств объектов образующих кольцо выборок:
\[
    \mathfrak{D} = \{D_\Gamma^i\}, \quad D_\Gamma^i \subset \Gamma.
\]

\begin{definition}[Мера сложности выборки]\label{chapter:complex:def-data-complexity}
    Мерой сложности выборки назовем отображение~$\mu_D,$ такое, что: 
    \[
        \mu_D(D_i) : \mathfrak{D}_\Gamma \to \mathbb{R}_+,
    \]
    удовлетворяющее свойству:
    \begin{align}
        \mu_D(D_i\cup D_j) \leq \mu_D(D_i)+\mu_D(D_j),
    \end{align}
    где равенство достигается при условии~$D_i\cap D_j=\emptyset.$
\end{definition}

Определение~\ref{chapter:complex:def-data-complexity} является классическим определением из теории меры, удовлетворяющее свойству конечной-адитивности. Конечной-адитивности нам достаточно, так как в рамках исследований предполагается конечное число объектов при обучении моделей глубокого обучения.
Отдельно стоит оговорить, что мы предполагаем, что мы производим сравнение выборок только из одной генеральной совокупности, но заметим, что мы никак не ограничиваем саму генеральную совокупность и в рамках определения возможны мультимодальные генеральные совокупности.


Пусть задано множество параметрических аппроксимирующих моделей
\[
    \mathfrak{F} = \left\{f_i\right\},
\]
где каждое~$f_i$ является некоторым множеством параметрическим функций. В определении~\ref{chapter:complex:def-model} вводиться общее определение характеристики параметрического семейства функций~$f,$ которые мы в дальнейшем будем рассматривать в качестве моделей моделей глубокого обучения.
\begin{definition}\label{chapter:complex:def-model}
    Мерой сложности модели~$f$ назовем отображение~$\mu_f(f_i)$:
    \[
        \mu_f(f_i) : \mathfrak{F} \to \mathbb{R}_+.
    \]
\end{definition}

Заметим, что определение меры сложности модели~$f$ не является определением меры в общем случае, так как множество~$\mathfrak{F}$ не является кольцом, поэтому данная мера является некоторым отображением, которая является некоторой характеристикой сложности.
К примеру число параметров модели удовлетворяет определению~\ref{chapter:complex:def-model}.

Введя определения меры сложности как для выборки, так и для модели, перейдем к определению обучаемости модели на выборке6 которое сформулировано в определении~\ref{chapter:complex:def-model-bound-data}.

\begin{definition}\label{chapter:complex:def-model-bound-data}
    Назовем модель $f\in\mathfrak{F}$ \textit{обучаемой} на выборке $D\in\mathfrak{D},$ если 
    \[
        \mu_f(f)\leq \mu_D(D).
    \]
\end{definition}

В рамках определения~\ref{chapter:complex:def-model-bound-data} не вводится никакого ограничения на качество аппроксимации модели после обучения, более подробно это будет определено для частных случаев мер в следующих разделах. Также, определение~\ref{chapter:complex:def-model-bound-data} имеет эмпирическую интерпретацию: сложность модели не должна превышать сложности данных, на которых она обучается, так как в противном случае возникает проблема переобучения, когда модель запоминает шум в данных вместо выявления значимых закономерностей.

В рамках диссертационной работы предполагается исследовать частный случай меры сложности модели на основе оценок ландшафта оптимизационных задач используя матрицы Гессе для различных нейросетевых архитектур, которые описаны в главе~\ref{chapter:gesian}. Подробнее о частном случае меры сложности описано в разделе~\ref{chapter:complexity:loss}.

\begin{theorem}\label{chapter:complex:theorem-finetunning}
    Если для исходной выборки~$D\in\mathfrak{D}$ выполняется условие~$\mu_f(f) \leq \mu_D(D)$, тогда для новой выборки~$D'\in\mathfrak{D}$ модель дообучаема при условии:
    \[
        \mu_f(f) - \mu_D(D) \leq \mu_D(D').
    \]
\end{theorem}
\begin{proof}
Доказательство основано на свойствах мер сложности и условии обучаемости модели. 

По определению обучаемости модели на выборке $D$ имеем:
\[
    \mu_f(f) \leq \mu_D(D).
\]
При добавлении новых данных $D'$ к исходной выборке $D$ сложность объединенной выборки не убывает:
\[
    \mu_D(D) \leq \mu_D(D\cup D')
\]
Из свойства адитивности меры сложности выборки, получаем:
\[
    \mu_D(D\cup D') \leq \mu_D(D)+\mu_D(D'),
\]
тогда, объединяя эти три неравенства, получаем цепочку:
\[
    \mu_f(f) \leq \mu_D(D) \leq \mu_D(D\cup D') \leq \mu_D(D)+\mu_D(D'),
\]
тогда перенося $\mu_D(D)$ в левую часть, получаем окончательное неравенство:
\[
    \mu_f(f) - \mu_D(D) \leq \mu_D(D').
\]
\end{proof}

Это неравенство показывает, что ``оставшаяся емкость'' модели, а именно, что разность между сложностью модели и сложностью исходных данных не превосходит сложности новых данных~$D'$, что является необходимым условием для успешного дообучения модели на новых данных.

Теорема~\ref{chapter:complex:theorem-finetunning} предполагает, что мера сложности данных обладает свойством монотонности и субаддитивности. В практических приложениях эти свойства должны быть проверены для конкретных выбранных мер сложности.

Таким образом, введение формальных мер сложности моделей и данных создает теоретическую основу для решения практических задач проектирования архитектур нейронных сетей, планирования экспериментов и оптимизации процессов обучения.


\section{Достаточный объем выборки, как мера сложности данных}

В рамках введенного определения об обучаемости модели на выборке, ключевым понятием становится \textit{условная сложность выборки}:
\begin{equation}\label{chapter:complex:eq-data-submessure}
    \mu_D(D|f) : \mathfrak{D} \to \mathbb{R}_+,
\end{equation}
которая характеризует сложность данных $D\in\mathfrak{D}$ относительно заданной параметрической модели~$f$.
Эта мера отражает, насколько ``трудной'' является выборка~$D$ для обучения модели $f$.

Мотивация введения условной сложности выборки проистекает из практического опыта обучения нейронных сетей.
Одна и та же выборка данных может представлять различную сложность для разных архитектур моделей.

Таким образом мера сложности модели~$\mu_f(f)$ индуцирует меру сложности выборки следующим образом:
\begin{equation}\label{chapter:complex:eq-data-submessure-infinum}
    \mu_D(D|f) = \inf \{ \mu_D(D') : D' \subseteq D, \quad \mu_f(f) \leq \mu_D(D') \},
\end{equation}
то есть условная сложность выборки может быть задана как минимальная сложность данных, при которой модель $f$ остается обучаемой.

\begin{definition}
    Условной сложностью выборки~$D$ относительно заданной параметрической модели~$f$ назовем отображение~\eqref{chapter:complex:eq-data-submessure} определяющиеся выражением~\eqref{chapter:complex:eq-data-submessure-infinum}.
\end{definition}

Рассмотрим частный случай меры сложности данных~$\mu_D$ заданной из определения достаточного объема выборки.
Предположим, что генеральная совокупность~$\Gamma_C$ состоит из объектов одинаковой сложности~$C$, то есть для каждого объекта $\gamma \in \Gamma_C$ выполняется:
\[
    \mu_D(\gamma) = C,
\]
где~$C\in\mathbb{R}_+$ некоторая агрегирована сложность одного объекта выборки. Заметим, что данное предположение является сильным ограничением и может не выполняться на практике, поскольку в реальных задачах различные объекты могут обладать разной сложностью для модели.

\begin{remark}
Константа $C$ представляет собой ``стоимость'' одного объекта выборки в единицах сложности.
На практике $C$ может зависеть от характеристик генеральной совокупности~$\Gamma$ и должна калиброваться экспериментально.
\end{remark}

\begin{definition}
    Однородную генеральную совокупность~$\Gamma_C$ назовем простой, если она состоит из объектов одинаковой сложности~$C.$
\end{definition}

\begin{theorem}
    Для простой генеральной совокупности, мера сложности любой выборки $D \subset \Gamma$ равна ее объему:
    \[
        \mu_D(D) = C\cdot|D|.
    \]
\end{theorem}
\begin{proof}
Докажем, что функция $\mu_D(D) = C \cdot |D|$ удовлетворяет определению меры сложности выборки~\ref{chapter:complex:def-data-complexity}.

Для начала докажем, что функция~$\mu_D$ является неотрицательной.
Поскольку $|D| \geq 0$ для любой выборки $D \subset \Gamma$, и константа $C\in\mathbb{R}_+$, то $\mu_D(D) = C|D| \geq 0$.

Докажем монотоность функции~$\mu_D$.
Пусть $D_1 \subseteq D_2 \subset \Gamma$.
Тогда $|D_1| \leq |D_2|$, следовательно:
\[
    \mu_D(D_1) = C|D_1| \leq C|D_2| = \mu_D(D_2)
\]

Докажем субадитивность функции~$\mu_D$.
Для любых непересекающихся выборок $D_1, D_2 \subset \Gamma$ выполняется:
\[
    \mu_D(D_1 \cup D_2) = C|D_1 \cup D_2| = C(|D_1| + |D_2|) = \mu_D(D_1) + \mu_D(D_2)
\]

Таким образом, функция $\mu_D(D) = C\cdot|D|$ удовлетворяет всем требованиям меры сложности данных в рамках сделанных предположений.
\end{proof}

Частным случаем~\textit{условной сложности выборки} является достаточный объем выборки~--- минимальный объем данных из выборки~$D$ необходимый для обучения модели~$f$.

\begin{definition}
    Размер выборки $m^*$ называется \textit{достаточным} согласно критерию $T$, если $T$ выполняется для всех $k \geqslant m^*$.
\end{definition}

Таким образом исследования достаточного объема выборки является частным случаем предложенного определения меры сложности данных.
Подробный методов оценки достаточного объема выборки рассматривается в главе~\ref{chapter:samplesize}.


\section{Сходимость ландшафта оптимизационной задачи, как мера сложности модели}\label{chapter:complexity:loss}

\begin{figure}[h!t]\center
    \centering
    \includegraphics[width=0.7\linewidth]{figures/chapter-3/losses_difference.pdf}
    \caption{Пример изменения функции потерь при добавлении нового объекта}
    \label{fig-chapter-3-losses-difference}
\end{figure}


Рассмотрим выборку из простой генеральной совокупности~$\Gamma_C$:
\begin{equation}
    D = \left\{ (\mathbf{x}_i, \mathbf{y}_i) \right\}, \quad i = 1, \ldots, m, \quad \mathbf{x} \in \mathcal{X}, \ \mathbf{y} \in \mathcal{Y}, \quad D\subset \Gamma_C.
\end{equation}

Рассмотрим некоторое параметрическое отображение~$f_{\boldsymbol{\theta}}: \mathcal{X} \to \mathcal{Y},$ которое аппроксимирует условное распределение целевой переменной для заданного признакового описания объекта~$p(\mathbf{y}|\mathbf{x}).$ Параметры~$\boldsymbol{\theta}$ функции~$f_{\boldsymbol{\theta}}$ принадлежат пространству~$\mathbb{R}^{P},$ где~$P$ описывает число параметров отображения~$f_{\boldsymbol{\theta}}$.

Пусть, для выбора оптимального вектора параметров~$\hat{\boldsymbol{\theta}}$ используется подход минимизации эмпирического риска:
\begin{equation}
    \hat{\boldsymbol{\theta}} = \arg\min_{\boldsymbol{\theta}} \mathcal{L}_m(\boldsymbol{\theta}),
\end{equation}
где функция эмпирического риска для выборки размера~$|D|=m$ задается в следующем виде: 
\begin{equation}
    \mathcal{L}_m(\boldsymbol{\theta}) = \frac{1}{m} \sum\limits_{i=1}^{m} \ell(f_{\boldsymbol{\theta}}(\mathbf{x}_i), \mathbf{y}_i) \approx \mathbb{E}_{(\mathbf{x}, \mathbf{y}) \sim p(\mathbf{x}, \mathbf{y})} \left[ \ell(f_{\boldsymbol{\theta}}(\mathbf{x}), \mathbf{y}) \right],
\end{equation}
где функция~$\ell\left(\mathbf{z}, \mathbf{y}\right)$ описывает ошибку на одном объекте. Далее в качестве функции~$\ell$ будут рассматриваться либо кросс-энтропийная функция ошибка либо средняя квадратическая ошибка, в зависимости от рассматриваемой задачи и архитектуры модели.

Заметим, что функция эмпирического риска~$\mathcal{L}_m(\boldsymbol{\theta})$ задает некоторую поверхностью в пространстве размерности~$P.$
Изменение значения при добавлении одного объекта
\begin{align}\label{chapter:complex:equation-difference}
    \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) &= \frac{1}{k+1}\sum_{i=1}^k\ell(f_{\boldsymbol{\theta}}(\mathbf{x}_{i}), \mathbf{y}_{i}) - \frac{1}{k+1}\sum_{i=1}^k\ell(f_{\boldsymbol{\theta}}(\mathbf{x}_{i}), \mathbf{y}_{i}) = \\
    &= \frac{1}{k+1}\ell(f_{\boldsymbol{\theta}}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1})-\sum_{i=1}^{k}\frac{1}{k(k+1)}\ell(f_{\boldsymbol{\theta}}(\mathbf{x}_{i}), \mathbf{y}_{i}) = \\
    &= \frac{1}{k+1} \left(\ell(f_{\boldsymbol{\theta}}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1}) - \mathcal{L}_{k}(\boldsymbol{\theta})\right).
\end{align}

Дальнейшее исследования ландшафта нацелено на исследования данной разницы, причем особенно особенно интересуют предельные свойства при стремлении размера выборки к бесконечности. Для дальнейших оценок данной разности вводиться предположение~\ref{chapter:complex:assumption-local-optima-not-change}, которое в целом подтверждается на практике, но в свою очередь является достаточно сильным, что упрощает дальнейшие выкладки.

\begin{assumption}\label{chapter:complex:assumption-local-optima-not-change}
    Пусть $\boldsymbol{\theta}^*$ является локальным минимумом обеих эмпирических функций потерь $\mathcal{L}_{k}(\boldsymbol{\theta})$ и $\mathcal{L}_{k+1}(\boldsymbol{\theta})$, т.е.
    \[
        \nabla \mathcal{L}_{k}(\boldsymbol{\theta}^*) = \nabla \mathcal{L}_{k+1}(\boldsymbol{\theta}^*) = \mathbf{0}.
    \]
\end{assumption}
Содержательно, предположение \ref{chapter:complex:assumption-local-optima-not-change} имеет простую эвристическую интерпретацию, что новый объект данных является \textit{репрезентативным} для уже обученной модели~--- он не приносит ``новой информации'', а лишь уточняет ее.
В целом при асимптотически большом объеме выборки, данное свойство не противоречит эмпирическим результатам.

Воспользуемся квадратичным приближением Тейлора для упомянутых выше функций потерь в окрестности точки $\boldsymbol{\theta}^*$. Предполагаем, что разложение до второго порядка будет достаточным для изучения локального поведения. Член первого порядка обращается в ноль, поскольку градиенты $\nabla \mathcal{L}_{k}(\boldsymbol{\theta}^*)$ и $\nabla \mathcal{L}_{k+1}(\boldsymbol{\theta}^*)$ равны нулю:
\begin{equation}\label{chapter:complex:equation-approx}
    \mathcal{L}_{k}(\boldsymbol{\theta}) \approx \mathcal{L}_{k}(\boldsymbol{\theta}^*) + \frac{1}{2} (\boldsymbol{\theta} - \boldsymbol{\theta}^*)^\top \mathbf{H}^{(k)}(\boldsymbol{\theta}^*) (\boldsymbol{\theta} - \boldsymbol{\theta}^*),
\end{equation}
где мы обозначили гессиан функции $\mathcal{L}_{k}(\boldsymbol{\theta})$ по параметрам $\boldsymbol{\theta}$ в точке $\boldsymbol{\theta}^*$ как $\mathbf{H}^{(k)}(\boldsymbol{\theta}^*) \in \mathbb{R}^{P \times P}$. Более того, полный гессиан может быть записан как среднее значение гессианов отдельных членов эмпирической функции потерь:
\[
    \mathbf{H}^{(k)}(\boldsymbol{\theta}) = \nabla^2_{\boldsymbol{\theta}} \mathcal{L}_{k}(\boldsymbol{\theta}) = \frac{1}{k} \sum\limits_{i=1}^{k} \nabla^2_{\boldsymbol{\theta}} \ell(f_{\boldsymbol{\theta}}(\mathbf{x}_{i}), \mathbf{y}_{i}) = \frac{1}{k} \sum\limits_{i=1}^{k} \mathbf{H}_{i}(\boldsymbol{\theta}).
\]

Следовательно, используя полученное квадратичное приближение~\eqref{chapter:complex:equation-approx}, формула для разности потерь~\eqref{chapter:complex:equation-difference} принимает вид:
\begin{align}
    \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) &= \frac{1}{k+1} \left( \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1}) - \frac{1}{k} \sum\limits_{i=1}^{k} \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{i}), \mathbf{y}_{i}) \right) +\\
    &\quad+ \frac{1}{k+1} (\boldsymbol{\theta} - \boldsymbol{\theta}^*)^\top \left( \mathbf{H}_{k+1}(\boldsymbol{\theta}^*) - \frac{1}{k} \sum\limits_{i=1}^{k} \mathbf{H}_{i}(\boldsymbol{\theta}^*) \right) (\boldsymbol{\theta} - \boldsymbol{\theta}^*),
\end{align}
причем, используя неравенство треугольника, мы можем вывести следующую оценку:
\begin{align}\label{chapter:complex:equation-mod-difference-full}
    \left| \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) \right| &\leqslant \frac{1}{k+1} \left| \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1}) - \frac{1}{k} \sum\limits_{i=1}^{k} \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{i}), \mathbf{y}_{i}) \right| +\\
    &\quad+ \frac{1}{k+1} \left\|\boldsymbol{\theta} - \boldsymbol{\theta}^*\right\|_2^2 \left\| \mathbf{H}_{k+1}(\boldsymbol{\theta}^*) - \frac{1}{k} \sum\limits_{i=1}^{k} \mathbf{H}_{i}(\boldsymbol{\theta}^*) \right\|_2.
\end{align}

Заметим, что первое слагаемое может быть легко ограничено константой, поскольку сама функция потерь принимает ограниченные значения.
Однако выражение с гессианами не так просто оценить.
Подробный анализ матриц Гессе для различных типов параметрических моделей глубокого обучения представлен в главе~\ref{chapter:gesian}.
Таким образом, мы анализируем локальную сходимость ландшафта функции, ее матрицу Гессе.

Получаем выражение для анализа, описывающее поведение ландшафта функции потерь:
\begin{equation}\label{chapter:complex:equation-mod-difference}
    \left| \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) \right| \leqslant \frac{M_l}{k+1}+ \frac{1}{k+1} \left\|\boldsymbol{\theta} - \boldsymbol{\theta}^*\right\|_2^2 \left\| \mathbf{H}_{k+1}(\boldsymbol{\theta}^*) - \frac{1}{k} \sum\limits_{i=1}^{k} \mathbf{H}_{i}(\boldsymbol{\theta}^*) \right\|_2.
\end{equation}

Таким образом получили, что анализ сходимости ландшафта оптимизационной задачи сводится к анализу нормы матрицы Гессе, которые подробно разобраны в главе~\ref{chapter:gesian}.

Оценка~\ref{chapter:complex:equation-mod-difference} задает некоторое свойство параметрического семейства функций~$f$ на заданной выборке~$D.$
Определим данное свойство как условную сложность модели~$f$ на выборке~$D:$
\begin{equation}\label{chapter:complex:equantion-subcomplex-model}
    \mu_f(f|D) : \mathfrak{F} \to \mathbb{R}_+,
\end{equation}
причем, более подробно рассмотрим частный случай условной меры сложности параметрического семейства функций~$f$ вида:
\begin{equation}\label{chapter:complex:equantion-subcomplex-model-surface}
    \mu_f(f|D) = \mathsf{E}_{\mathbf{x}_i\in D}\left\| \mathbf{H}_{i}(\boldsymbol{\theta}^*) -  \mathsf{E}_{\mathbf{x}_i\in D}\mathbf{H}_{i}(\boldsymbol{\theta}^*) \right\|_2.
\end{equation}

\begin{definition}\label{chapter:complex:definition-subcomplex-model}
    Условной сложностью параметрической модели~$f$ относительно заданной выборки~$D$ назовем отображение~\eqref{chapter:complex:equantion-subcomplex-model}.
\end{definition}

\begin{definition}\label{chapter:complex:definition-subcomplex-model-surface}
    Ландшафтноя мерой сложности параметрической функции~$f$ назовем условную сложность параметрической модели~$f$ заданной выражением~\eqref{chapter:complex:equantion-subcomplex-model-surface}.
\end{definition}

Определение~\ref{chapter:complex:definition-subcomplex-model} описывает прикладный способ задания сложности на параметрических семействах функций в контексте оптимизации на заданных выборках.
Причем, условная сложность модели~$\mu_f(f|D)$ характеризует сложность архитектуры модели~$f$ при ее обучении на выборке данных $D$.
Это позволяет количественно оценить, насколько модель ``соответствует'' данным.
Так слишком простая модель может недообучаться, а слишком сложная~--- переобучаться.

Ландшафтная же мера сложности~\ref{chapter:complex:definition-subcomplex-model-surface} представляет собой явный вид условной сложности, основанную на анализе оптимизационного ландшафта функции потерь.
Заметим, что выражение \eqref{chapter:complex:equantion-subcomplex-model-surface} содержательно указывает на то, насколько сильно добавление нового объекта данных изменяет кривизну функции потерь в окрестности оптимума.

Дальнейшее повествование в главе посвящено к оценкам ландшафтной меры для различных параметрических моделей~$f.$
Все результаты основываются на анализе матриц Гессе описаных в главе~\ref{chapter:gesian}.

Используя выражение~\ref{chapter:complex:equation-mod-difference} и определение ландшафтной меры сложности получаем следующую асимптотическую связь между этими оценками:
\begin{equation}\label{chapter:complex:relation-surface-subcomplex-model}
    \left| \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) \right| \leqslant \frac{M_l}{k+1}+ \frac{\mu_f(f|D)}{k+1}\left\|\boldsymbol{\theta} - \boldsymbol{\theta}^*\right\|_2^2.
\end{equation}

\begin{lemma}
    Пусть задан некоторый~$\varepsilon,$ описывающей допустимое изменение ландшафта при добавления одного объекта в некоторой окрестности оптимума~$\boldsymbol{\theta}^*$ радиуса~$R$,
    причем выборка~$D$ из простой генеральной совокупности~$\Gamma_C$.

    Тогда верно следующее соотношение между ландшафтной мерой~$\mu_f(f|D)$ и условной сложностью выборки~$\mu_D(D|f):$
    \[
        \mu_f(f|D) \geq \mu_D(D|f)\frac{\varepsilon}{CR^2} - \frac{M_\ell }{R^2}.
    \]
\end{lemma}
\begin{proof}
    Очевидно из определения условных мер сложности моделей и данных и подстановке всей выборки~$D$ в выражение~\eqref{chapter:complex:relation-surface-subcomplex-model}.
\end{proof}


\subsection{Полносвязная нейросетевая модель глубокого обучения}

Используя результаты, полученные в рамках главы~\ref{chapter:gesian}, а именно результаты теоремы~\ref{theorem:hess-kiselev-lemma} в которой показана асимптотика нормы матрицы Гессе от гиперпараметров полносвязной нейросетевой модели:
\[
    \left\| \mathbf{H}_i(\boldsymbol{\theta}) \right\|_2 \propto L (hM)^{2L},
\]
из которой видно, что спектральная норма матрицы Гессе имеет полиномиальную зависимость от размера слоя и экспоненциальную зависимость от числа слоев.

\begin{theorem}\label{chapter:complex:theorem-kiselev-loss}
    Пусть параметры $\boldsymbol{\theta}$ выбраны так, что $\left\|\boldsymbol{\theta} - \boldsymbol{\theta}^*\right\|_2^2 \leqslant R^2$ для некоторого $R > 0$. Если существует неотрицательная константа $M_{\ell}$ такая, что $\left| \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{i}), \mathbf{y}_{i}) \right| \leqslant M_{\ell}$ для всех объектов $i = 1, \ldots, m$ в наборе данных, то при выполнении условий Теоремы~\ref{theorem:hess-kiselev-theorem} справедливо:
    \begin{align}
        \left| \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) \right| \leqslant \frac{2}{k+1}\left( M_{\ell} + \left( L \sqrt{2} M_{\mathbf{x}}^2 M_{\mathbf{W}}^{2L} + \sqrt{2} \frac{M_{\mathbf{W}}^2 (M_{\mathbf{W}}^{2L} - 1)}{M_{\mathbf{W}}^2 - 1} \right) R^2 \right),
    \end{align}
    причем, что выражение асимптотически стремиться к~$0,$ то есть:
    \begin{align}
        \left| \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) \right| \to 0~\text{при}~k \to \infty.
    \end{align}
    Таким образом, имеет место следующая пропорциональность:
    \begin{equation}\label{eq:rate}
        \left| \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) \right| \propto \frac{L (hM)^{2L} R^2}{k}. 
    \end{equation}
\end{theorem}
\begin{proof}
    Используя неравенство треугольника для выражения~\ref{chapter:complex:equation-mod-difference-full}, получаем
    \begin{align}
        & \left| \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1}) - \frac{1}{k} \sum\limits_{i=1}^{k} \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{i}), \mathbf{y}_{i}) \right| \leqslant \\
        &\quad\leqslant \left| \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1}) \right| + \left| \frac{1}{k} \sum\limits_{i=1}^{k} \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{i}), \mathbf{y}_{i}) \right| \leqslant \\
        &\quad\leqslant \left| \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1}) \right| + \frac{1}{k} \sum\limits_{i=1}^{k} \left| \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{i}), \mathbf{y}_{i}) \right| \leqslant\\
        &\quad\leqslant M_{\ell} + \frac{1}{k} \sum\limits_{i=1}^{k} M_{\ell} = 2M_{\ell} = \mathcal{O}(1) \text{ при } k \to \infty.
    \end{align}
    Аналогично для норм матриц Гессе получаем:
    \begin{align}
        & \left\| \mathbf{H}_{k+1}(\boldsymbol{\theta}^*) - \frac{1}{k} \sum\limits_{i=1}^{k} \mathbf{H}_{i}(\boldsymbol{\theta}^*) \right\|_2 \leqslant \\
        &\quad\leqslant \left\| \mathbf{H}_{k+1}(\boldsymbol{\theta}^*) \right\| + \left\| \frac{1}{k} \sum\limits_{i=1}^{k} \mathbf{H}_{i}(\boldsymbol{\theta}^*) \right\|_2 \leqslant \\
        &\quad\leqslant \left\| \mathbf{H}_{k+1}(\boldsymbol{\theta}^*) \right\| + \frac{1}{k} \sum\limits_{i=1}^{k} \left\| \mathbf{H}_{i}(\boldsymbol{\theta}^*) \right\|_2 \leqslant \\
        &\quad\leqslant M_{\mathbf{H}} + \frac{1}{k} \sum\limits_{i=1}^{k} M_{\mathbf{H}} = 2 M_{\mathbf{H}} = \mathcal{O}(1)~\text{при}~k \to \infty,
    \end{align}
    где из Теоремы~\ref{theorem:hess-kiselev-theorem} получаем
    \[
        M_{\mathbf{H}} = L \sqrt{2} M_{\mathbf{x}}^2 M_{\mathbf{W}}^{2L} + \sqrt{2} \frac{M_{\mathbf{W}}^2 (M_{\mathbf{W}}^{2L} - 1)}{M_{\mathbf{W}}^2 - 1}.
    \]
    
    Таким образом, подставляя полученные оценки в выражение для разности, получаем
    \[
        \left| \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) \right| \leqslant \frac{2M_{\ell}}{k+1} + \frac{2M_{\mathbf{H}}}{k+1} \left\|\boldsymbol{\theta} - \boldsymbol{\theta}^*\right\|_2^2,
    \]
    где выбирая окрестность локального минимума $\boldsymbol{\theta}^*$, т.е. $\left\|\boldsymbol{\theta} - \boldsymbol{\theta}^*\right\|_2^2 \leqslant R^2$, получаем
    \[
        \left| \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) \right| \leqslant \frac{2}{k+1}\left( M_{\ell} + M_{\mathbf{H}}R^2 \right) \to 0 \text{ при } k \to \infty.
    \]
\end{proof}

Используя доказательство теоремы~\ref{chapter:complex:theorem-kiselev-loss} легко получается выражение для ландшафтной меры полносвязной нейросетевой модели глубокого обучения, которое описано в следствии~\ref{chapter:complex:corollary-theorem-kiselev-loss}.

\begin{corollary}\label{chapter:complex:corollary-theorem-kiselev-loss}
    Ландшафтная мера сложности параметрической функции~$f$ полносвязной нейросетевой модели глубокого обучения имеет асимптотику:
    \[
        \mu_f(f|D) \propto L(hM)^{2L},
    \]
    где~$M$ некоторая константа зависящая ограничивающая параметры и данные.
\end{corollary}

В работе~\cite{eldan2016exponentialcomplexity} показано, что существуют функции, которые могут быть эффективно представлены трехслойными сетями, но требуют экспоненциального числа нейронов в двухслойных сетях.
Следствие указывает~\ref{chapter:complex:corollary-theorem-kiselev-loss}, указывает на схожий результат, описывающий то, что экспоненциальный рост сложность модели увеличивается экспоненциально при увеличении числа слоев, и следовательно, уменьшив число слоем, потребуется экспоненциальный рост параметров модели, чтобы сохранить заданную сложность модели.

\subsection{Сверточные модели глубокого обучения}

В данном подразделе рассматривается оценка ландшафтной меры сложности для сверточных нейронных сетей, которые являются одними из популярных на текущий момент моделей глубокого обучения.
В анализе ландшафта используются результаты о матрицах Гессе из главы~\ref{chapter:gesian}.

Начнем с анализа 1D-сверточных сетей, которые применяются в обработке последовательностей, временных рядов и сигналов.
Основные результаты, важные для определения ландшафтной меры сложности, представлены в теореме~\ref{chapter:complex:theorem-1Dconv-loss}.

\begin{theorem}\label{chapter:complex:theorem-1Dconv-loss}
Пусть параметры~$\boldsymbol{\theta}$ находятся в $R$-окрестности оптимума:
\[
    \|\boldsymbol{\theta} - \boldsymbol{\theta}^*\| \leqslant R,
\]
а функция потерь ограничена некоторой константой:
\[
    \exists \; W_l > 0: \; \forall i\; |\ell_i| \leqslant M_{\ell}.
\]
Пусть все объекты в наборе данных ограничены:
\[
    \exists W_x\; \forall i \; \|{x_i}\| \leqslant W_x.
\]
Тогда в условиях теоремы~\ref{thm:1Dconv}:
\begin{align}
    & \big|\mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_{k}(\boldsymbol{\theta})\big| \leqslant \frac{2}{k+1}M_{\ell} +\\
    & + \frac{2}{k+1}R^2\sqrt{2}d^2W_x^2(L+1)(C^2w^2kd)^L.
\end{align}
\end{theorem}
\begin{proof}
    Доказательство эквивалентно доказательству теореме~\ref{chapter:complex:theorem-kiselev-loss} подставляя оценки нормы матрицы Гессе из теоремы~\ref{thm:1Dconv}.
\end{proof}

Используя теорему~\ref{chapter:complex:theorem-1Dconv-loss} легко получается выражение для ландшафтной меры 1D-сверточной нейросетевой модели глубокого обучения, которое описано в следствии~\ref{chapter:complex:corollary-theorem-1Dconv-loss}.

\begin{corollary}\label{chapter:complex:corollary-theorem-1Dconv-loss}
    Ландшафтная мера сложности параметрической функции~$f$ 1D-сверточной модели глубокого обучения имеет асимптотику:
    \[
        \mu_f(f|D) \propto L(C^2M^2kd)^{L},
    \]
    где~$C$~--- максимальное число каналов,~$d$~--- длина входной последовательности,~$k$~--- размер свертки,~$M$~--- некоторая константа зависящая ограничивающая параметры и данные.
\end{corollary}

Полученные оценки демонстрируют, что сложность 1D-сверточных нейросетевых моделей экспоненциально зависит от глубины $L$ и полиномиально~--- от остальных гиперпараметров архитектуры.
Особенностью 1D-архитектур является линейная зависимость от длины последовательности $d$, что отражает специфику обработки последовательностей.

Перейдем к анализу 2D-сверточных сетей, которые применяются в задачах обработки изображений.
Основные результаты, важные для определения ландшафтной меры сложности, представлены в теореме~\ref{chapter:complex:theorem-2Dconv-loss}.

\begin{theorem}\label{chapter:complex:theorem-2Dconv-loss}
Пусть параметры $\boldsymbol{\theta}$ находятся в $R$-окрестности оптимума:
\[
    \|\boldsymbol{\theta} - \boldsymbol{\theta}^*\| \leqslant R.
\]
Также функция потерь ограничена некоторой константой:
\[
    \exists \; W_l > 0: \; \forall i\; |\ell_i| \leqslant W_l.
\]
Пусть все объекты в наборе данных также ограничены:
\[
    \exists W_x\; \forall i \; \|{x_i}\| \leqslant W_x.
\]

Тогда при выполнении условий теоремы~\ref{thm:2Dconv} справедливо:
\begin{align}
    & \big|\mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_{k}(\boldsymbol{\theta})\big| \leqslant \frac{2}{k+1}W_{\ell} +\\
    & + \frac{2}{k+1}R^2\sqrt{2}q^2W_{x}^2(L+1)(C^2k^2w^2mn)^L,
\end{align}
где $q^2 = C^2k^2mn$.
\end{theorem}
\begin{proof}
    Доказательство эквивалентно доказательству теореме~\ref{chapter:complex:theorem-kiselev-loss} подставляя оценки нормы матрицы Гессе из теоремы~\ref{thm:2Dconv}.
\end{proof}

Используя теорему~\ref{chapter:complex:theorem-2Dconv-loss} легко получается выражение для ландшафтной меры 2D-сверточной нейросетевой модели глубокого обучения, которое описано в следствии~\ref{chapter:complex:corollary-theorem-2Dconv-loss}.

\begin{corollary}\label{chapter:complex:corollary-theorem-2Dconv-loss}
    Ландшафтная мера сложности параметрической функции~$f$ 2D-сверточной модели глубокого обучения имеет асимптотику:
    \[
        \mu_f(f|D) \propto C^2k^2L(C^2k^2M^2mn)^{L},
    \]
    где~$C$~--- максимальное число каналов,~$m,n$~--- размеры входного изображения,~$k$~--- размер свертки,~$M$~--- некоторая константа зависящая ограничивающая параметры и данные.
\end{corollary}

Для 2D-сверточных сетей наблюдается более быстрый рост сложности по сравнению с 1D-архитектурами, что обусловлено двумерной природой данных.

\subsection{Трансформер модели глубокого обучения}

Архитектура трансформеров представляет собой один из наиболее значительных прорывов в области глубокого обучения последних лет.
Эти модели демонстрируют state-of-the-art результаты в задачах обработки естественного языка, компьютерного зрения и других областях.
Особенностью трансформеров является механизм самовнимания, который позволяет модели учитывать глобальные зависимости в данных независимо от их положения.

\begin{theorem}\label{chapter:complex:theorem-transformer-loss}
Для одного блока самовнимания и одного блока трансформера \ref{eq:transformer} при условии ограниченности функции потерь \[
    0 \leqslant \ell(\mathbf{f}_{\mathbf{w}^*}(\mathbf{x}_i), \mathbf{y}_i) \leqslant L,
\]
и ограниченности норм матриц Гессе справедливо:
\[
    \left| \mathcal{L}_{k+1}(\mathbf{w}) - \mathcal{L}_k(\mathbf{w}) \right| \leqslant \frac{2L}{k+1} + \frac{M \left\| \mathbf{w} - \mathbf{w}^* \right\|_2^2}{(k+1)},
\]
где для блока самовнимания константа $M$ может быть непосредственно вычислена из Теоремы \ref{thm:self_attention_hessian_estimation},
а для блока трансформера \(M = M_{\text{tr}}\) вычисляется в соответствии с Теоремой~\ref{thm:transformer_hessian_estimate}.
\end{theorem}
\begin{proof}
Доказательство проводится в несколько этапов.
На первом этапе оценивается разность значений функции потерь в оптимальной точке, затем на втором этапе оценивается разность гессианов.
После чего используя результаты обоих этапов, проводиться объединение обоих оценок.

Рассмотрим разность эмпирических функций потерь при добавлении нового объекта. Используя разложение разности и свойства норм, получаем:
\begin{align}
    \left| \mathcal{L}_{k+1}(\mathbf{w}) - \mathcal{L}_k(\mathbf{w}) \right| &\leqslant \frac{1}{k+1} \left| \ell(\mathbf{f}_{\mathbf{w}^*}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1}) - \frac{1}{k} \sum_{i=1}^{k} \ell(\mathbf{f}_{\mathbf{w}^*}(\mathbf{x}_{i}), \mathbf{y}_{i}) \right| +\\
    &\quad+ \frac{1}{2 (k+1)} \left\| \mathbf{w} - \mathbf{w}^* \right\|_2^2 \left\| \mathbf{H}_{k+1}(\mathbf{w}^*) - \frac{1}{k} \sum_{i=1}^{k} \mathbf{H}_i(\mathbf{w}^*) \right\|_2.
\end{align}

Первое слагаемое характеризует изменение значения функции потерь в оптимальной точке параметров $\mathbf{w}^*$ при добавлении нового объекта.
Это разность между значением потерь на новом объекте и средним значением потерь на предыдущей выборке, до добавления нового объекта.
Предположим, что функция потерь $\ell(\mathbf{f}_{\mathbf{w}^*}(\mathbf{x}_i), \mathbf{y}_i)$ ограничена сверху константой $L$ для всех объектов выборки:
\[
    0 \leqslant \ell(\mathbf{f}_{\mathbf{w}^*}(\mathbf{x}_i), \mathbf{y}_i) \leqslant L.
\]
Это предположение является естественным для большинства функций потерь, используемых в машинном обучении, таких как кросс-энтропия или среднеквадратичная ошибка.
Тогда для нового объекта выполняется:
\[
    \ell(\mathbf{f}_{\mathbf{w}^*}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1}) \leqslant L,
\]
а для среднего значения по предыдущей выборке:
\[
    \frac{1}{k} \sum_{i=1}^{k} \ell(\mathbf{f}_{\mathbf{w}^*}(\mathbf{x}_{i}), \mathbf{y}_{i}) \leqslant \frac{1}{k} \sum_{i=1}^{k} L = L.
\]
Используя неравенство треугольника для модуля разности, получаем:
\[
    \left| \ell(\mathbf{f}_{\mathbf{w}^*}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1}) - \frac{1}{k} \sum_{i=1}^{k} \ell(\mathbf{f}_{\mathbf{w}^*}(\mathbf{x}_{i}), \mathbf{y}_{i}) \right| \leqslant L + L = 2L.
\]
Таким образом, вклад первого слагаемого в общую оценку не превосходит:
\[
    \frac{1}{k+1} \left| \ell(\mathbf{f}_{\mathbf{w}^*}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1}) - \frac{1}{k} \sum_{i=1}^{k} \ell(\mathbf{f}_{\mathbf{w}^*}(\mathbf{x}_{i}), \mathbf{y}_{i}) \right| \leqslant \frac{2L}{k+1}.
\]

Второе слагаемое в оценке связано с изменением гессиана функции потерь. Рассмотрим выражение:
\[
    \left\| \mathbf{H}_{k+1}(\mathbf{w}^*) - \frac{1}{k} \sum_{i=1}^{k} \mathbf{H}_i(\mathbf{w}^*) \right\|_2,
\]
где $\mathbf{H}_{k+1}(\mathbf{w}^*) = \nabla^2_{\mathbf{w}} \ell(\mathbf{f}_{\mathbf{w}^*}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1})$~--- матрица Гессе функции потерь для нового объекта, а $\frac{1}{k} \sum_{i=1}^{k} \mathbf{H}_i(\mathbf{w}^*) = \mathbf{H}_k(\mathbf{w}^*)$~--- средняя матрица Гессе по всей предыдущей выборке.
Перепишем это выражение в более удобной форме:
\begin{align}
    \mathbf{H}_k(\mathbf{w}^*) &= \frac{1}{k} \sum_{i=1}^{k} \mathbf{H}_i(\mathbf{w}^*),\\
    \mathbf{H}_{k+1}(\mathbf{w}^*) - \mathbf{H}_k(\mathbf{w}^*) &= \mathbf{H}_{k+1}(\mathbf{w}^*) - \frac{1}{k} \sum_{i=1}^{k} \mathbf{H}_i(\mathbf{w}^*).
\end{align}
Для оценки нормы этой разности используем неравенство треугольника:
\[
    \left\| \mathbf{H}_{k+1}(\mathbf{w}^*) - \frac{1}{k} \sum_{i=1}^{k} \mathbf{H}_i(\mathbf{w}^*) \right\|_2 \leqslant \left\| \mathbf{H}_{k+1}(\mathbf{w}^*) \right\|_2 + \left\| \frac{1}{k} \sum_{i=1}^{k} \mathbf{H}_i(\mathbf{w}^*) \right\|_2.
\]
Предположим, что выполняется ограниченость следующих метриц Гессе:
\[
    \left\| \mathbf{H}_i(\mathbf{w}^*) \right\|_2 \leqslant M
\]
для некоторой константы $M$.
Тогда для гессиана нового объекта:
\[
    \left\| \mathbf{H}_{k+1}(\mathbf{w}^*) \right\|_2 \leqslant M,
\]
а для суммы гессианов:
\[
    \left\| \sum_{i=1}^{k} \mathbf{H}_i(\mathbf{w}^*) \right\|_2 \leqslant \sum_{i=1}^{k} \left\| \mathbf{H}_i(\mathbf{w}^*) \right\|_2 \leqslant k M.
\]
Следовательно:
\[
    \left\| \frac{1}{k} \sum_{i=1}^{k} \mathbf{H}_i(\mathbf{w}^*) \right\|_2 \leqslant \frac{1}{k} \cdot k M = M.
\]
Объединяя полученные оценки, получаем:
\[
    \left\| \mathbf{H}_{k+1}(\mathbf{w}^*) - \frac{1}{k} \sum_{i=1}^{k} \mathbf{H}_i(\mathbf{w}^*) \right\|_2 \leqslant M + M = 2M.
\]
Теперь оценим вклад второго слагаемого в общую разность функций потерь:
\begin{align}
    \frac{1}{2 (k+1)} \left\| \mathbf{w} - \mathbf{w}^* \right\|_2^2 \left\| \mathbf{H}_{k+1}(\mathbf{w}^*) - \mathbf{H}_k(\mathbf{w}^*) \right\|_2 &\leqslant \frac{2M}{2 (k+1)} \left\| \mathbf{w} - \mathbf{w}^* \right\|_2^2 = \\
    &=\frac{M \left\| \mathbf{w} - \mathbf{w}^* \right\|_2^2}{k+1}.
\end{align}


Комбинируя оценки для обоих слагаемых, получаем итоговую оценку:
\[
    \left| \mathcal{L}_{k+1}(\mathbf{w}) - \mathcal{L}_k(\mathbf{w}) \right| \leqslant \frac{2L}{k+1} + \frac{M \left\| \mathbf{w} - \mathbf{w}^* \right\|_2^2}{k+1}.
\]
\end{proof}