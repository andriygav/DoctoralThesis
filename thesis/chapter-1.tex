Современные модели глубокого обучения демонстрируют исключительную эффективность в решении сложных задач, однако их успешное применение требует понимания фундаментального взаимодействия между сложностью модели и характеристиками данных.
В главе~\ref{chapter:gesian} проводится анализ матриц Гессе для различных архитектур нейронных сетей, что позволяет получить количественные оценки кривизны функции потерь и сложности оптимизационного ландшафта.
Эти результаты создают теоретическую основу для формального определения и измерения сложности как моделей, так и данных.

Ключевой идеей настоящей главы является установление формального соотношения между мерой сложности модели $\mu_f(f)$ и мерой сложности данных $\mu_D(D)$, определяемого через условие обучаемости:
\begin{equation}
    \mu_f(f) \leq \mu_D(D),
\end{equation}
а также получения частных случаев, которые имеют более подробный практический и теоретический анализ.

В рамках данного подхода основным является анализ изменения функции потерь при непрерывном изменении выборки. В разделе~\ref{chapter:complexity:loss} описывается то как абсолютное изменение функции потерь оценивается через спектральную норму матрицы Гессе:
\begin{equation}
    \left| \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) \right| \leqslant M_l + \dfrac{1}{k+1} \left\|\boldsymbol{\theta} - \boldsymbol{\theta}^*\right\|_2^2 \left\| \mathbf{H}_{k+1}(\boldsymbol{\theta}^*) - \dfrac{1}{k} \sum\limits_{i=1}^{k} \mathbf{H}_{i}(\boldsymbol{\theta}^*) \right\|_2
\end{equation}

Этот результат, основанный на теоретических выкладках из главы~\ref{chapter:gesian}, позволяет формализовать понятие~\textit{условной сложности выборки}~$\mu_D(D_i|f)$ и установить критерии достаточности объема данных для обучения конкретной модели.

Предлагаемый формализм не только углубляет теоретическое понимание процессов обучения глубоких нейронных сетей, но и имеет практическую значимость для разработки эффективных стратегий обучения, выбора архитектур моделей и планирования экспериментов.
Результаты данной главы создают мост между теоретическим анализом оптимизационных свойств моделей и практическими аспектами их применения к реальным данным, открывая новые возможности для систематического подхода к проектированию и обучению сложных нейросетевых архитектур.

\section{Оценка сложности моделей и данных}

В современной теории глубокого обучения фундаментальной проблемой является установление соответствия между сложностью модели и характеристиками данных.
В рамках данного раздела произведем формализацию данного определения.

\begin{definition}\label{chapter:complex:def-gamma}
    Генеральной совокупностью данных~$\Gamma$ назовем произвольное множество объектов, которые исследуются в рамках той либо иной задаче. В общем случае нет никаких ограничение на счетность множества генеральной совокупности.
\end{definition}

Определение~\ref{chapter:complex:def-gamma} позволяет работать как с однородными, так и с многородной генеральными совокупностями.

\begin{definition}\label{chapter:complex:def-gamma-modality}
    Генеральную совокупность~$\Gamma$ назовем однородной, если все объекты генеральной совокупности порождаются из одного распределения. В противном случае выборку назовем~$k$-родной, где~$k$ является числом распределений на основе которой была сгенерирована генеральная совокупность;
\end{definition}

В определении~\ref{chapter:complex:def-gamma-modality} примером двуродной генеральной совокупности выступает выборка состоящая из текстов и из изображений в качестве объекта исследования. Например, современные большие языковые модели одновременно работают как с текстами, так и с изображениями и называются многомодальными моделями.

Пусть задана генеральная совокупность данных~$\Gamma,$ где задано множество всех подмножеств объектов образующих кольцо выборок:
\[
    \mathfrak{D} = \{D_\Gamma^i\}, \quad D_\Gamma^i \subset \Gamma.
\]

\begin{definition}[Мера сложности выборки]\label{chapter:complex:def-data-complexity}
    Мерой сложности выборки назовем отображение~$\mu_D,$ такое, что: 
    \[
        \mu_D(D_i) : \mathfrak{D}_\Gamma \to \mathbb{R}_+,
    \]
    удовлетворяющее свойству:
    \begin{align}
        \mu_D(D_i\cup D_j) \leq \mu_D(D_i)+\mu_D(D_j),
    \end{align}
    где равенство достигается при условии~$D_i\cap D_j=\emptyset.$
\end{definition}

Определение~\ref{chapter:complex:def-data-complexity} является классическим определением из теории меры, удовлетворяющее свойству конечной-адитивности. Конечной-адитивности нам достаточно, так как в рамках исследований предполагается конечное число объектов при обучении моделей глубокого обучения.
Отдельно стоит оговорить, что мы предполагаем, что мы производим сравнение выборок только из одной генеральной совокупности, но заметим, что мы никак не ограничиваем саму генеральную совокупность и в рамках определения возможны мультимодальные генеральные совокупности.


Пусть задано множество параметрических аппроксимирующих моделей
\[
    \mathfrak{F} = \left\{f_i\right\},
\]
где каждое~$f_i$ является некоторым множеством параметрическим функций. В определении~\ref{chapter:complex:def-model} вводиться общее определение характеристики параметрического семейства функций~$f,$ которые мы в дальнейшем будем рассматривать в качестве моделей моделей глубокого обучения.
\begin{definition}\label{chapter:complex:def-model}
    Мерой сложности модели~$f$ назовем отображение~$\mu_f(f_i)$:
    \[
        \mu_f(f_i) : \mathfrak{F} \to \mathbb{R}_+.
    \]
\end{definition}

Заметим, что определение меры сложности модели~$f$ не является определением меры в общем случае, так как множество~$\mathfrak{F}$ не является кольцом, поэтому данная мера является некоторым отображением, которая является некоторой характеристикой сложности.
К примеру число параметров модели удовлетворяет определению~\ref{chapter:complex:def-model}.

Введя определения меры сложности как для выборки, так и для модели, перейдем к определению обучаемости модели на выборке6 которое сформулировано в определении~\ref{chapter:complex:def-model-bound-data}.

\begin{definition}\label{chapter:complex:def-model-bound-data}
    Назовем модель $f\in\mathfrak{F}$ \textit{обучаемой} на выборке $D\in\mathfrak{D},$ если 
    \[
        \mu_f(f)\leq \mu_D(D).
    \]
\end{definition}

В рамках определения~\ref{chapter:complex:def-model-bound-data} не вводится никакого ограничения на качество аппроксимации модели после обучения, более подробно это будет определено для частных случаев мер в следующих разделах. Также, определение~\ref{chapter:complex:def-model-bound-data} имеет эмпирическую интерпретацию: сложность модели не должна превышать сложности данных, на которых она обучается, так как в противном случае возникает проблема переобучения, когда модель запоминает шум в данных вместо выявления значимых закономерностей.

В рамках диссертационной работы предполагается исследовать частный случай меры сложности модели на основе оценок ландшафта оптимизационных задач используя матрицы Гессе для различных нейросетевых архитектур, которые описаны в главе~\ref{chapter:gesian}. Подробнее о частном случае меры сложности описано в разделе~\ref{chapter:complexity:loss}.

\begin{theorem}\label{chapter:complex:theorem-finetunning}
    Если для исходной выборки~$D\in\mathfrak{D}$ выполняется условие~$\mu_f(f) \leq \mu_D(D)$, тогда для новой выборки~$D'\in\mathfrak{D}$ модель может быть успешно дообучена при условии:
    \[
        \mu_f(f) - \mu_D(D) \leq \mu_D(D').
    \]
\end{theorem}
\begin{proof}
Доказательство основано на свойствах мер сложности и условии обучаемости модели. 

По определению обучаемости модели на выборке $D$ имеем:
\[
    \mu_f(f) \leq \mu_D(D).
\]
При добавлении новых данных $D'$ к исходной выборке $D$ сложность объединенной выборки не убывает:
\[
    \mu_D(D) \leq \mu_D(D\cup D')
\]
Из свойства адитивности меры сложности выборки, получаем:
\[
    \mu_D(D\cup D') \leq \mu_D(D)+\mu_D(D'),
\]
тогда, объединяя эти три неравенства, получаем цепочку:
\[
    \mu_f(f) \leq \mu_D(D) \leq \mu_D(D\cup D') \leq \mu_D(D)+\mu_D(D'),
\]
тогда перенося $\mu_D(D)$ в левую часть, получаем окончательное неравенство:
\[
    \mu_f(f) - \mu_D(D) \leq \mu_D(D').
\]
\end{proof}

Это неравенство показывает, что ``оставшаяся емкость'' модели, а именно, что разность между сложностью модели и сложностью исходных данных не превосходит сложности новых данных~$D'$, что является необходимым условием для успешного дообучения модели на новых данных.

Теорема~\ref{chapter:complex:theorem-finetunning} предполагает, что мера сложности данных обладает свойством монотонности и субаддитивности. В практических приложениях эти свойства должны быть проверены для конкретных выбранных мер сложности.

Таким образом, введение формальных мер сложности моделей и данных создает теоретическую основу для решения практических задач проектирования архитектур нейронных сетей, планирования экспериментов и оптимизации процессов обучения.


\section{Достаточный объем выборки, как мера сложности данных}

В рамках введенного определения об обучаемости модели на выборке, ключевым понятием становится \textit{условная сложность выборки}:
\begin{equation}\label{chapter:complex:eq-data-submessure}
    \mu_D(D|f) : \mathfrak{D} \to \mathbb{R}_+,
\end{equation}
которая характеризует сложность данных $D\in\mathfrak{D}$ относительно заданной параметрической модели~$f$.
Эта мера отражает, насколько ``трудной'' является выборка~$D$ для обучения модели $f$.

Мотивация введения условной сложности выборки проистекает из практического опыта обучения нейронных сетей.
Одна и та же выборка данных может представлять различную сложность для разных архитектур моделей.

Таким образом мера сложности модели~$\mu_f(f)$ индуцирует меру сложности выборки следующим образом:
\begin{equation}\label{chapter:complex:eq-data-submessure-infinum}
    \mu_D(D|f) = \inf \{ \mu_D(D') : D' \subseteq D, \quad \mu_f(f) \leq \mu_D(D') \},
\end{equation}
то есть условная сложность выборки может быть задана как минимальная сложность данных, при которой модель $f$ остается обучаемой.

\begin{definition}
    Условной сложностью выборки~$D$ относительно заданной параметрической модели~$f$ назовем отображение~\eqref{chapter:complex:eq-data-submessure} определяющиеся выражением~\eqref{chapter:complex:eq-data-submessure-infinum}.
\end{definition}

Рассмотрим частный случай меры сложности данных~$\mu_D$ заданной из определения достаточного объема выборки.
Предположим, что генеральная совокупность~$\Gamma_C$ состоит из объектов одинаковой сложности~$C$, то есть для каждого объекта $\gamma \in \Gamma_C$ выполняется:
\[
    \mu_D(\gamma) = C,
\]
где~$C\in\mathbb{R}_+$ некоторая агрегирована сложность одного объекта выборки. Заметим, что данное предположение является сильным ограничением и может не выполняться на практике, поскольку в реальных задачах различные объекты могут обладать разной сложностью для модели.

\begin{remark}
Константа $C$ представляет собой ``стоимость'' одного объекта выборки в единицах сложности.
На практике $C$ может зависеть от характеристик генеральной совокупности~$\Gamma$ и должна калиброваться экспериментально.
\end{remark}

\begin{definition}
    Однородную генеральную совокупность~$\Gamma_C$ назовем простой, если она состоит из объектов одинаковой сложности~$C.$
\end{definition}

\begin{theorem}
    Для простой генеральной совокупности, мера сложности любой выборки $D \subset \Gamma$ равна ее объему:
    \[
        \mu_D(D) = C\cdot|D|.
    \]
\end{theorem}
\begin{proof}
Докажем, что функция $\mu_D(D) = C \cdot |D|$ удовлетворяет определению меры сложности выборки~\ref{chapter:complex:def-data-complexity}.

Для начала докажем, что функция~$\mu_D$ является неотрицательной.
Поскольку $|D| \geq 0$ для любой выборки $D \subset \Gamma$, и константа $C\in\mathbb{R}_+$, то $\mu_D(D) = C|D| \geq 0$.

Докажем монотоность функции~$\mu_D$.
Пусть $D_1 \subseteq D_2 \subset \Gamma$.
Тогда $|D_1| \leq |D_2|$, следовательно:
\[
    \mu_D(D_1) = C|D_1| \leq C|D_2| = \mu_D(D_2)
\]

Докажем субадитивность функции~$\mu_D$.
Для любых непересекающихся выборок $D_1, D_2 \subset \Gamma$ выполняется:
\[
    \mu_D(D_1 \cup D_2) = C|D_1 \cup D_2| = C(|D_1| + |D_2|) = \mu_D(D_1) + \mu_D(D_2)
\]

Таким образом, функция $\mu_D(D) = C\cdot|D|$ удовлетворяет всем требованиям меры сложности данных в рамках сделанных предположений.
\end{proof}

Частным случаем~\textit{условной сложности выборки} является достаточный объем выборки~--- минимальный объем данных из выборки~$D$ необходимый для обучения модели~$f$.

\begin{definition}
    Размер выборки $m^*$ называется \textit{достаточным} согласно критерию $T$, если $T$ выполняется для всех $k \geqslant m^*$.
\end{definition}

Таким образом исследования достаточного объема выборки является частным случаем предложенного определения меры сложности данных.
Подробный методов оценки достаточного объема выборки рассматривается в главе~\ref{chapter:samplesize}.


\section{Сходимость ландшафта оптимизационной задачи, как мера сложности модели}\label{chapter:complexity:loss}

\begin{figure}[h!t]\center
    \centering
    \includegraphics[width=0.7\linewidth]{figures/chapter-3/losses_difference.pdf}
    \caption{Пример изменения функции потерь при добавлении нового объекта}
    \label{fig-chapter-3-losses-difference}
\end{figure}


Рассмотрим выборку из простой генеральной совокупности~$\Gamma_C$:
\begin{equation}
    D = \left\{ (\mathbf{x}_i, \mathbf{y}_i) \right\}, \quad i = 1, \ldots, m, \quad \mathbf{x} \in \mathcal{X}, \ \mathbf{y} \in \mathcal{Y}, \quad D\subset \Gamma_C.
\end{equation}

Рассмотрим некоторое параметрическое отображение~$f_{\boldsymbol{\theta}}: \mathcal{X} \to \mathcal{Y},$ которое аппроксимирует условное распределение целевой переменной для заданного признакового описания объекта~$p(\mathbf{y}|\mathbf{x}).$ Параметры~$\boldsymbol{\theta}$ функции~$f_{\boldsymbol{\theta}}$ принадлежат пространству~$\mathbb{R}^{P},$ где~$P$ описывает число параметров отображения~$f_{\boldsymbol{\theta}}$.

Пусть, для выбора оптимального вектора параметров~$\hat{\boldsymbol{\theta}}$ используется подход минимизации эмпирического риска:
\begin{equation}
    \hat{\boldsymbol{\theta}} = \arg\min_{\boldsymbol{\theta}} \mathcal{L}_m(\boldsymbol{\theta}),
\end{equation}
где функция эмпирического риска для выборки размера~$|D|=m$ задается в следующем виде: 
\begin{equation}
    \mathcal{L}_m(\boldsymbol{\theta}) = \dfrac{1}{m} \sum\limits_{i=1}^{m} \ell(f_{\boldsymbol{\theta}}(\mathbf{x}_i), \mathbf{y}_i) \approx \mathbb{E}_{(\mathbf{x}, \mathbf{y}) \sim p(\mathbf{x}, \mathbf{y})} \left[ \ell(f_{\boldsymbol{\theta}}(\mathbf{x}), \mathbf{y}) \right],
\end{equation}
где функция~$\ell\left(\mathbf{z}, \mathbf{y}\right)$ описывает ошибку на одном объекте. Далее в качестве функции~$\ell$ будут рассматриваться либо кросс-энтропийная функция ошибка либо средняя квадратическая ошибка, в зависимости от рассматриваемой задачи и архитектуры модели.

Заметим, что функция эмпирического риска~$\mathcal{L}_m(\boldsymbol{\theta})$ задает некоторую поверхностью в пространстве размерности~$P.$
Изменение значения при добавлении одного объекта
\begin{align}\label{chapter:complex:equation-difference}
    \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) &= \frac{1}{k+1}\sum_{i=1}^k\ell(f_{\boldsymbol{\theta}}(\mathbf{x}_{i}), \mathbf{y}_{i}) - \frac{1}{k+1}\sum_{i=1}^k\ell(f_{\boldsymbol{\theta}}(\mathbf{x}_{i}), \mathbf{y}_{i}) = \\
    &= \frac{1}{k+1}\ell(f_{\boldsymbol{\theta}}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1})-\sum_{i=1}^{k}\frac{1}{k(k+1)}\ell(f_{\boldsymbol{\theta}}(\mathbf{x}_{i}), \mathbf{y}_{i}) = \\
    &= \dfrac{1}{k+1} \left(\ell(f_{\boldsymbol{\theta}}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1}) - \mathcal{L}_{k}(\boldsymbol{\theta})\right).
\end{align}

Дальнейшее исследования ландшафта нацелено на исследования данной разницы, причем особенно особенно интересуют предельные свойства при стремлении размера выборки к бесконечности. Для дальнейших оценок данной разности вводиться предположение~\ref{chapter:complex:assumption-local-optima-not-change}, которое в целом подтверждается на практике, но в свою очередь является достаточно сильным, что упрощает дальнейшие выкладки.

\begin{assumption}\label{chapter:complex:assumption-local-optima-not-change}
    Пусть $\boldsymbol{\theta}^*$ является локальным минимумом обеих эмпирических функций потерь $\mathcal{L}_{k}(\boldsymbol{\theta})$ и $\mathcal{L}_{k+1}(\boldsymbol{\theta})$, т.е.
    \[
        \nabla \mathcal{L}_{k}(\boldsymbol{\theta}^*) = \nabla \mathcal{L}_{k+1}(\boldsymbol{\theta}^*) = \mathbf{0}.
    \]
\end{assumption}
Содержательно, предположение \ref{chapter:complex:assumption-local-optima-not-change} имеет простую эвристическую интерпретацию, что новый объект данных является \textit{репрезентативным} для уже обученной модели~--- он не приносит ``новой информации'', а лишь уточняет ее.
В целом при асимптотически большом объеме выборки, данное свойство не противоречит эмпирическим результатам.

Воспользуемся квадратичным приближением Тейлора для упомянутых выше функций потерь в окрестности точки $\boldsymbol{\theta}^*$. Предполагаем, что разложение до второго порядка будет достаточным для изучения локального поведения. Член первого порядка обращается в ноль, поскольку градиенты $\nabla \mathcal{L}_{k}(\boldsymbol{\theta}^*)$ и $\nabla \mathcal{L}_{k+1}(\boldsymbol{\theta}^*)$ равны нулю:
\begin{equation}\label{chapter:complex:equation-approx}
    \mathcal{L}_{k}(\boldsymbol{\theta}) \approx \mathcal{L}_{k}(\boldsymbol{\theta}^*) + \dfrac{1}{2} (\boldsymbol{\theta} - \boldsymbol{\theta}^*)^\top \mathbf{H}^{(k)}(\boldsymbol{\theta}^*) (\boldsymbol{\theta} - \boldsymbol{\theta}^*),
\end{equation}
где мы обозначили гессиан функции $\mathcal{L}_{k}(\boldsymbol{\theta})$ по параметрам $\boldsymbol{\theta}$ в точке $\boldsymbol{\theta}^*$ как $\mathbf{H}^{(k)}(\boldsymbol{\theta}^*) \in \mathbb{R}^{P \times P}$. Более того, полный гессиан может быть записан как среднее значение гессианов отдельных членов эмпирической функции потерь:
\[
    \mathbf{H}^{(k)}(\boldsymbol{\theta}) = \nabla^2_{\boldsymbol{\theta}} \mathcal{L}_{k}(\boldsymbol{\theta}) = \dfrac{1}{k} \sum\limits_{i=1}^{k} \nabla^2_{\boldsymbol{\theta}} \ell(f_{\boldsymbol{\theta}}(\mathbf{x}_{i}), \mathbf{y}_{i}) = \dfrac{1}{k} \sum\limits_{i=1}^{k} \mathbf{H}_{i}(\boldsymbol{\theta}).
\]

Следовательно, используя полученное квадратичное приближение~\eqref{chapter:complex:equation-approx}, формула для разности потерь~\eqref{chapter:complex:equation-difference} принимает вид:
\begin{align}
    \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) &= \dfrac{1}{k+1} \left( \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1}) - \dfrac{1}{k} \sum\limits_{i=1}^{k} \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{i}), \mathbf{y}_{i}) \right) +\\
    &\quad+ \dfrac{1}{k+1} (\boldsymbol{\theta} - \boldsymbol{\theta}^*)^\top \left( \mathbf{H}_{k+1}(\boldsymbol{\theta}^*) - \dfrac{1}{k} \sum\limits_{i=1}^{k} \mathbf{H}_{i}(\boldsymbol{\theta}^*) \right) (\boldsymbol{\theta} - \boldsymbol{\theta}^*),
\end{align}
причем, используя неравенство треугольника, мы можем вывести следующую оценку:
\begin{align}
    \left| \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) \right| &\leqslant \dfrac{1}{k+1} \left| \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{k+1}), \mathbf{y}_{k+1}) - \dfrac{1}{k} \sum\limits_{i=1}^{k} \ell(f_{\boldsymbol{\theta}^*}(\mathbf{x}_{i}), \mathbf{y}_{i}) \right| +\\
    &\quad+ \dfrac{1}{k+1} \left\|\boldsymbol{\theta} - \boldsymbol{\theta}^*\right\|_2^2 \left\| \mathbf{H}_{k+1}(\boldsymbol{\theta}^*) - \dfrac{1}{k} \sum\limits_{i=1}^{k} \mathbf{H}_{i}(\boldsymbol{\theta}^*) \right\|_2.
\end{align}

Заметим, что первое слагаемое может быть легко ограничено константой, поскольку сама функция потерь принимает ограниченные значения.
Однако выражение с гессианами не так просто оценить.
Подробный анализ матриц Гессе для различных типов параметрических моделей глубокого обучения представлен в главе~\ref{chapter:gesian}.
Таким образом, мы анализируем локальную сходимость ландшафта функции, ее матрицу Гессе.

Итого, получаем следующее интересующее нас выражение для анализа, описывающее поведение ландшафта функции потерь:
\begin{equation}\label{chapter:complex:equation-mod-difference}
    \left| \mathcal{L}_{k+1}(\boldsymbol{\theta}) - \mathcal{L}_k(\boldsymbol{\theta}) \right| \leqslant M_l+ \dfrac{1}{k+1} \left\|\boldsymbol{\theta} - \boldsymbol{\theta}^*\right\|_2^2 \left\| \mathbf{H}_{k+1}(\boldsymbol{\theta}^*) - \dfrac{1}{k} \sum\limits_{i=1}^{k} \mathbf{H}_{i}(\boldsymbol{\theta}^*) \right\|_2.
\end{equation}