Диссертационная работа посвящена проблеме оценки сложности моделей и данных моделей глубокого обучения.
Предлагается подход, основанный на основе анализа ландшафта оптимизационной задачи для получения асимптотических оценок сложности различных семейств моделей глубокого обучения и их связи с оценкой сложности данных для обучения этих семейств.

\paragraph{Актуальность темы.}
Ключевым фактором развития нейросетевых моделей с начала XXI века является прогресс в вычислительной технике, характеризующийся экспоненциальным ростом производительности суперкомпьютеров, измеряемой в операциях с плавающей запятой~(англ. FLOPS): от значений на уровне терафлопсов в начале столетия до достижения экзафлопсов в настоящий момент.
Параллельно наблюдается сопоставимый рост сложности моделей глубокого обучения, выраженный в увеличении количества обучаемых параметров на несколько порядков~--- от тысяч в начале нулевых годов до миллиардов и сотен миллиардов в двадцатых, с прогнозируемым переходом к триллионам параметров в ближайшем десятилетии.
Современные исследования, посвященные анализу сложности таких моделей, в значительной степени опираются на эмпирические корреляции, связывающие их эффективность с количественными метриками~--- числом параметров и вычислительными затратами на обучение либо применение.
Отсутствие же строгой теоретической основы для предсказания поведения моделей при масштабировании делает этот процесс экономически и энергетически нерациональным и зачастую приводит к получению необоснованных и противоречивых результатов.

Развитие больших языковых моделей~(англ. LLM) сопряжено с высокими затратами на их обучение, выражающимися в большом потреблении вычислительных, энергетических и финансовых ресурсов.
Существенной проблемой в этом процессе является присущая ему непредсказуемость, для нивелирования которой на предварительной стадии обучения~(англ. pretrain) эмпирически подбираются оптимальные соотношения между размером модели в параметрах и объемом обучающих данных в токенах при заданной допустимой вычислительном ресурсе в операциях с плавающей запятой.
Однако данные, полученные для одной архитектуры, не являются переносимыми на другие модели, что делает подобные оценки зачастую несостоятельными и приводит к непредвиденным результатам при полномасштабном обучении.
Поэтому, разработка теоретических оценок сложности моделей является критически важной, поскольку задает асимптотические оценки сложности моделей, которые связаны со сложностью выборки еще на этапе проектирования архитектуры.
Глубоким теоретическим анализом выбора и порождения моделей на этапе проектирования архитектур моделей глубокого обучения занимается Вадим Викторович Стрижов~\cite{strijov2014doctoral}.

Оценка сложности моделей машинного обучения является глубоко изученной областью для классических методов и находит ограниченное применение при анализе моделей глубокого обучения.
Фундаментальный вклад в теорию оценивания сложности моделей и в теорию машинного обучения в целом внесли работы Владимира Наумовича Вапника и Алексея Яковлевича Червоненкиса, заложившие основы статистической теории обучения~\cite{vapnik1974StatTheory}.
Альтернативный математический аппарат для анализа алгоритмов обучения был разработан Лесли Вэлиантом, предложившим приближенно правильного обучения~(англ. PAC-Learning)~\cite{valiant1984LearnableTheory}.
Современный подход к определению сложности основан на Радемахеровской сложности, предложенная Владимиром Кольчинским и Дмитрием Панченко~\cite{koltchinskii2000RadamakherTheory}.
Отдельно стоит отметить комбинаторный подход к оценке обучаемости алгоритмов Константина Вячеславовича Воронцова~\cite{vorontsov04qualdan} в котором получен математический апарат на основе комбинаторных оценок вероятности переобучения моделей. 
Современные исследования в области теории машинного обучения редко рассматривают современные нейросетевые модели в виду их сложности и невозможности получения ``адекватных'' оценок на сложность таких моделей.
Значимая часть современных исследованиях на ведущих конференция посвящена классическим методам машинного анализа и улучшения оценок для известных методов, так как текущие оценки сложности даже для классических моделей машинного обучения являются сильно завышенными.

Отдельным направлением в исследованиях являются оценки репрезентативной способности моделей глубокого обучения к аппроксимации по претендентам. Основополагающий результат в этом принадлежит Джорджу Цибенко~\cite{cybenko1989ApproximationBS}, который доказал, что нейронные сети аппроксимируют непрерывные функции с некоторыми ограничениями сколь угодно большим качеством. С другой стороны Йохану Хостаду~\cite{hastad1987phd} принадлежит первые оценки, которые указывают на рост аппроксимирующей способности моделей глубокого обучения с глубиной модели. В более современных работах Яна Лекуна~\cite{bengioLecun2007:scaling}, Йошуа Бенджио~\cite{begio2011exponetialdepth}, Надава Кохэнема~\cite{cohen2015OnTE} эти оценки получены с более мягкими ограничениями на класс рассматриваемых функций. В целом все эти оценки на ряду с работой Охада Шамира~\cite{eldan2016exponentialcomplexity} указываеют на экспоненциальное увеличение аппроксимирующей способности моделей глубокого обучения с ростом числа слоев.

В работе же проводится теоретический анализ нейросетевых моделей, опирающийся на анализ их матриц Гессе.
Матрица Гессе используется как для анализа параметров в задачах прореживания нейросетевых моделей, так и для анализа ландшафта функции потерь, который используется для анализа сложности моделей и данных и их связи.

\paragraph{Степень разработанности темы диссертационного исследования.}
Современное состояние анализа сложности моделей машинного обучения описаны в~\cite{macKay2003}. С другой стороны сложность нейросетевых моделей является слабо изученной темой на текущий момент. В свою очередь рассмотрения сложности выборки сводится только к анализу размера выборки для обучения~\cite{motrenko2022numerical613055643, demidenko2007, joseph1997, joseph1995, kloek1975, lindley1997, motrenko2014, qumsiyeh2013, rubin1998, self1988, self1992, shieh2000, shieh2005, wang2002}, что является не совсем корректным, так как сложность выборки также обусловлено и сложностью каждого объекта. Современные методы оценки сложность объектов выборки опираются исследования сложности многообразий, которые аппроксимируют данный элемент выборки. Одним из способов оценки объема выборки для обучения больших языковых моделей являются эмперические оценки вместе с методологией их получения для новых моделей~\cite{hoffmann2022Chinchila,kaplan2020ScalingLaws} полученные Джаредом Капланом и Джорданом Хофманом в рамках исследования законов масштабирования нейросетевых моделей~\cite{rae2022scalinglanguagemodelsmethods}. Что касается задачи снижения сложности моделей, на текущий момент существует несколько направлений. Первое направление направлено на квантизацию параметров моделей, второе же, более теоретическое, направлено на дистиляцию и привилегированное обучение~\cite{hinton2015, lopez2016, grabovoi2021bayesian609999432}.

Однако, на текущий момент, в исследованиях не существует теоретического апарата, для описания сложности моделей и данных, чтобы получить асимптотические оценки сложности моделей и данных. Вместе с тем полученный математический аппарат позволит проводить сравнительный анализ различных нейросетевых архитектур, для выбора лучшего решения для заданной задачи, которая описывается выборкой заданной сложности.

В данной работе проведен комплексный подход к оценке сложности моделей и данных. Предложен альтернативный математический аппарат для анализа сложности на основе анализа ландшафта функции потерь нейросетевых моделей. Получены теоретические оценки для матриц Гессе различных моделей глубокого обучения, которые требуются для оценки сложности модели. Отдельной частью данной работы является анализ связи объема и сложности выборки со сложностью модели. Вводятся частные случае общей теории сложности, которые позволяют получать практические оценки для прикладных задач.

\paragraph{Объектом исследования} в работе являются параметрические семейства функций, которые представимы в виде суперпозиции линейных и нелинейных преобразований; данные, которые используются для настройки параметров параметрических семейств.

\paragraph{Предмет исследования:} разработка моделей, методов и теоретического аппарата работы со сложностью моделей глубокого обучения и данными, которые используются для обучения.

\paragraph{Цель и задачи исследования.}
Целью исследования является получения оценок сложности моделей глубокого обучения, а также получения оценок сложности данных для обучения моделей.

Для достижения цели были поставлены и решены следующие задачи:
\begin{itemize}
    \item[--] разработка методов оценки сложности моделей глубокого обучения;
    \item[--] вычисление оценок матриц Гессе для различных архитектур моделей глубокого обучения;
    \item[--] вычисление оценок размера выборки и их связь со сложностью моделей и данных;
    \item[--] разработка методов снижения пространства параметров моделей глубокого обучения при обучении и предсказании;
    \item[--] оценка влияния регуляризации параметров моделей глубокого обучения на оценку сложности моделей глубокого обучения;
    \item[--] практическое применение анализа сложности моделей и данных при обучении моделей глубокого обучения;
    \item[--] неявная регуляризация сложности модели при мультизадачном обучении.
\end{itemize}

\paragraph{Методы исследования.}
Для решения поставленных задач в диссертации используются методы: машинного обучения, статистического анализа данных, статистической теории машинного обучения, линейной алгебры, дискретной математики, теории вероятности, глубокого обучения.

\paragraph{Научная новизна.}
Научной новизной проведенного исследования являются теоретические оценки сложности моделей глубокого обучения и их связи со сложностью данных для обучения.
Диссертация представляет новый подход к рассмотрению сложности моделей глубокого обучения на стыке строго терроризированных оценок и их практической применимостью в реальных задачах.
В диссертации предлагается новый подход к оценке сложности модели на основе анализа ландшафта оптимизационной задачи.
В рамках диссертационной работы получены оценки матриц Гессе для некоторых моделей глубокого обучения.
На основе полученных оценок матриц Гессе в рамках диссертационной работы рассмотрены новые подходы для построения методов оценки важности параметров нейросетевых моделей, которые ранее были слабо исследованы из-за невычислимости данной матрицы для больших нейросетевых моделей.

\paragraph{Теоретическая значимость работы.}
Диссертационная работа в значительной степени представляет из себя именно теоретический результат. В диссертационной работе рассматриваются фундаментальные вопросы о сложности моделей машинного обучения. Полученные оценки на матрицы Гессе открывают большой спектр задач в теории выбора моделей машинного обучения. 

\paragraph{Практическая значимость работы.}
Предложенные теоретические оценки в работе также рассматривались и из практической стороны. В диссертационной работе предложены адаптации различных полученных оценок, для их применимости в различных прикладных задачах. Отдельно проведены работы с сравнением теоретических оценок и эмпирических оценок закона масштабирования моделей глубокого обучения.

\paragraph{Положения, выносимые на защиту:}
\begin{enumerate}
    \item Оценки сложности моделей глубокого обучения.
    \item Оценки сложности данных.
    \item Ландшафтная мера сложности моделей глубокого обучения и ее связь со сложностью данных.
    \item Оценки матриц Гессе для некоторых классов нейросетевых архитектур и их связь с ландшафтной мерой сложности моделей глубокого обучения.
    \item Оценки достаточного размера выборки и их связь со сложностью моделей и данных.
    \item Методы снижения размерности пространства параметров моделей глубокого обучения на основе анализа матриц Гессе.
\end{enumerate}

\paragraph{Степень достоверности результатов.}
Достоверность научных результатов работы подтверждается непротиворечивостью и согласованностью с известными фактами и исследованиями в рассматриваемой области, высокой степенью сходимости теоретических результатов с данными экспериментов и определяется применением теоретических и методологических основ разработок ведущих ученых в области обработки естественного языка, корректным и обоснованным использованием математического аппарата, экспериментальными исследованиями разработанных моделей и методов.

\paragraph{Соответствие диссертации паспорту специальности.}
Тема и основные результаты диссертации соответствуют следующим областям исследований паспорта специальности 1.2.1 --- Искусственный интеллект и машинное обучение.

2 Исследования в области оценки качества и эффективности алгоритмических и программных решений для систем искусственного интеллекта и машинного обучения. Методики сравнения и выбора алгоритмических и программных решений при многих критериях.

4 Разработка методов, алгоритмов и создание систем искусственного интеллекта и машинного обучения для обработки и анализа текстов на естественном языке, для изображений, речи, биомедицины и других специальных видов данных.

16 Исследования в области специальных методов оптимизации, проблем сложность и элиминации перебора, снижения размерности.

17 Исследования в области многослойных алгоритмических конструкций, в том числе – многослойных нейросетей.

\paragraph{Апробация результатов диссертации.}
Основные результаты работы докладывались и обсуждались на Всероссийской конференции с международным участием «Математические методы распознавания образов»~(Москва, 2019, Москва, 2021, Муром, 2025), Международной конференции «Интеллектуализация обработки информации»~(Гаэта, 2018, Москва, 2020, Москва, 2022), Всероссийской научной конференции МФТИ~(Москва, 2018, 2019, 2020, 2021, 2023, 2024, 2025), Ivannikov Ispras Open Conference~(Москва, 2021, 2022, 2023, 2024), Ivannikov Memorial Workshop~(Казань, 2022), Iberian Languages Evaluation Forum co-located with the Conference of the Spanish Society for Natural Language Processing~(Андалусия, 2023, 2024), 35th Conference of Open Innovations Association~(Тампере, 2024), Fourth Workshop on Scholarly Document Processing~(Бангкок, 2024), 1st Workshop on GenAI Content Detection (GenAIDetect)~(Абу-Даби 2025), 19th International Workshop on Semantic Evaluation~(Вена, 2025).

\paragraph{Публикации.}
По теме диссертации опубликовано 56 научных работ, из
которых 17 статей в научно-технических журналах, входящих в перечень ВАК, 32~--- в изданиях, входящих в международные наукометрические базы Scopus и Web of Science.
В трудах российских и международных конференций опубликовано 39 работ. Также на основе работ автора зарегистрировано 13 программ для ЭВМ.

\paragraph{Личный вклад соискателя.}
Все выносимые на защиту результаты и положения, составляющие основное содержание диссертационного исследования, разработаны и получены лично автором или при его непосредственном участии вместе с учениками.
В работах, опубликованных в соавторстве, соискателю принадлежит определяющая роль в построении теоретических методов и направлении.

\paragraph{Структура и объем работы.}
Диссертация состоит из оглавления, введения, шести разделов, заключения, списка иллюстраций, списка таблиц, перечня основных обозначений и списка литературы из~\total{citnum} наименований. Основной текст занимает~\pageref{LastPage} страницы.

\paragraph{Краткое содержание работы по главам.}

В главе~\ref{chapter:curent-learnability-theory} рассматривается текущее состояние теории обучаемости моделей глубокого обучения.

В главе~\ref{chapter:complexity} вводятся общие определения меры сложности моделей и данных.
Вводится понятие обучаемости модели, которое основывается на сравнении меры сложности модели и меры сложности данных.
Отдельно рассматривается условная сложность выборки, частным случаем которой, при простой генеральной совокупности, является достаточный объем выборки для обучения модели глубокого обучения. Отдельно методы оценки достаточного объема выборки рассматриваются в главе~\ref{chapter:samplesize}.
Также вводится понятие условной сложности моделей глубокого обучения, частным случаем которой является ландшафтная мера, которая анализирует изменении ландшафта функции потерь при вариации обучающей выборки.
Ландшафтная мера основывается на исследовании матриц Гессе в окрестности локального минимума, подробные результаты по оценке матриц Гессе для специальных семейств моделей глубокого обучения рассматриваются в главе~\ref{chapter:gesian}.
В главе получена связь между достаточным объемом выборки, которая является частным случаем условной сложности выборки и ландшафтной мерой модели глубокого обучения.
Из полученных общих теоретических оценок, получены оценки для некоторых популярных семейств моделей глубокого обучения, а именно, получена оценка ландшафтной меры для: полносвязной нейросетевой модели глубокого обучения; сверточной модели глубокого обучения; трансформер модели глубокого обучения.
Полученные оценки имеют ассимптотический характер, однако указывают на экспоненциальный рост ландшафтной меры при увеличении числа слоев сети и показательный рост при увеличении числа параметров внутри слоя. Полученные асимптотические оценки ландшафтной меры и их анализ является основной целью данной диссертационной работы.

В главе~\ref{chapter:gesian} описываются ключевые теоремы об оценках матриц Гессе для различных семейств моделей глубокого обучения.
Матрица Гессе функции ошибки оптимизационной модели по параметрам модели глубокого обучения содержит информацию о поведении функции вокруг некоторой точки. На основе матрицы Гессе введена ландшафтная мера из главы~\ref{chapter:complexity}.
В рамках данной главы получены выражение для матриц Гессе и оценки их спектральных норм для: полносвязной нейросетевой модели глубокого обучения; сверточной модели глубокого обучения; трансформер модели глубокого обучения.
Хоть и данная глава имеет больше технический характер, который используется в других главах данной диссертации, однако эти оценки имеют сами по себе научный результат, который может быть использован в других направлениях исследования моделей глубокого обучения.
В частности в теории оптимизации.

В главе~\ref{chapter:samplesize} предлагаются различные методы оценки достаточно объема выборки для различных моделей машинного обучения.
В частности рассматриваются как линейные модели, так и нейросетевые модели глубокого обучения.
В главе сравниваются классические методы оценки достаточного объема выборки с байесовскими методами достаточно объема выборки.
Предложен новый метод оценки достаточно объема выборки на основе сэмлирования эмпирической функции ошибки, для которого указана сходимость для линейной модели, а также эмперически подтверждена работа для моделей глубокого обучения.
Также в главе предложены методы определения достаточного размера выборки, основанный для близости апостериорных распределений близких выборок.
Данные метод имеет теоретические оценки сходимости для любых параметрических семейств с нормальным апостериорным распределением параметров.

В главе~\ref{chapter:pruning} рассматриваются различные методы снижения сложности моделей глубокого обучения.
Предложены методы удаления и фиксации параметров на основе анализа матриц Гессе функции ошибки по параметрам модели.
Отдельно в главе рассматриваются методы дистиляции моделей глубокого обучения, в частности предложен метод дистиляции моделей на многодоменных данных.
Также в рамках главы рассматривается метод анти-дистиляции, в рамках которого рассматривается наращивание сложности модели.
В рамках данного подхода получен эмперический результат, который указывает, что в случае использования информации из обученной небольшой модели учителя, при обучении большой модели ученика, она является более устойчивой к шумму и достигает более высокой точности аппроксимации.

В главе~\ref{chapter:other-aplication} рассматриваются прикладные применения теории сложности моделей глубокого обучения.
В частности рассматривается оценка Радамахеровской сложности в задаче многозадачного обучения.
Доказано, что использования LoRA адаптеров в задаче многозадачного обучения снижает Радамахеровскую сложность.
Приведен пример, когда снижение размерности признакового описания не снижает сложности данных и как следствие не снижает качество аппроксимации модели на примере высокоразмерных ФМРТ снимков.
Отдельно рассмотрено качество данных в задаче детекции машинной генерации.
При помощи введеных метрик продемонстрировано, что качество данных непосредственно влияет на оценку детекторов.



\paragraph{Благодарности.}
Автор благодарен научной школе академиков РАН Константина Владимировича Рудакова и Юрия Ивановича Журавлева, в частности своим учителям доктору физико-математических наук Вадиму Викторовичу Стрижову и профессору РАН Константину Вячеславовичу Воронцову за интерес к работе, советам и поддержку в исследованиях, связанных с данной докторской диссертацией.

Также автор благодарен компании АО <<Антиплагиат>>, где под руководством Юрия Викторовича Чеховича и Александра Сергеевича Кильдякова в отделе исследований проведено большое количество прикладных экспериментов, которые снизили общую сложность моделей глубокого обучения в сервисах компании.

Отдельно, автор признателен своим ученикам, аспирантам и студентам Герману Грицаю, Никите Киселеву, Данилу Дорину, Ильдару Хабутдинову, Владиславу Мешкову, Игорю Игнашину, Анастасии Вознюк, Анне Зверевой, Камилу Баязитову, Анне Ремизовой и Егору Петрову за обсуждение результатов, экспериментальную работу и за общее развитие теории моделей глубокого обучения и в частности их теорию сложности.